nohup: ignoring input
using world size: 8, data-parallel-size: 8, tensor-model-parallel size: 1, pipeline-model-parallel size: 1 
using torch.float16 for parameters ...
WARNING: overriding default arguments for tokenizer_type:BertWordPieceLowerCase                        with tokenizer_type:BertWordPieceCaseJp
------------------------ arguments ------------------------
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  bert_load ....................................... None
  bias_dropout_fusion ............................. True
  bias_gelu_fusion ................................ True
  block_data_path ................................. None
  checkpoint_activations .......................... False
  checkpoint_num_layers ........................... 1
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_impl ....................................... mmap
  data_parallel_size .............................. 8
  data_path ....................................... ['/workspace/megatron/megatron2/nttreso-ja-bert-vocab-32k-mecab-bpe-case_text_sentence']
  DDP_impl ........................................ local
  distribute_checkpointed_activations ............. False
  distributed_backend ............................. nccl
  emoji_file ...................................... None
  eod_mask_loss ................................... False
  eval_interval ................................... 5000
  eval_iters ...................................... 10
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  faiss_use_gpu ................................... False
  finetune ........................................ False
  fp16 ............................................ True
  fp16_lm_cross_entropy ........................... False
  fp32_allreduce .................................. False
  fp32_residual_connection ........................ False
  global_batch_size ............................... 128
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 768
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  init_method_std ................................. 0.02
  initial_loss_scale .............................. 4294967296
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  local_rank ...................................... 0
  log_interval .................................... 1000
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lowercase ....................................... False
  lr .............................................. 0.0001
  lr_decay_iters .................................. 990000
  lr_decay_samples ................................ None
  lr_decay_style .................................. linear
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_prob ....................................... 0.15
  max_position_embeddings ......................... 512
  mecab_dict_path ................................. None
  merge_file ...................................... None
  micro_batch_size ................................ 16
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... False
  no_load_rng ..................................... False
  no_save_optim ................................... False
  no_save_rng ..................................... False
  num_attention_heads ............................. 12
  num_layers ...................................... 12
  num_workers ..................................... 1
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  override_lr_scheduler ........................... False
  params_dtype .................................... torch.float16
  pipeline_model_parallel_size .................... 1
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  report_topk_accuracies .......................... []
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  save ............................................ /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  save_interval ................................... 50000
  scaled_masked_softmax_fusion .................... True
  scaled_upper_triang_masked_softmax_fusion ....... None
  seed ............................................ 1234
  seq_length ...................................... 512
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  titles_data_path ................................ None
  tokenizer_type .................................. BertWordPieceCaseJp
  train_iters ..................................... 10000000
  train_samples ................................... None
  use_checkpoint_lr_scheduler ..................... False
  use_cpu_initialization .......................... False
  use_one_sent_docs ............................... False
  vocab_file ...................................... /workspace/megatron/datasets/nttreso_qa/export/export_readable_20210727_simp_2read_v3.mecab.txt.vocab.32000.v3.bpe
  weight_decay .................................... 0.01
  world_size ...................................... 8
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 1
> building BertWordPieceCaseJp tokenizer ...
 > padded vocab (size: 31960) with 40 dummy tokens (new size: 32000)
> initializing torch distributed ...
> initializing tensor model parallel with size 1
> initializing pipeline model parallel with size 1
> setting random seeds to 1234 ...
> initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234
time to initialize megatron (seconds): 49.628
[after megatron is initialized] datetime: 2021-09-04 06:01:21 
building BERT model ...
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 111243010
> learning rate decay style: linear
WARNING: could not find the metadata file /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe/latest_checkpointed_iteration.txt 
    will not load any checkpoints and will start from random
time (ms) | load checkpoint: 0.38
[after model, optimizer, and learning rate scheduler are built] datetime: 2021-09-04 06:01:21 
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      1280000000
    validation: 2561280
    test:       1280
> building train, validation, and test datasets for BERT ...
 > building dataset index ...
    reading sizes...
    reading pointers...
    reading document index...
    creating numpy buffer of mmap...
    creating memory view of numpy buffer...
 > finished creating indexed dataset in 0.001939 seconds
 > indexed dataset stats:
    number of documents: 31039541
    number of sentences: 416546482
 > dataset split:
    train:
     document indices in [0, 29456524) total of 29456524 documents
     sentence indices in [0, 402507292) total of 402507292 sentences
    validation:
     document indices in [29456524, 31008501) total of 1551977 documents
     sentence indices in [402507292, 416290243) total of 13782951 sentences
    test:
     document indices in [31008501, 31039541) total of 31040 documents
     sentence indices in [416290243, 416546482) total of 256239 sentences
 > WARNING: could not find index map file /workspace/megatron/megatron2/nttreso-ja-bert-vocab-32k-mecab-bpe-case_text_sentence_train_indexmap_1280000000mns_512msl_0.10ssp_1234s.npy, building the indices on rank 0 ...
 > building sapmles index mapping for train ...
    using uint32 for data mapping...
    using:
     number of documents:            29456524
     sentences range:                [0, 402507292)
     total number of sentences:      402507292
     number of epochs:               2147483646
     maximum number of samples:      1280000000
     maximum sequence length:        509
     short sequence probability:     0.1
     short sequence ration (1/prob): 10
     seed:                           1234
    reached 1280000000 samples after 37 epochs ...
   number of empty documents: 153208
   number of documents with one sentence: 505053
   number of documents with long sentences: 36011
   will create mapping for 1291480882 samples
 > done building sapmles index maping
 > saved the index mapping in /workspace/megatron/megatron2/nttreso-ja-bert-vocab-32k-mecab-bpe-case_text_sentence_train_indexmap_1280000000mns_512msl_0.10ssp_1234s.npy
 > elasped time to build and save samples mapping (seconds): 260.480770
 > loading indexed mapping from /workspace/megatron/megatron2/nttreso-ja-bert-vocab-32k-mecab-bpe-case_text_sentence_train_indexmap_1280000000mns_512msl_0.10ssp_1234s.npy
    loaded indexed file in 0.932 seconds
    total number of samples: 1291480882
 > WARNING: could not find index map file /workspace/megatron/megatron2/nttreso-ja-bert-vocab-32k-mecab-bpe-case_text_sentence_valid_indexmap_2561280mns_512msl_0.10ssp_1234s.npy, building the indices on rank 0 ...
 > building sapmles index mapping for valid ...
    using uint32 for data mapping...
    using:
     number of documents:            1551977
     sentences range:                [402507292, 416290243)
     total number of sentences:      13782951
     number of epochs:               2147483646
     maximum number of samples:      2561280
     maximum sequence length:        509
     short sequence probability:     0.1
     short sequence ration (1/prob): 10
     seed:                           1234
    reached 2561280 samples after 2 epochs ...
   number of empty documents: 35109
   number of documents with one sentence: 102592
   number of documents with long sentences: 1212
   will create mapping for 3134213 samples
 > done building sapmles index maping
 > saved the index mapping in /workspace/megatron/megatron2/nttreso-ja-bert-vocab-32k-mecab-bpe-case_text_sentence_valid_indexmap_2561280mns_512msl_0.10ssp_1234s.npy
 > elasped time to build and save samples mapping (seconds): 0.542859
 > loading indexed mapping from /workspace/megatron/megatron2/nttreso-ja-bert-vocab-32k-mecab-bpe-case_text_sentence_valid_indexmap_2561280mns_512msl_0.10ssp_1234s.npy
    loaded indexed file in 0.003 seconds
    total number of samples: 3134213
 > WARNING: could not find index map file /workspace/megatron/megatron2/nttreso-ja-bert-vocab-32k-mecab-bpe-case_text_sentence_test_indexmap_1280mns_512msl_0.10ssp_1234s.npy, building the indices on rank 0 ...
 > building sapmles index mapping for test ...
    using uint32 for data mapping...
    using:
     number of documents:            31040
     sentences range:                [416290243, 416546482)
     total number of sentences:      256239
     number of epochs:               2147483646
     maximum number of samples:      1280
     maximum sequence length:        509
     short sequence probability:     0.1
     short sequence ration (1/prob): 10
     seed:                           1234
    reached 1280 samples after 1 epochs ...
   number of empty documents: 674
   number of documents with one sentence: 2329
   number of documents with long sentences: 17
   will create mapping for 30685 samples
 > done building sapmles index maping
 > saved the index mapping in /workspace/megatron/megatron2/nttreso-ja-bert-vocab-32k-mecab-bpe-case_text_sentence_test_indexmap_1280mns_512msl_0.10ssp_1234s.npy
 > elasped time to build and save samples mapping (seconds): 0.005674
 > loading indexed mapping from /workspace/megatron/megatron2/nttreso-ja-bert-vocab-32k-mecab-bpe-case_text_sentence_test_indexmap_1280mns_512msl_0.10ssp_1234s.npy
    loaded indexed file in 0.000 seconds
    total number of samples: 30685
> finished creating BERT datasets ...
[after dataloaders are built] datetime: 2021-09-04 06:05:45 
done with setups ...
training ...time (ms) | model and optimizer: 241.13 | train/valid/test data iterators: 263196.84

[before the start of training step] datetime: 2021-09-04 06:05:45 
 iteration     1000/10000000 | consumed samples:       128000 | elapsed time per iteration (ms): 269.2 | learning rate: 9.909E-06 | global batch size:   128 | lm loss: 7.851343E+00 | sop loss: 6.912719E-01 | loss scale: 16384.0 | number of skipped iterations:  19 | number of nan iterations:   0 |
time (ms) | forward-compute: 154.52 | backward-compute: 80.25 | backward-params-all-reduce: 15.28 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.43 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.22 | optimizer: 16.60 | batch-generator: 16.55
[Rank 0] (after 1000 iterations) memory (MB) | allocated: 2173.80078125 | max allocated: 9134.31103515625 | reserved: 9878.0 | max reserved: 9878.0
 iteration     2000/10000000 | consumed samples:       256000 | elapsed time per iteration (ms): 253.0 | learning rate: 1.999E-05 | global batch size:   128 | lm loss: 6.239408E+00 | sop loss: 5.313275E-01 | loss scale: 4096.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.80 | backward-compute: 79.74 | backward-params-all-reduce: 14.65 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 14.61
 iteration     3000/10000000 | consumed samples:       384000 | elapsed time per iteration (ms): 247.2 | learning rate: 3.008E-05 | global batch size:   128 | lm loss: 6.099056E+00 | sop loss: 4.124775E-01 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.59 | backward-compute: 79.76 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 16.78
 iteration     4000/10000000 | consumed samples:       512000 | elapsed time per iteration (ms): 250.3 | learning rate: 4.017E-05 | global batch size:   128 | lm loss: 5.995527E+00 | sop loss: 3.801832E-01 | loss scale: 4096.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.04 | backward-compute: 79.74 | backward-params-all-reduce: 14.36 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.21 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.61 | batch-generator: 14.80
 iteration     5000/10000000 | consumed samples:       640000 | elapsed time per iteration (ms): 249.0 | learning rate: 5.027E-05 | global batch size:   128 | lm loss: 5.905013E+00 | sop loss: 3.586012E-01 | loss scale: 8192.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.20 | backward-compute: 79.75 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 17.04
------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 5000 | lm loss value: 5.846741E+00 | lm loss PPL: 3.461047E+02 | sop loss value: 4.209736E-01 | sop loss PPL: 1.523444E+00 | 
------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration     6000/10000000 | consumed samples:       768000 | elapsed time per iteration (ms): 253.4 | learning rate: 6.035E-05 | global batch size:   128 | lm loss: 5.815246E+00 | sop loss: 3.492447E-01 | loss scale: 8192.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.86 | backward-compute: 79.77 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 18.38
 iteration     7000/10000000 | consumed samples:       896000 | elapsed time per iteration (ms): 246.8 | learning rate: 7.043E-05 | global batch size:   128 | lm loss: 5.717161E+00 | sop loss: 3.344220E-01 | loss scale: 8192.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.85 | backward-compute: 79.85 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.52 | batch-generator: 18.51
 iteration     8000/10000000 | consumed samples:      1024000 | elapsed time per iteration (ms): 247.3 | learning rate: 8.052E-05 | global batch size:   128 | lm loss: 5.602923E+00 | sop loss: 3.229464E-01 | loss scale: 8192.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.57 | backward-compute: 79.84 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 20.77
 iteration     9000/10000000 | consumed samples:      1152000 | elapsed time per iteration (ms): 248.2 | learning rate: 9.062E-05 | global batch size:   128 | lm loss: 5.171649E+00 | sop loss: 3.158706E-01 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.56 | backward-compute: 79.84 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 14.90
 iteration    10000/10000000 | consumed samples:      1280000 | elapsed time per iteration (ms): 247.8 | learning rate: 9.999E-05 | global batch size:   128 | lm loss: 4.129676E+00 | sop loss: 3.086760E-01 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.98 | backward-compute: 79.85 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.97
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 10000 | lm loss value: 3.843793E+00 | lm loss PPL: 4.670229E+01 | sop loss value: 3.165781E-01 | sop loss PPL: 1.372423E+00 | 
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration    11000/10000000 | consumed samples:      1408000 | elapsed time per iteration (ms): 248.4 | learning rate: 9.990E-05 | global batch size:   128 | lm loss: 3.679525E+00 | sop loss: 2.961609E-01 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.42 | backward-compute: 79.84 | backward-params-all-reduce: 14.43 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.53 | batch-generator: 15.59
 iteration    12000/10000000 | consumed samples:      1536000 | elapsed time per iteration (ms): 247.6 | learning rate: 9.981E-05 | global batch size:   128 | lm loss: 3.485852E+00 | sop loss: 2.736551E-01 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.75 | backward-compute: 79.83 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 12.99
 iteration    13000/10000000 | consumed samples:      1664000 | elapsed time per iteration (ms): 247.1 | learning rate: 9.972E-05 | global batch size:   128 | lm loss: 3.349916E+00 | sop loss: 2.512627E-01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.47 | backward-compute: 79.80 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.76 | optimizer-unscale-and-check-inf: 2.24 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 13.71
 iteration    14000/10000000 | consumed samples:      1792000 | elapsed time per iteration (ms): 246.8 | learning rate: 9.963E-05 | global batch size:   128 | lm loss: 3.244133E+00 | sop loss: 2.407539E-01 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.15 | backward-compute: 79.85 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 14.25
 iteration    15000/10000000 | consumed samples:      1920000 | elapsed time per iteration (ms): 248.9 | learning rate: 9.953E-05 | global batch size:   128 | lm loss: 3.155899E+00 | sop loss: 2.266683E-01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.14 | backward-compute: 79.87 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 13.90
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 15000 | lm loss value: 3.163184E+00 | lm loss PPL: 2.364576E+01 | sop loss value: 2.153490E-01 | sop loss PPL: 1.240295E+00 | 
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration    16000/10000000 | consumed samples:      2048000 | elapsed time per iteration (ms): 248.6 | learning rate: 9.944E-05 | global batch size:   128 | lm loss: 3.080760E+00 | sop loss: 2.172855E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.80 | backward-compute: 79.85 | backward-params-all-reduce: 14.31 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 14.91
 iteration    17000/10000000 | consumed samples:      2176000 | elapsed time per iteration (ms): 248.4 | learning rate: 9.935E-05 | global batch size:   128 | lm loss: 3.010980E+00 | sop loss: 2.091602E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.70 | backward-compute: 79.93 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.33 | batch-generator: 15.74
 iteration    18000/10000000 | consumed samples:      2304000 | elapsed time per iteration (ms): 248.5 | learning rate: 9.926E-05 | global batch size:   128 | lm loss: 2.957627E+00 | sop loss: 2.003240E-01 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.75 | backward-compute: 79.90 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 22.35
 iteration    19000/10000000 | consumed samples:      2432000 | elapsed time per iteration (ms): 247.4 | learning rate: 9.917E-05 | global batch size:   128 | lm loss: 2.903376E+00 | sop loss: 1.944167E-01 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.61 | backward-compute: 79.88 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.76 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 16.90
 iteration    20000/10000000 | consumed samples:      2560000 | elapsed time per iteration (ms): 246.5 | learning rate: 9.908E-05 | global batch size:   128 | lm loss: 2.858889E+00 | sop loss: 1.875897E-01 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.92 | backward-compute: 79.84 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 14.10
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 20000 | lm loss value: 2.841293E+00 | lm loss PPL: 1.713790E+01 | sop loss value: 1.903499E-01 | sop loss PPL: 1.209673E+00 | 
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration    21000/10000000 | consumed samples:      2688000 | elapsed time per iteration (ms): 248.9 | learning rate: 9.898E-05 | global batch size:   128 | lm loss: 2.818749E+00 | sop loss: 1.848232E-01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.75 | backward-compute: 79.81 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 14.75
 iteration    22000/10000000 | consumed samples:      2816000 | elapsed time per iteration (ms): 245.9 | learning rate: 9.889E-05 | global batch size:   128 | lm loss: 2.787020E+00 | sop loss: 1.779280E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.24 | backward-compute: 79.92 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 18.84
 iteration    23000/10000000 | consumed samples:      2944000 | elapsed time per iteration (ms): 247.2 | learning rate: 9.880E-05 | global batch size:   128 | lm loss: 2.753504E+00 | sop loss: 1.757456E-01 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.66 | backward-compute: 79.89 | backward-params-all-reduce: 13.90 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 15.92
 iteration    24000/10000000 | consumed samples:      3072000 | elapsed time per iteration (ms): 248.6 | learning rate: 9.871E-05 | global batch size:   128 | lm loss: 2.722817E+00 | sop loss: 1.714966E-01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.44 | backward-compute: 79.88 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.56 | batch-generator: 22.00
 iteration    25000/10000000 | consumed samples:      3200000 | elapsed time per iteration (ms): 247.7 | learning rate: 9.862E-05 | global batch size:   128 | lm loss: 2.696516E+00 | sop loss: 1.654102E-01 | loss scale: 65536.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.06 | backward-compute: 79.93 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 12.02
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 25000 | lm loss value: 2.728410E+00 | lm loss PPL: 1.530853E+01 | sop loss value: 1.709581E-01 | sop loss PPL: 1.186441E+00 | 
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration    26000/10000000 | consumed samples:      3328000 | elapsed time per iteration (ms): 248.3 | learning rate: 9.853E-05 | global batch size:   128 | lm loss: 2.675572E+00 | sop loss: 1.626897E-01 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.48 | backward-compute: 79.89 | backward-params-all-reduce: 14.27 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.50 | batch-generator: 15.76
 iteration    27000/10000000 | consumed samples:      3456000 | elapsed time per iteration (ms): 250.2 | learning rate: 9.843E-05 | global batch size:   128 | lm loss: 2.651051E+00 | sop loss: 1.615583E-01 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.54 | backward-compute: 79.80 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 17.39
 iteration    28000/10000000 | consumed samples:      3584000 | elapsed time per iteration (ms): 246.5 | learning rate: 9.834E-05 | global batch size:   128 | lm loss: 2.630689E+00 | sop loss: 1.601722E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.90 | backward-compute: 79.75 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.76 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 14.52
 iteration    29000/10000000 | consumed samples:      3712000 | elapsed time per iteration (ms): 247.6 | learning rate: 9.825E-05 | global batch size:   128 | lm loss: 2.610908E+00 | sop loss: 1.562868E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.57 | backward-compute: 79.82 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.54 | batch-generator: 18.36
 iteration    30000/10000000 | consumed samples:      3840000 | elapsed time per iteration (ms): 248.3 | learning rate: 9.816E-05 | global batch size:   128 | lm loss: 2.590373E+00 | sop loss: 1.534911E-01 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.47 | backward-compute: 79.83 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 21.98
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 30000 | lm loss value: 2.616263E+00 | lm loss PPL: 1.368449E+01 | sop loss value: 1.512933E-01 | sop loss PPL: 1.163338E+00 | 
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration    31000/10000000 | consumed samples:      3968000 | elapsed time per iteration (ms): 248.8 | learning rate: 9.807E-05 | global batch size:   128 | lm loss: 2.576689E+00 | sop loss: 1.525897E-01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.16 | backward-compute: 79.83 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 13.30
 iteration    32000/10000000 | consumed samples:      4096000 | elapsed time per iteration (ms): 247.6 | learning rate: 9.798E-05 | global batch size:   128 | lm loss: 2.560733E+00 | sop loss: 1.479574E-01 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.79 | backward-compute: 79.81 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 16.22
 iteration    33000/10000000 | consumed samples:      4224000 | elapsed time per iteration (ms): 249.7 | learning rate: 9.788E-05 | global batch size:   128 | lm loss: 2.549134E+00 | sop loss: 1.480202E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.07 | backward-compute: 79.83 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 20.95
 iteration    34000/10000000 | consumed samples:      4352000 | elapsed time per iteration (ms): 248.6 | learning rate: 9.779E-05 | global batch size:   128 | lm loss: 2.535213E+00 | sop loss: 1.460973E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.73 | backward-compute: 79.87 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 15.68
 iteration    35000/10000000 | consumed samples:      4480000 | elapsed time per iteration (ms): 248.3 | learning rate: 9.770E-05 | global batch size:   128 | lm loss: 2.515742E+00 | sop loss: 1.452382E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.29 | backward-compute: 79.78 | backward-params-all-reduce: 14.27 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 17.48
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 35000 | lm loss value: 2.545126E+00 | lm loss PPL: 1.274484E+01 | sop loss value: 1.488697E-01 | sop loss PPL: 1.160522E+00 | 
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration    36000/10000000 | consumed samples:      4608000 | elapsed time per iteration (ms): 247.6 | learning rate: 9.761E-05 | global batch size:   128 | lm loss: 2.502815E+00 | sop loss: 1.420602E-01 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 131.85 | backward-compute: 79.86 | backward-params-all-reduce: 14.83 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.87 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.35 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.84 | batch-generator: 17.62
 iteration    37000/10000000 | consumed samples:      4736000 | elapsed time per iteration (ms): 248.5 | learning rate: 9.752E-05 | global batch size:   128 | lm loss: 2.492042E+00 | sop loss: 1.396797E-01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.66 | backward-compute: 79.83 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 18.37
 iteration    38000/10000000 | consumed samples:      4864000 | elapsed time per iteration (ms): 247.9 | learning rate: 9.743E-05 | global batch size:   128 | lm loss: 2.479520E+00 | sop loss: 1.403584E-01 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.07 | backward-compute: 79.85 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.44
 iteration    39000/10000000 | consumed samples:      4992000 | elapsed time per iteration (ms): 247.7 | learning rate: 9.733E-05 | global batch size:   128 | lm loss: 2.471023E+00 | sop loss: 1.387006E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.06 | backward-compute: 79.84 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 14.55
 iteration    40000/10000000 | consumed samples:      5120000 | elapsed time per iteration (ms): 249.6 | learning rate: 9.724E-05 | global batch size:   128 | lm loss: 2.459225E+00 | sop loss: 1.378265E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.99 | backward-compute: 79.89 | backward-params-all-reduce: 13.89 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 16.43
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 40000 | lm loss value: 2.518999E+00 | lm loss PPL: 1.241616E+01 | sop loss value: 1.401200E-01 | sop loss PPL: 1.150412E+00 | 
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration    41000/10000000 | consumed samples:      5248000 | elapsed time per iteration (ms): 249.8 | learning rate: 9.715E-05 | global batch size:   128 | lm loss: 2.449062E+00 | sop loss: 1.369355E-01 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.42 | backward-compute: 79.82 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 24.84
 iteration    42000/10000000 | consumed samples:      5376000 | elapsed time per iteration (ms): 249.4 | learning rate: 9.706E-05 | global batch size:   128 | lm loss: 2.437489E+00 | sop loss: 1.332160E-01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.78 | backward-compute: 79.91 | backward-params-all-reduce: 13.92 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 23.31
 iteration    43000/10000000 | consumed samples:      5504000 | elapsed time per iteration (ms): 247.3 | learning rate: 9.697E-05 | global batch size:   128 | lm loss: 2.429991E+00 | sop loss: 1.327314E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.58 | backward-compute: 79.82 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 15.12
 iteration    44000/10000000 | consumed samples:      5632000 | elapsed time per iteration (ms): 247.8 | learning rate: 9.688E-05 | global batch size:   128 | lm loss: 2.421628E+00 | sop loss: 1.341907E-01 | loss scale: 8192.0 | number of skipped iterations:   4 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.26 | backward-compute: 79.88 | backward-params-all-reduce: 13.88 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 15.64
 iteration    45000/10000000 | consumed samples:      5760000 | elapsed time per iteration (ms): 247.9 | learning rate: 9.678E-05 | global batch size:   128 | lm loss: 2.413079E+00 | sop loss: 1.316559E-01 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.10 | backward-compute: 79.83 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 17.51
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 45000 | lm loss value: 2.471118E+00 | lm loss PPL: 1.183567E+01 | sop loss value: 1.553503E-01 | sop loss PPL: 1.168067E+00 | 
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration    46000/10000000 | consumed samples:      5888000 | elapsed time per iteration (ms): 250.5 | learning rate: 9.669E-05 | global batch size:   128 | lm loss: 2.402047E+00 | sop loss: 1.311714E-01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.06 | backward-compute: 79.83 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 24.19
 iteration    47000/10000000 | consumed samples:      6016000 | elapsed time per iteration (ms): 246.9 | learning rate: 9.660E-05 | global batch size:   128 | lm loss: 2.395971E+00 | sop loss: 1.286029E-01 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.81 | backward-compute: 79.85 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 15.86
 iteration    48000/10000000 | consumed samples:      6144000 | elapsed time per iteration (ms): 246.5 | learning rate: 9.651E-05 | global batch size:   128 | lm loss: 2.389529E+00 | sop loss: 1.290988E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.88 | backward-compute: 79.86 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 17.22
 iteration    49000/10000000 | consumed samples:      6272000 | elapsed time per iteration (ms): 247.1 | learning rate: 9.642E-05 | global batch size:   128 | lm loss: 2.377759E+00 | sop loss: 1.289312E-01 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.19 | backward-compute: 79.88 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.78
 iteration    50000/10000000 | consumed samples:      6400000 | elapsed time per iteration (ms): 250.3 | learning rate: 9.633E-05 | global batch size:   128 | lm loss: 2.371179E+00 | sop loss: 1.274638E-01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.32 | backward-compute: 79.88 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.51 | batch-generator: 18.04
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 50000 | lm loss value: 2.431044E+00 | lm loss PPL: 1.137074E+01 | sop loss value: 1.225211E-01 | sop loss PPL: 1.130343E+00 | 
-------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration   50000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration   50000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2396.33
 iteration    51000/10000000 | consumed samples:      6528000 | elapsed time per iteration (ms): 253.7 | learning rate: 9.623E-05 | global batch size:   128 | lm loss: 2.365719E+00 | sop loss: 1.253546E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.97 | backward-compute: 79.85 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 16.08
 iteration    52000/10000000 | consumed samples:      6656000 | elapsed time per iteration (ms): 248.3 | learning rate: 9.614E-05 | global batch size:   128 | lm loss: 2.358136E+00 | sop loss: 1.262752E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.63 | backward-compute: 79.87 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 19.77
 iteration    53000/10000000 | consumed samples:      6784000 | elapsed time per iteration (ms): 246.1 | learning rate: 9.605E-05 | global batch size:   128 | lm loss: 2.348996E+00 | sop loss: 1.235571E-01 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.27 | backward-compute: 79.84 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 17.28
 iteration    54000/10000000 | consumed samples:      6912000 | elapsed time per iteration (ms): 248.4 | learning rate: 9.596E-05 | global batch size:   128 | lm loss: 2.343909E+00 | sop loss: 1.225558E-01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.66 | backward-compute: 79.85 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.43 | batch-generator: 21.39
 iteration    55000/10000000 | consumed samples:      7040000 | elapsed time per iteration (ms): 248.7 | learning rate: 9.587E-05 | global batch size:   128 | lm loss: 2.339032E+00 | sop loss: 1.222638E-01 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.04 | backward-compute: 79.85 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 14.03
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 55000 | lm loss value: 2.398372E+00 | lm loss PPL: 1.100525E+01 | sop loss value: 1.310331E-01 | sop loss PPL: 1.140006E+00 | 
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration    56000/10000000 | consumed samples:      7168000 | elapsed time per iteration (ms): 250.8 | learning rate: 9.578E-05 | global batch size:   128 | lm loss: 2.331237E+00 | sop loss: 1.215000E-01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.56 | backward-compute: 79.85 | backward-params-all-reduce: 13.88 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 16.55
 iteration    57000/10000000 | consumed samples:      7296000 | elapsed time per iteration (ms): 248.3 | learning rate: 9.568E-05 | global batch size:   128 | lm loss: 2.324118E+00 | sop loss: 1.228639E-01 | loss scale: 65536.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.46 | backward-compute: 79.86 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.41 | batch-generator: 15.95
 iteration    58000/10000000 | consumed samples:      7424000 | elapsed time per iteration (ms): 245.8 | learning rate: 9.559E-05 | global batch size:   128 | lm loss: 2.320308E+00 | sop loss: 1.212847E-01 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.10 | backward-compute: 79.86 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.76 | optimizer-unscale-and-check-inf: 2.24 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.29 | batch-generator: 16.34
 iteration    59000/10000000 | consumed samples:      7552000 | elapsed time per iteration (ms): 246.9 | learning rate: 9.550E-05 | global batch size:   128 | lm loss: 2.313334E+00 | sop loss: 1.191548E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.10 | backward-compute: 79.90 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 15.36
 iteration    60000/10000000 | consumed samples:      7680000 | elapsed time per iteration (ms): 246.6 | learning rate: 9.541E-05 | global batch size:   128 | lm loss: 2.307610E+00 | sop loss: 1.202647E-01 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.94 | backward-compute: 79.84 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 13.40
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 60000 | lm loss value: 2.318185E+00 | lm loss PPL: 1.015722E+01 | sop loss value: 1.515163E-01 | sop loss PPL: 1.163597E+00 | 
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration    61000/10000000 | consumed samples:      7808000 | elapsed time per iteration (ms): 248.7 | learning rate: 9.532E-05 | global batch size:   128 | lm loss: 2.303635E+00 | sop loss: 1.190342E-01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.55 | backward-compute: 79.84 | backward-params-all-reduce: 14.60 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.23 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.65 | batch-generator: 17.10
 iteration    62000/10000000 | consumed samples:      7936000 | elapsed time per iteration (ms): 246.6 | learning rate: 9.523E-05 | global batch size:   128 | lm loss: 2.295418E+00 | sop loss: 1.180319E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.28 | backward-compute: 79.85 | backward-params-all-reduce: 14.40 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.57 | batch-generator: 17.54
 iteration    63000/10000000 | consumed samples:      8064000 | elapsed time per iteration (ms): 248.5 | learning rate: 9.513E-05 | global batch size:   128 | lm loss: 2.290318E+00 | sop loss: 1.170028E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.72 | backward-compute: 79.81 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 16.20
 iteration    64000/10000000 | consumed samples:      8192000 | elapsed time per iteration (ms): 249.3 | learning rate: 9.504E-05 | global batch size:   128 | lm loss: 2.286217E+00 | sop loss: 1.178186E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.67 | backward-compute: 79.84 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 15.00
 iteration    65000/10000000 | consumed samples:      8320000 | elapsed time per iteration (ms): 247.3 | learning rate: 9.495E-05 | global batch size:   128 | lm loss: 2.280329E+00 | sop loss: 1.166776E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.58 | backward-compute: 79.86 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 16.72
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 65000 | lm loss value: 2.287324E+00 | lm loss PPL: 9.848552E+00 | sop loss value: 1.243137E-01 | sop loss PPL: 1.132371E+00 | 
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration    66000/10000000 | consumed samples:      8448000 | elapsed time per iteration (ms): 251.8 | learning rate: 9.486E-05 | global batch size:   128 | lm loss: 2.280412E+00 | sop loss: 1.164511E-01 | loss scale: 65536.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.25 | backward-compute: 79.83 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 14.99
 iteration    67000/10000000 | consumed samples:      8576000 | elapsed time per iteration (ms): 248.2 | learning rate: 9.477E-05 | global batch size:   128 | lm loss: 2.272214E+00 | sop loss: 1.157497E-01 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.22 | backward-compute: 79.83 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 16.24
 iteration    68000/10000000 | consumed samples:      8704000 | elapsed time per iteration (ms): 248.6 | learning rate: 9.468E-05 | global batch size:   128 | lm loss: 2.269094E+00 | sop loss: 1.136164E-01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.92 | backward-compute: 79.80 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 19.69
 iteration    69000/10000000 | consumed samples:      8832000 | elapsed time per iteration (ms): 247.5 | learning rate: 9.458E-05 | global batch size:   128 | lm loss: 2.262780E+00 | sop loss: 1.133651E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.92 | backward-compute: 79.83 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 13.71
 iteration    70000/10000000 | consumed samples:      8960000 | elapsed time per iteration (ms): 249.8 | learning rate: 9.449E-05 | global batch size:   128 | lm loss: 2.261885E+00 | sop loss: 1.133245E-01 | loss scale: 65536.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.30 | backward-compute: 79.82 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 13.64
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 70000 | lm loss value: 2.293897E+00 | lm loss PPL: 9.913499E+00 | sop loss value: 1.355863E-01 | sop loss PPL: 1.145208E+00 | 
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration    71000/10000000 | consumed samples:      9088000 | elapsed time per iteration (ms): 248.3 | learning rate: 9.440E-05 | global batch size:   128 | lm loss: 2.253037E+00 | sop loss: 1.124278E-01 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.84 | backward-compute: 79.86 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 21.03
 iteration    72000/10000000 | consumed samples:      9216000 | elapsed time per iteration (ms): 246.7 | learning rate: 9.431E-05 | global batch size:   128 | lm loss: 2.248040E+00 | sop loss: 1.141337E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.97 | backward-compute: 79.87 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 17.06
 iteration    73000/10000000 | consumed samples:      9344000 | elapsed time per iteration (ms): 248.9 | learning rate: 9.422E-05 | global batch size:   128 | lm loss: 2.241138E+00 | sop loss: 1.093492E-01 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.19 | backward-compute: 79.83 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 16.16
 iteration    74000/10000000 | consumed samples:      9472000 | elapsed time per iteration (ms): 247.1 | learning rate: 9.412E-05 | global batch size:   128 | lm loss: 2.240205E+00 | sop loss: 1.130832E-01 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.28 | backward-compute: 79.81 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 12.84
 iteration    75000/10000000 | consumed samples:      9600000 | elapsed time per iteration (ms): 249.7 | learning rate: 9.403E-05 | global batch size:   128 | lm loss: 2.235534E+00 | sop loss: 1.096068E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.98 | backward-compute: 79.83 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 21.19
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 75000 | lm loss value: 2.292896E+00 | lm loss PPL: 9.903573E+00 | sop loss value: 1.189136E-01 | sop loss PPL: 1.126273E+00 | 
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration    76000/10000000 | consumed samples:      9728000 | elapsed time per iteration (ms): 249.9 | learning rate: 9.394E-05 | global batch size:   128 | lm loss: 2.230153E+00 | sop loss: 1.111609E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.99 | backward-compute: 79.80 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 16.77
 iteration    77000/10000000 | consumed samples:      9856000 | elapsed time per iteration (ms): 248.1 | learning rate: 9.385E-05 | global batch size:   128 | lm loss: 2.226478E+00 | sop loss: 1.114224E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.52 | backward-compute: 79.89 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 13.52
 iteration    78000/10000000 | consumed samples:      9984000 | elapsed time per iteration (ms): 247.1 | learning rate: 9.376E-05 | global batch size:   128 | lm loss: 2.221731E+00 | sop loss: 1.107185E-01 | loss scale: 65536.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.38 | backward-compute: 79.83 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 16.84
 iteration    79000/10000000 | consumed samples:     10112000 | elapsed time per iteration (ms): 247.8 | learning rate: 9.367E-05 | global batch size:   128 | lm loss: 2.219300E+00 | sop loss: 1.092279E-01 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.90 | backward-compute: 79.83 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 16.19
 iteration    80000/10000000 | consumed samples:     10240000 | elapsed time per iteration (ms): 249.2 | learning rate: 9.358E-05 | global batch size:   128 | lm loss: 2.216184E+00 | sop loss: 1.100043E-01 | loss scale: 4096.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.56 | backward-compute: 79.75 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 17.72
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 80000 | lm loss value: 2.242057E+00 | lm loss PPL: 9.412670E+00 | sop loss value: 1.291689E-01 | sop loss PPL: 1.137882E+00 | 
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration    81000/10000000 | consumed samples:     10368000 | elapsed time per iteration (ms): 251.1 | learning rate: 9.348E-05 | global batch size:   128 | lm loss: 2.213377E+00 | sop loss: 1.077853E-01 | loss scale: 8192.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.92 | backward-compute: 79.75 | backward-params-all-reduce: 13.89 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 20.32
 iteration    82000/10000000 | consumed samples:     10496000 | elapsed time per iteration (ms): 247.4 | learning rate: 9.339E-05 | global batch size:   128 | lm loss: 2.208260E+00 | sop loss: 1.092987E-01 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.70 | backward-compute: 79.78 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.45 | batch-generator: 18.84
 iteration    83000/10000000 | consumed samples:     10624000 | elapsed time per iteration (ms): 247.1 | learning rate: 9.330E-05 | global batch size:   128 | lm loss: 2.204422E+00 | sop loss: 1.092411E-01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.29 | backward-compute: 79.83 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 13.99
 iteration    84000/10000000 | consumed samples:     10752000 | elapsed time per iteration (ms): 245.8 | learning rate: 9.321E-05 | global batch size:   128 | lm loss: 2.196975E+00 | sop loss: 1.076430E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.20 | backward-compute: 79.88 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 15.76
 iteration    85000/10000000 | consumed samples:     10880000 | elapsed time per iteration (ms): 246.7 | learning rate: 9.312E-05 | global batch size:   128 | lm loss: 2.199821E+00 | sop loss: 1.079314E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.37 | backward-compute: 79.85 | backward-params-all-reduce: 14.40 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.19 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.62 | batch-generator: 17.32
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 85000 | lm loss value: 2.289726E+00 | lm loss PPL: 9.872233E+00 | sop loss value: 1.413312E-01 | sop loss PPL: 1.151806E+00 | 
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration    86000/10000000 | consumed samples:     11008000 | elapsed time per iteration (ms): 249.5 | learning rate: 9.302E-05 | global batch size:   128 | lm loss: 2.195761E+00 | sop loss: 1.067004E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.23 | backward-compute: 79.81 | backward-params-all-reduce: 14.65 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.25 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.69 | batch-generator: 15.14
 iteration    87000/10000000 | consumed samples:     11136000 | elapsed time per iteration (ms): 246.1 | learning rate: 9.293E-05 | global batch size:   128 | lm loss: 2.190107E+00 | sop loss: 1.063029E-01 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.90 | backward-compute: 79.80 | backward-params-all-reduce: 14.36 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.57 | batch-generator: 15.55
 iteration    88000/10000000 | consumed samples:     11264000 | elapsed time per iteration (ms): 246.0 | learning rate: 9.284E-05 | global batch size:   128 | lm loss: 2.190556E+00 | sop loss: 1.058685E-01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.63 | backward-compute: 79.84 | backward-params-all-reduce: 14.42 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.58 | batch-generator: 14.76
 iteration    89000/10000000 | consumed samples:     11392000 | elapsed time per iteration (ms): 248.8 | learning rate: 9.275E-05 | global batch size:   128 | lm loss: 2.185154E+00 | sop loss: 1.040360E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.11 | backward-compute: 79.80 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 17.86
 iteration    90000/10000000 | consumed samples:     11520000 | elapsed time per iteration (ms): 246.8 | learning rate: 9.266E-05 | global batch size:   128 | lm loss: 2.180373E+00 | sop loss: 1.033211E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.08 | backward-compute: 79.82 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 17.77
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 90000 | lm loss value: 2.257330E+00 | lm loss PPL: 9.557534E+00 | sop loss value: 1.393776E-01 | sop loss PPL: 1.149558E+00 | 
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration    91000/10000000 | consumed samples:     11648000 | elapsed time per iteration (ms): 248.7 | learning rate: 9.257E-05 | global batch size:   128 | lm loss: 2.181840E+00 | sop loss: 1.040389E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.50 | backward-compute: 79.84 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 14.84
 iteration    92000/10000000 | consumed samples:     11776000 | elapsed time per iteration (ms): 248.5 | learning rate: 9.247E-05 | global batch size:   128 | lm loss: 2.175020E+00 | sop loss: 1.047737E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.80 | backward-compute: 79.83 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 16.17
 iteration    93000/10000000 | consumed samples:     11904000 | elapsed time per iteration (ms): 246.8 | learning rate: 9.238E-05 | global batch size:   128 | lm loss: 2.173989E+00 | sop loss: 1.042996E-01 | loss scale: 65536.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.06 | backward-compute: 79.86 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 13.39
 iteration    94000/10000000 | consumed samples:     12032000 | elapsed time per iteration (ms): 246.2 | learning rate: 9.229E-05 | global batch size:   128 | lm loss: 2.167212E+00 | sop loss: 1.036215E-01 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.32 | backward-compute: 79.82 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 14.91
 iteration    95000/10000000 | consumed samples:     12160000 | elapsed time per iteration (ms): 247.7 | learning rate: 9.220E-05 | global batch size:   128 | lm loss: 2.166892E+00 | sop loss: 1.030057E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.25 | backward-compute: 79.81 | backward-params-all-reduce: 14.48 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.24 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.66 | batch-generator: 13.18
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 95000 | lm loss value: 2.208337E+00 | lm loss PPL: 9.100572E+00 | sop loss value: 1.183022E-01 | sop loss PPL: 1.125584E+00 | 
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration    96000/10000000 | consumed samples:     12288000 | elapsed time per iteration (ms): 250.5 | learning rate: 9.211E-05 | global batch size:   128 | lm loss: 2.166200E+00 | sop loss: 1.042930E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.88 | backward-compute: 79.82 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 16.03
 iteration    97000/10000000 | consumed samples:     12416000 | elapsed time per iteration (ms): 248.1 | learning rate: 9.202E-05 | global batch size:   128 | lm loss: 2.163022E+00 | sop loss: 1.033051E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.32 | backward-compute: 79.81 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 17.06
 iteration    98000/10000000 | consumed samples:     12544000 | elapsed time per iteration (ms): 247.2 | learning rate: 9.192E-05 | global batch size:   128 | lm loss: 2.157329E+00 | sop loss: 1.044687E-01 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.42 | backward-compute: 79.78 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 14.82
 iteration    99000/10000000 | consumed samples:     12672000 | elapsed time per iteration (ms): 248.7 | learning rate: 9.183E-05 | global batch size:   128 | lm loss: 2.155072E+00 | sop loss: 1.030474E-01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.75 | backward-compute: 79.81 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 21.82
 iteration   100000/10000000 | consumed samples:     12800000 | elapsed time per iteration (ms): 248.3 | learning rate: 9.174E-05 | global batch size:   128 | lm loss: 2.148572E+00 | sop loss: 1.022266E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.64 | backward-compute: 79.81 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 16.08
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 100000 | lm loss value: 2.223074E+00 | lm loss PPL: 9.235675E+00 | sop loss value: 9.496875E-02 | sop loss PPL: 1.099624E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration  100000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration  100000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2287.28
 iteration   101000/10000000 | consumed samples:     12928000 | elapsed time per iteration (ms): 252.5 | learning rate: 9.165E-05 | global batch size:   128 | lm loss: 2.146718E+00 | sop loss: 1.028128E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.91 | backward-compute: 79.82 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 12.41
 iteration   102000/10000000 | consumed samples:     13056000 | elapsed time per iteration (ms): 248.2 | learning rate: 9.156E-05 | global batch size:   128 | lm loss: 2.145517E+00 | sop loss: 1.007026E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.58 | backward-compute: 79.81 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 14.63
 iteration   103000/10000000 | consumed samples:     13184000 | elapsed time per iteration (ms): 247.1 | learning rate: 9.147E-05 | global batch size:   128 | lm loss: 2.146159E+00 | sop loss: 1.015268E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.79 | backward-compute: 79.82 | backward-params-all-reduce: 14.42 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.60 | batch-generator: 23.78
 iteration   104000/10000000 | consumed samples:     13312000 | elapsed time per iteration (ms): 248.1 | learning rate: 9.137E-05 | global batch size:   128 | lm loss: 2.140647E+00 | sop loss: 1.018316E-01 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.16 | backward-compute: 79.82 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.50 | batch-generator: 16.01
 iteration   105000/10000000 | consumed samples:     13440000 | elapsed time per iteration (ms): 248.0 | learning rate: 9.128E-05 | global batch size:   128 | lm loss: 2.139069E+00 | sop loss: 1.014412E-01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.41 | backward-compute: 79.85 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.64
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 105000 | lm loss value: 2.173595E+00 | lm loss PPL: 8.789826E+00 | sop loss value: 1.081942E-01 | sop loss PPL: 1.114264E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   106000/10000000 | consumed samples:     13568000 | elapsed time per iteration (ms): 248.2 | learning rate: 9.119E-05 | global batch size:   128 | lm loss: 2.136621E+00 | sop loss: 1.022268E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.58 | backward-compute: 79.87 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 15.10
 iteration   107000/10000000 | consumed samples:     13696000 | elapsed time per iteration (ms): 247.8 | learning rate: 9.110E-05 | global batch size:   128 | lm loss: 2.131483E+00 | sop loss: 1.017999E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.44 | backward-compute: 79.84 | backward-params-all-reduce: 14.43 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.20 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.60 | batch-generator: 12.23
 iteration   108000/10000000 | consumed samples:     13824000 | elapsed time per iteration (ms): 246.3 | learning rate: 9.101E-05 | global batch size:   128 | lm loss: 2.132843E+00 | sop loss: 1.000413E-01 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.58 | backward-compute: 79.82 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.48
 iteration   109000/10000000 | consumed samples:     13952000 | elapsed time per iteration (ms): 249.5 | learning rate: 9.092E-05 | global batch size:   128 | lm loss: 2.128366E+00 | sop loss: 9.949399E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.78 | backward-compute: 79.81 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.45 | batch-generator: 13.74
 iteration   110000/10000000 | consumed samples:     14080000 | elapsed time per iteration (ms): 250.3 | learning rate: 9.082E-05 | global batch size:   128 | lm loss: 2.127884E+00 | sop loss: 9.832436E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.65 | backward-compute: 79.75 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.42 | batch-generator: 9.89
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 110000 | lm loss value: 2.223177E+00 | lm loss PPL: 9.236626E+00 | sop loss value: 1.059783E-01 | sop loss PPL: 1.111798E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   111000/10000000 | consumed samples:     14208000 | elapsed time per iteration (ms): 249.1 | learning rate: 9.073E-05 | global batch size:   128 | lm loss: 2.122747E+00 | sop loss: 1.003838E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.73 | backward-compute: 79.82 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 14.53
 iteration   112000/10000000 | consumed samples:     14336000 | elapsed time per iteration (ms): 248.3 | learning rate: 9.064E-05 | global batch size:   128 | lm loss: 2.123266E+00 | sop loss: 9.842408E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.63 | backward-compute: 79.82 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 16.95
 iteration   113000/10000000 | consumed samples:     14464000 | elapsed time per iteration (ms): 249.4 | learning rate: 9.055E-05 | global batch size:   128 | lm loss: 2.117842E+00 | sop loss: 9.988504E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.76 | backward-compute: 79.83 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 19.79
 iteration   114000/10000000 | consumed samples:     14592000 | elapsed time per iteration (ms): 248.4 | learning rate: 9.046E-05 | global batch size:   128 | lm loss: 2.117698E+00 | sop loss: 9.979151E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.59 | backward-compute: 79.87 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 22.82
 iteration   115000/10000000 | consumed samples:     14720000 | elapsed time per iteration (ms): 247.8 | learning rate: 9.037E-05 | global batch size:   128 | lm loss: 2.118414E+00 | sop loss: 9.828743E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.24 | backward-compute: 79.83 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 15.84
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 115000 | lm loss value: 2.132775E+00 | lm loss PPL: 8.438251E+00 | sop loss value: 1.103718E-01 | sop loss PPL: 1.116693E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   116000/10000000 | consumed samples:     14848000 | elapsed time per iteration (ms): 250.3 | learning rate: 9.027E-05 | global batch size:   128 | lm loss: 2.113028E+00 | sop loss: 9.906948E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.97 | backward-compute: 79.83 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.38
 iteration   117000/10000000 | consumed samples:     14976000 | elapsed time per iteration (ms): 249.2 | learning rate: 9.018E-05 | global batch size:   128 | lm loss: 2.111229E+00 | sop loss: 9.904699E-02 | loss scale: 65536.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.36 | backward-compute: 79.85 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 34.57
 iteration   118000/10000000 | consumed samples:     15104000 | elapsed time per iteration (ms): 247.4 | learning rate: 9.009E-05 | global batch size:   128 | lm loss: 2.108816E+00 | sop loss: 9.675197E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.70 | backward-compute: 79.87 | backward-params-all-reduce: 14.54 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.26 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.72 | batch-generator: 16.83
 iteration   119000/10000000 | consumed samples:     15232000 | elapsed time per iteration (ms): 248.1 | learning rate: 9.000E-05 | global batch size:   128 | lm loss: 2.105272E+00 | sop loss: 1.003783E-01 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.55 | backward-compute: 79.82 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 14.06
 iteration   120000/10000000 | consumed samples:     15360000 | elapsed time per iteration (ms): 247.6 | learning rate: 8.991E-05 | global batch size:   128 | lm loss: 2.102354E+00 | sop loss: 9.794706E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.83 | backward-compute: 79.91 | backward-params-all-reduce: 14.57 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.27 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.73 | batch-generator: 14.77
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 120000 | lm loss value: 2.126715E+00 | lm loss PPL: 8.387269E+00 | sop loss value: 1.276803E-01 | sop loss PPL: 1.136190E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   121000/10000000 | consumed samples:     15488000 | elapsed time per iteration (ms): 248.6 | learning rate: 8.982E-05 | global batch size:   128 | lm loss: 2.103167E+00 | sop loss: 9.719318E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.95 | backward-compute: 79.84 | backward-params-all-reduce: 14.29 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.44 | batch-generator: 15.60
 iteration   122000/10000000 | consumed samples:     15616000 | elapsed time per iteration (ms): 248.0 | learning rate: 8.972E-05 | global batch size:   128 | lm loss: 2.099419E+00 | sop loss: 9.753393E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.62 | backward-compute: 79.83 | backward-params-all-reduce: 14.37 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.19 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.63 | batch-generator: 15.85
 iteration   123000/10000000 | consumed samples:     15744000 | elapsed time per iteration (ms): 247.5 | learning rate: 8.963E-05 | global batch size:   128 | lm loss: 2.097893E+00 | sop loss: 9.607541E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.06 | backward-compute: 79.83 | backward-params-all-reduce: 14.48 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.24 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.67 | batch-generator: 15.30
 iteration   124000/10000000 | consumed samples:     15872000 | elapsed time per iteration (ms): 249.2 | learning rate: 8.954E-05 | global batch size:   128 | lm loss: 2.095810E+00 | sop loss: 9.605933E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.53 | backward-compute: 79.84 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 13.68
 iteration   125000/10000000 | consumed samples:     16000000 | elapsed time per iteration (ms): 249.4 | learning rate: 8.945E-05 | global batch size:   128 | lm loss: 2.089934E+00 | sop loss: 9.623935E-02 | loss scale: 65536.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.47 | backward-compute: 79.79 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 16.36
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 125000 | lm loss value: 2.121608E+00 | lm loss PPL: 8.344545E+00 | sop loss value: 1.010446E-01 | sop loss PPL: 1.106326E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   126000/10000000 | consumed samples:     16128000 | elapsed time per iteration (ms): 247.8 | learning rate: 8.936E-05 | global batch size:   128 | lm loss: 2.091442E+00 | sop loss: 9.652995E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.73 | backward-compute: 79.80 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 16.22
 iteration   127000/10000000 | consumed samples:     16256000 | elapsed time per iteration (ms): 248.1 | learning rate: 8.927E-05 | global batch size:   128 | lm loss: 2.088023E+00 | sop loss: 9.729661E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.36 | backward-compute: 79.81 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 15.82
 iteration   128000/10000000 | consumed samples:     16384000 | elapsed time per iteration (ms): 247.7 | learning rate: 8.917E-05 | global batch size:   128 | lm loss: 2.086686E+00 | sop loss: 9.695677E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.04 | backward-compute: 79.80 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 16.90
 iteration   129000/10000000 | consumed samples:     16512000 | elapsed time per iteration (ms): 247.9 | learning rate: 8.908E-05 | global batch size:   128 | lm loss: 2.083494E+00 | sop loss: 9.373923E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.77 | backward-compute: 79.85 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.60 | batch-generator: 16.93
 iteration   130000/10000000 | consumed samples:     16640000 | elapsed time per iteration (ms): 246.3 | learning rate: 8.899E-05 | global batch size:   128 | lm loss: 2.082772E+00 | sop loss: 9.748522E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.62 | backward-compute: 79.84 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 16.35
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 130000 | lm loss value: 2.134355E+00 | lm loss PPL: 8.451590E+00 | sop loss value: 1.040241E-01 | sop loss PPL: 1.109627E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   131000/10000000 | consumed samples:     16768000 | elapsed time per iteration (ms): 248.2 | learning rate: 8.890E-05 | global batch size:   128 | lm loss: 2.078267E+00 | sop loss: 9.711822E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.05 | backward-compute: 79.81 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 17.19
 iteration   132000/10000000 | consumed samples:     16896000 | elapsed time per iteration (ms): 247.9 | learning rate: 8.881E-05 | global batch size:   128 | lm loss: 2.079938E+00 | sop loss: 9.473173E-02 | loss scale: 65536.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.37 | backward-compute: 79.82 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 15.30
 iteration   133000/10000000 | consumed samples:     17024000 | elapsed time per iteration (ms): 246.8 | learning rate: 8.872E-05 | global batch size:   128 | lm loss: 2.076722E+00 | sop loss: 9.565512E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.26 | backward-compute: 79.80 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.29 | batch-generator: 14.18
 iteration   134000/10000000 | consumed samples:     17152000 | elapsed time per iteration (ms): 245.3 | learning rate: 8.862E-05 | global batch size:   128 | lm loss: 2.073215E+00 | sop loss: 9.452623E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.55 | backward-compute: 79.83 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 13.79
 iteration   135000/10000000 | consumed samples:     17280000 | elapsed time per iteration (ms): 250.2 | learning rate: 8.853E-05 | global batch size:   128 | lm loss: 2.072303E+00 | sop loss: 9.304768E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.70 | backward-compute: 79.78 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 18.21
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 135000 | lm loss value: 2.133546E+00 | lm loss PPL: 8.444762E+00 | sop loss value: 9.644200E-02 | sop loss PPL: 1.101246E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   136000/10000000 | consumed samples:     17408000 | elapsed time per iteration (ms): 249.6 | learning rate: 8.844E-05 | global batch size:   128 | lm loss: 2.072785E+00 | sop loss: 9.327945E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.30 | backward-compute: 79.79 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 15.21
 iteration   137000/10000000 | consumed samples:     17536000 | elapsed time per iteration (ms): 245.8 | learning rate: 8.835E-05 | global batch size:   128 | lm loss: 2.071466E+00 | sop loss: 9.447084E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.22 | backward-compute: 79.76 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 12.77
 iteration   138000/10000000 | consumed samples:     17664000 | elapsed time per iteration (ms): 246.9 | learning rate: 8.826E-05 | global batch size:   128 | lm loss: 2.067048E+00 | sop loss: 9.321331E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.03 | backward-compute: 79.78 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 19.43
 iteration   139000/10000000 | consumed samples:     17792000 | elapsed time per iteration (ms): 246.7 | learning rate: 8.817E-05 | global batch size:   128 | lm loss: 2.065881E+00 | sop loss: 9.262731E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.67 | backward-compute: 79.76 | backward-params-all-reduce: 14.29 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.55 | batch-generator: 13.66
 iteration   140000/10000000 | consumed samples:     17920000 | elapsed time per iteration (ms): 247.7 | learning rate: 8.807E-05 | global batch size:   128 | lm loss: 2.062829E+00 | sop loss: 9.375984E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.64 | backward-compute: 79.85 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 16.34
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 140000 | lm loss value: 2.116161E+00 | lm loss PPL: 8.299216E+00 | sop loss value: 9.954078E-02 | sop loss PPL: 1.104664E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   141000/10000000 | consumed samples:     18048000 | elapsed time per iteration (ms): 250.8 | learning rate: 8.798E-05 | global batch size:   128 | lm loss: 2.062917E+00 | sop loss: 9.402945E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.54 | backward-compute: 79.79 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 17.89
 iteration   142000/10000000 | consumed samples:     18176000 | elapsed time per iteration (ms): 248.0 | learning rate: 8.789E-05 | global batch size:   128 | lm loss: 2.058885E+00 | sop loss: 9.265916E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.20 | backward-compute: 79.82 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.26
 iteration   143000/10000000 | consumed samples:     18304000 | elapsed time per iteration (ms): 247.7 | learning rate: 8.780E-05 | global batch size:   128 | lm loss: 2.057060E+00 | sop loss: 9.230750E-02 | loss scale: 65536.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.78 | backward-compute: 79.87 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 26.28
 iteration   144000/10000000 | consumed samples:     18432000 | elapsed time per iteration (ms): 247.1 | learning rate: 8.771E-05 | global batch size:   128 | lm loss: 2.058766E+00 | sop loss: 9.276330E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.36 | backward-compute: 79.86 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 19.59
 iteration   145000/10000000 | consumed samples:     18560000 | elapsed time per iteration (ms): 248.5 | learning rate: 8.762E-05 | global batch size:   128 | lm loss: 2.055819E+00 | sop loss: 9.054234E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.89 | backward-compute: 79.90 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 12.71
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 145000 | lm loss value: 2.110596E+00 | lm loss PPL: 8.253158E+00 | sop loss value: 8.260259E-02 | sop loss PPL: 1.086110E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   146000/10000000 | consumed samples:     18688000 | elapsed time per iteration (ms): 248.5 | learning rate: 8.752E-05 | global batch size:   128 | lm loss: 2.054820E+00 | sop loss: 9.310504E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.96 | backward-compute: 79.85 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.32
 iteration   147000/10000000 | consumed samples:     18816000 | elapsed time per iteration (ms): 246.5 | learning rate: 8.743E-05 | global batch size:   128 | lm loss: 2.052626E+00 | sop loss: 9.399364E-02 | loss scale: 65536.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.76 | backward-compute: 79.83 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.43 | batch-generator: 14.47
 iteration   148000/10000000 | consumed samples:     18944000 | elapsed time per iteration (ms): 246.2 | learning rate: 8.734E-05 | global batch size:   128 | lm loss: 2.056463E+00 | sop loss: 9.189763E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.53 | backward-compute: 79.78 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 12.24
 iteration   149000/10000000 | consumed samples:     19072000 | elapsed time per iteration (ms): 245.5 | learning rate: 8.725E-05 | global batch size:   128 | lm loss: 2.047076E+00 | sop loss: 9.243495E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.94 | backward-compute: 79.81 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 14.12
 iteration   150000/10000000 | consumed samples:     19200000 | elapsed time per iteration (ms): 247.3 | learning rate: 8.716E-05 | global batch size:   128 | lm loss: 2.045328E+00 | sop loss: 9.296941E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.23 | backward-compute: 79.83 | backward-params-all-reduce: 14.29 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 14.84
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 150000 | lm loss value: 2.074815E+00 | lm loss PPL: 7.963073E+00 | sop loss value: 9.960629E-02 | sop loss PPL: 1.104736E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration  150000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration  150000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2319.12
 iteration   151000/10000000 | consumed samples:     19328000 | elapsed time per iteration (ms): 252.6 | learning rate: 8.707E-05 | global batch size:   128 | lm loss: 2.045811E+00 | sop loss: 9.105554E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.88 | backward-compute: 79.84 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 17.30
 iteration   152000/10000000 | consumed samples:     19456000 | elapsed time per iteration (ms): 247.2 | learning rate: 8.697E-05 | global batch size:   128 | lm loss: 2.045142E+00 | sop loss: 9.133055E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.60 | backward-compute: 79.83 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 18.38
 iteration   153000/10000000 | consumed samples:     19584000 | elapsed time per iteration (ms): 248.4 | learning rate: 8.688E-05 | global batch size:   128 | lm loss: 2.040461E+00 | sop loss: 9.026707E-02 | loss scale: 65536.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.69 | backward-compute: 79.80 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 17.91
 iteration   154000/10000000 | consumed samples:     19712000 | elapsed time per iteration (ms): 250.4 | learning rate: 8.679E-05 | global batch size:   128 | lm loss: 2.041939E+00 | sop loss: 9.080857E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.69 | backward-compute: 79.81 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 13.50
 iteration   155000/10000000 | consumed samples:     19840000 | elapsed time per iteration (ms): 249.2 | learning rate: 8.670E-05 | global batch size:   128 | lm loss: 2.038105E+00 | sop loss: 9.049258E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.26 | backward-compute: 79.78 | backward-params-all-reduce: 14.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 15.02
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 155000 | lm loss value: 2.086477E+00 | lm loss PPL: 8.056484E+00 | sop loss value: 9.752686E-02 | sop loss PPL: 1.102441E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   156000/10000000 | consumed samples:     19968000 | elapsed time per iteration (ms): 247.6 | learning rate: 8.661E-05 | global batch size:   128 | lm loss: 2.035236E+00 | sop loss: 9.213356E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.99 | backward-compute: 79.83 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.52 | batch-generator: 20.54
 iteration   157000/10000000 | consumed samples:     20096000 | elapsed time per iteration (ms): 247.2 | learning rate: 8.651E-05 | global batch size:   128 | lm loss: 2.035309E+00 | sop loss: 9.100080E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.57 | backward-compute: 79.82 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 16.91
 iteration   158000/10000000 | consumed samples:     20224000 | elapsed time per iteration (ms): 248.1 | learning rate: 8.642E-05 | global batch size:   128 | lm loss: 2.034743E+00 | sop loss: 9.279902E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.38 | backward-compute: 79.80 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 15.17
 iteration   159000/10000000 | consumed samples:     20352000 | elapsed time per iteration (ms): 246.4 | learning rate: 8.633E-05 | global batch size:   128 | lm loss: 2.033360E+00 | sop loss: 9.016778E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.85 | backward-compute: 79.76 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 14.52
 iteration   160000/10000000 | consumed samples:     20480000 | elapsed time per iteration (ms): 249.0 | learning rate: 8.624E-05 | global batch size:   128 | lm loss: 2.031833E+00 | sop loss: 8.872871E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.20 | backward-compute: 79.70 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.45 | batch-generator: 14.03
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 160000 | lm loss value: 2.124839E+00 | lm loss PPL: 8.371546E+00 | sop loss value: 1.139044E-01 | sop loss PPL: 1.120645E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   161000/10000000 | consumed samples:     20608000 | elapsed time per iteration (ms): 250.0 | learning rate: 8.615E-05 | global batch size:   128 | lm loss: 2.031924E+00 | sop loss: 9.062948E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.29 | backward-compute: 79.76 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.53 | batch-generator: 16.25
 iteration   162000/10000000 | consumed samples:     20736000 | elapsed time per iteration (ms): 247.5 | learning rate: 8.606E-05 | global batch size:   128 | lm loss: 2.032610E+00 | sop loss: 8.804615E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.07 | backward-compute: 79.77 | backward-params-all-reduce: 14.45 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.22 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.65 | batch-generator: 13.27
 iteration   163000/10000000 | consumed samples:     20864000 | elapsed time per iteration (ms): 247.5 | learning rate: 8.596E-05 | global batch size:   128 | lm loss: 2.027373E+00 | sop loss: 8.962302E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.64 | backward-compute: 79.84 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 14.88
 iteration   164000/10000000 | consumed samples:     20992000 | elapsed time per iteration (ms): 245.6 | learning rate: 8.587E-05 | global batch size:   128 | lm loss: 2.026657E+00 | sop loss: 9.038340E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.05 | backward-compute: 79.86 | backward-params-all-reduce: 14.58 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.21 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.62 | batch-generator: 14.76
 iteration   165000/10000000 | consumed samples:     21120000 | elapsed time per iteration (ms): 248.6 | learning rate: 8.578E-05 | global batch size:   128 | lm loss: 2.023609E+00 | sop loss: 8.945561E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.90 | backward-compute: 79.77 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 16.79
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 165000 | lm loss value: 2.059045E+00 | lm loss PPL: 7.838481E+00 | sop loss value: 1.116673E-01 | sop loss PPL: 1.118141E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   166000/10000000 | consumed samples:     21248000 | elapsed time per iteration (ms): 250.5 | learning rate: 8.569E-05 | global batch size:   128 | lm loss: 2.023507E+00 | sop loss: 8.876793E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.15 | backward-compute: 79.76 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.45 | batch-generator: 14.66
 iteration   167000/10000000 | consumed samples:     21376000 | elapsed time per iteration (ms): 246.2 | learning rate: 8.560E-05 | global batch size:   128 | lm loss: 2.023981E+00 | sop loss: 9.007999E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.16 | backward-compute: 79.80 | backward-params-all-reduce: 14.29 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 13.18
 iteration   168000/10000000 | consumed samples:     21504000 | elapsed time per iteration (ms): 248.8 | learning rate: 8.551E-05 | global batch size:   128 | lm loss: 2.020108E+00 | sop loss: 8.929577E-02 | loss scale: 65536.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.26 | backward-compute: 79.79 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 13.78
 iteration   169000/10000000 | consumed samples:     21632000 | elapsed time per iteration (ms): 248.7 | learning rate: 8.541E-05 | global batch size:   128 | lm loss: 2.021706E+00 | sop loss: 8.852394E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.16 | backward-compute: 79.86 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 21.26
 iteration   170000/10000000 | consumed samples:     21760000 | elapsed time per iteration (ms): 246.5 | learning rate: 8.532E-05 | global batch size:   128 | lm loss: 2.016799E+00 | sop loss: 8.859484E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.83 | backward-compute: 79.85 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 15.60
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 170000 | lm loss value: 2.012057E+00 | lm loss PPL: 7.478684E+00 | sop loss value: 8.995918E-02 | sop loss PPL: 1.094130E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   171000/10000000 | consumed samples:     21888000 | elapsed time per iteration (ms): 248.6 | learning rate: 8.523E-05 | global batch size:   128 | lm loss: 2.020077E+00 | sop loss: 9.049397E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.27 | backward-compute: 79.83 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 16.69
 iteration   172000/10000000 | consumed samples:     22016000 | elapsed time per iteration (ms): 246.5 | learning rate: 8.514E-05 | global batch size:   128 | lm loss: 2.014933E+00 | sop loss: 8.829662E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.76 | backward-compute: 79.87 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 18.23
 iteration   173000/10000000 | consumed samples:     22144000 | elapsed time per iteration (ms): 248.2 | learning rate: 8.505E-05 | global batch size:   128 | lm loss: 2.015596E+00 | sop loss: 8.832963E-02 | loss scale: 65536.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.68 | backward-compute: 79.80 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 18.38
 iteration   174000/10000000 | consumed samples:     22272000 | elapsed time per iteration (ms): 247.2 | learning rate: 8.496E-05 | global batch size:   128 | lm loss: 2.014443E+00 | sop loss: 8.991320E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.65 | backward-compute: 79.81 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 13.69
 iteration   175000/10000000 | consumed samples:     22400000 | elapsed time per iteration (ms): 247.9 | learning rate: 8.486E-05 | global batch size:   128 | lm loss: 2.011861E+00 | sop loss: 8.853007E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.40 | backward-compute: 79.76 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 13.63
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 175000 | lm loss value: 2.075327E+00 | lm loss PPL: 7.967149E+00 | sop loss value: 9.821015E-02 | sop loss PPL: 1.103195E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   176000/10000000 | consumed samples:     22528000 | elapsed time per iteration (ms): 249.8 | learning rate: 8.477E-05 | global batch size:   128 | lm loss: 2.008390E+00 | sop loss: 8.850701E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.60 | backward-compute: 79.79 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.75 | optimizer-unscale-and-check-inf: 2.24 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.29 | batch-generator: 11.50
 iteration   177000/10000000 | consumed samples:     22656000 | elapsed time per iteration (ms): 247.2 | learning rate: 8.468E-05 | global batch size:   128 | lm loss: 2.011100E+00 | sop loss: 8.814345E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.21 | backward-compute: 79.87 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.50 | batch-generator: 15.59
 iteration   178000/10000000 | consumed samples:     22784000 | elapsed time per iteration (ms): 247.5 | learning rate: 8.459E-05 | global batch size:   128 | lm loss: 2.006987E+00 | sop loss: 8.703604E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.42 | backward-compute: 79.83 | backward-params-all-reduce: 14.31 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 17.20
 iteration   179000/10000000 | consumed samples:     22912000 | elapsed time per iteration (ms): 249.0 | learning rate: 8.450E-05 | global batch size:   128 | lm loss: 2.007238E+00 | sop loss: 8.866405E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.13 | backward-compute: 79.81 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 23.71
 iteration   180000/10000000 | consumed samples:     23040000 | elapsed time per iteration (ms): 248.6 | learning rate: 8.441E-05 | global batch size:   128 | lm loss: 2.006757E+00 | sop loss: 8.769080E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.95 | backward-compute: 79.83 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.43 | batch-generator: 26.33
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 180000 | lm loss value: 2.062943E+00 | lm loss PPL: 7.869096E+00 | sop loss value: 9.978690E-02 | sop loss PPL: 1.104935E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   181000/10000000 | consumed samples:     23168000 | elapsed time per iteration (ms): 249.9 | learning rate: 8.431E-05 | global batch size:   128 | lm loss: 2.003568E+00 | sop loss: 8.711686E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.63 | backward-compute: 79.85 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.27
 iteration   182000/10000000 | consumed samples:     23296000 | elapsed time per iteration (ms): 248.9 | learning rate: 8.422E-05 | global batch size:   128 | lm loss: 2.001596E+00 | sop loss: 8.785080E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.03 | backward-compute: 79.81 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 12.83
 iteration   183000/10000000 | consumed samples:     23424000 | elapsed time per iteration (ms): 250.2 | learning rate: 8.413E-05 | global batch size:   128 | lm loss: 2.001021E+00 | sop loss: 8.526692E-02 | loss scale: 65536.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.60 | backward-compute: 79.79 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.94
 iteration   184000/10000000 | consumed samples:     23552000 | elapsed time per iteration (ms): 249.7 | learning rate: 8.404E-05 | global batch size:   128 | lm loss: 2.003463E+00 | sop loss: 8.793014E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.89 | backward-compute: 79.80 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.45 | batch-generator: 17.20
 iteration   185000/10000000 | consumed samples:     23680000 | elapsed time per iteration (ms): 248.2 | learning rate: 8.395E-05 | global batch size:   128 | lm loss: 2.001642E+00 | sop loss: 8.622548E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.40 | backward-compute: 79.81 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 14.56
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 185000 | lm loss value: 2.042113E+00 | lm loss PPL: 7.706879E+00 | sop loss value: 1.046164E-01 | sop loss PPL: 1.110285E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   186000/10000000 | consumed samples:     23808000 | elapsed time per iteration (ms): 248.4 | learning rate: 8.386E-05 | global batch size:   128 | lm loss: 1.995865E+00 | sop loss: 8.676885E-02 | loss scale: 65536.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.72 | backward-compute: 79.82 | backward-params-all-reduce: 14.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 11.21
 iteration   187000/10000000 | consumed samples:     23936000 | elapsed time per iteration (ms): 248.3 | learning rate: 8.376E-05 | global batch size:   128 | lm loss: 1.999059E+00 | sop loss: 8.673904E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.24 | backward-compute: 79.81 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 11.85
 iteration   188000/10000000 | consumed samples:     24064000 | elapsed time per iteration (ms): 249.1 | learning rate: 8.367E-05 | global batch size:   128 | lm loss: 1.995295E+00 | sop loss: 8.629750E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.51 | backward-compute: 79.77 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 14.14
 iteration   189000/10000000 | consumed samples:     24192000 | elapsed time per iteration (ms): 247.5 | learning rate: 8.358E-05 | global batch size:   128 | lm loss: 1.996183E+00 | sop loss: 8.672818E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.89 | backward-compute: 79.77 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 20.59
 iteration   190000/10000000 | consumed samples:     24320000 | elapsed time per iteration (ms): 248.7 | learning rate: 8.349E-05 | global batch size:   128 | lm loss: 1.991558E+00 | sop loss: 8.627598E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.11 | backward-compute: 79.82 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 25.77
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 190000 | lm loss value: 2.016316E+00 | lm loss PPL: 7.510604E+00 | sop loss value: 1.075963E-01 | sop loss PPL: 1.113598E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   191000/10000000 | consumed samples:     24448000 | elapsed time per iteration (ms): 248.9 | learning rate: 8.340E-05 | global batch size:   128 | lm loss: 1.992609E+00 | sop loss: 8.692377E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.91 | backward-compute: 79.83 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 16.12
 iteration   192000/10000000 | consumed samples:     24576000 | elapsed time per iteration (ms): 249.8 | learning rate: 8.331E-05 | global batch size:   128 | lm loss: 1.988375E+00 | sop loss: 8.566851E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.23 | backward-compute: 79.77 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 19.43
 iteration   193000/10000000 | consumed samples:     24704000 | elapsed time per iteration (ms): 249.5 | learning rate: 8.321E-05 | global batch size:   128 | lm loss: 1.988612E+00 | sop loss: 8.796955E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.81 | backward-compute: 79.74 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 13.65
 iteration   194000/10000000 | consumed samples:     24832000 | elapsed time per iteration (ms): 247.5 | learning rate: 8.312E-05 | global batch size:   128 | lm loss: 1.993852E+00 | sop loss: 8.681496E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.78 | backward-compute: 79.77 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.68
 iteration   195000/10000000 | consumed samples:     24960000 | elapsed time per iteration (ms): 249.0 | learning rate: 8.303E-05 | global batch size:   128 | lm loss: 1.989978E+00 | sop loss: 8.497361E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.28 | backward-compute: 79.80 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.35
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 195000 | lm loss value: 2.005286E+00 | lm loss PPL: 7.428221E+00 | sop loss value: 1.102628E-01 | sop loss PPL: 1.116571E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   196000/10000000 | consumed samples:     25088000 | elapsed time per iteration (ms): 249.6 | learning rate: 8.294E-05 | global batch size:   128 | lm loss: 1.985227E+00 | sop loss: 8.602287E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.22 | backward-compute: 79.74 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.45
 iteration   197000/10000000 | consumed samples:     25216000 | elapsed time per iteration (ms): 247.6 | learning rate: 8.285E-05 | global batch size:   128 | lm loss: 1.984810E+00 | sop loss: 8.621041E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.94 | backward-compute: 79.88 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 12.66
 iteration   198000/10000000 | consumed samples:     25344000 | elapsed time per iteration (ms): 249.0 | learning rate: 8.275E-05 | global batch size:   128 | lm loss: 1.983495E+00 | sop loss: 8.496185E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.39 | backward-compute: 79.77 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 11.17
 iteration   199000/10000000 | consumed samples:     25472000 | elapsed time per iteration (ms): 247.7 | learning rate: 8.266E-05 | global batch size:   128 | lm loss: 1.980789E+00 | sop loss: 8.622677E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.20 | backward-compute: 79.74 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 13.81
 iteration   200000/10000000 | consumed samples:     25600000 | elapsed time per iteration (ms): 248.5 | learning rate: 8.257E-05 | global batch size:   128 | lm loss: 1.983991E+00 | sop loss: 8.470622E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.87 | backward-compute: 79.82 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 14.91
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 200000 | lm loss value: 2.025915E+00 | lm loss PPL: 7.583046E+00 | sop loss value: 9.962578E-02 | sop loss PPL: 1.104757E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration  200000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration  200000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2301.40
 iteration   201000/10000000 | consumed samples:     25728000 | elapsed time per iteration (ms): 252.5 | learning rate: 8.248E-05 | global batch size:   128 | lm loss: 1.978543E+00 | sop loss: 8.506637E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.07 | backward-compute: 79.77 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 15.65
 iteration   202000/10000000 | consumed samples:     25856000 | elapsed time per iteration (ms): 250.7 | learning rate: 8.239E-05 | global batch size:   128 | lm loss: 1.982908E+00 | sop loss: 8.681140E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.18 | backward-compute: 79.75 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 14.26
 iteration   203000/10000000 | consumed samples:     25984000 | elapsed time per iteration (ms): 247.6 | learning rate: 8.230E-05 | global batch size:   128 | lm loss: 1.980678E+00 | sop loss: 8.495392E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.06 | backward-compute: 79.81 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 16.38
 iteration   204000/10000000 | consumed samples:     26112000 | elapsed time per iteration (ms): 249.7 | learning rate: 8.220E-05 | global batch size:   128 | lm loss: 1.980084E+00 | sop loss: 8.455715E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.39 | backward-compute: 79.85 | backward-params-all-reduce: 14.38 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.56 | batch-generator: 14.44
 iteration   205000/10000000 | consumed samples:     26240000 | elapsed time per iteration (ms): 250.6 | learning rate: 8.211E-05 | global batch size:   128 | lm loss: 1.974943E+00 | sop loss: 8.365946E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.93 | backward-compute: 79.77 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.27
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 205000 | lm loss value: 2.059005E+00 | lm loss PPL: 7.838163E+00 | sop loss value: 1.101867E-01 | sop loss PPL: 1.116486E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   206000/10000000 | consumed samples:     26368000 | elapsed time per iteration (ms): 248.3 | learning rate: 8.202E-05 | global batch size:   128 | lm loss: 1.971965E+00 | sop loss: 8.659270E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.77 | backward-compute: 79.79 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 13.18
 iteration   207000/10000000 | consumed samples:     26496000 | elapsed time per iteration (ms): 249.8 | learning rate: 8.193E-05 | global batch size:   128 | lm loss: 1.970204E+00 | sop loss: 8.511334E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.11 | backward-compute: 79.81 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.67
 iteration   208000/10000000 | consumed samples:     26624000 | elapsed time per iteration (ms): 249.5 | learning rate: 8.184E-05 | global batch size:   128 | lm loss: 1.969790E+00 | sop loss: 8.532683E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.89 | backward-compute: 79.78 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 17.46
 iteration   209000/10000000 | consumed samples:     26752000 | elapsed time per iteration (ms): 249.8 | learning rate: 8.175E-05 | global batch size:   128 | lm loss: 1.971394E+00 | sop loss: 8.386053E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.23 | backward-compute: 79.79 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 19.52
 iteration   210000/10000000 | consumed samples:     26880000 | elapsed time per iteration (ms): 250.9 | learning rate: 8.165E-05 | global batch size:   128 | lm loss: 1.971759E+00 | sop loss: 8.436406E-02 | loss scale: 65536.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.22 | backward-compute: 79.80 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 12.50
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 210000 | lm loss value: 2.009943E+00 | lm loss PPL: 7.462892E+00 | sop loss value: 8.442767E-02 | sop loss PPL: 1.088094E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   211000/10000000 | consumed samples:     27008000 | elapsed time per iteration (ms): 250.0 | learning rate: 8.156E-05 | global batch size:   128 | lm loss: 1.970544E+00 | sop loss: 8.418029E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.84 | backward-compute: 79.76 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.30 | batch-generator: 13.96
 iteration   212000/10000000 | consumed samples:     27136000 | elapsed time per iteration (ms): 248.9 | learning rate: 8.147E-05 | global batch size:   128 | lm loss: 1.971343E+00 | sop loss: 8.554372E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.39 | backward-compute: 79.87 | backward-params-all-reduce: 13.86 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 17.26
 iteration   213000/10000000 | consumed samples:     27264000 | elapsed time per iteration (ms): 247.9 | learning rate: 8.138E-05 | global batch size:   128 | lm loss: 1.968496E+00 | sop loss: 8.346092E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.19 | backward-compute: 79.81 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 14.31
 iteration   214000/10000000 | consumed samples:     27392000 | elapsed time per iteration (ms): 249.1 | learning rate: 8.129E-05 | global batch size:   128 | lm loss: 1.965804E+00 | sop loss: 8.434716E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.31 | backward-compute: 79.81 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 15.26
 iteration   215000/10000000 | consumed samples:     27520000 | elapsed time per iteration (ms): 250.3 | learning rate: 8.120E-05 | global batch size:   128 | lm loss: 1.969102E+00 | sop loss: 8.338535E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.69 | backward-compute: 79.80 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 12.02
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 215000 | lm loss value: 2.015234E+00 | lm loss PPL: 7.502481E+00 | sop loss value: 1.236537E-01 | sop loss PPL: 1.131624E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   216000/10000000 | consumed samples:     27648000 | elapsed time per iteration (ms): 246.6 | learning rate: 8.110E-05 | global batch size:   128 | lm loss: 1.966688E+00 | sop loss: 8.223536E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.12 | backward-compute: 79.82 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.40 | batch-generator: 17.09
 iteration   217000/10000000 | consumed samples:     27776000 | elapsed time per iteration (ms): 249.7 | learning rate: 8.101E-05 | global batch size:   128 | lm loss: 1.962405E+00 | sop loss: 8.336842E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.96 | backward-compute: 79.81 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 16.16
 iteration   218000/10000000 | consumed samples:     27904000 | elapsed time per iteration (ms): 247.4 | learning rate: 8.092E-05 | global batch size:   128 | lm loss: 1.961501E+00 | sop loss: 8.474259E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.67 | backward-compute: 79.82 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 15.74
 iteration   219000/10000000 | consumed samples:     28032000 | elapsed time per iteration (ms): 249.4 | learning rate: 8.083E-05 | global batch size:   128 | lm loss: 1.963717E+00 | sop loss: 8.362146E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.83 | backward-compute: 79.74 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 11.20
 iteration   220000/10000000 | consumed samples:     28160000 | elapsed time per iteration (ms): 248.0 | learning rate: 8.074E-05 | global batch size:   128 | lm loss: 1.963860E+00 | sop loss: 8.266518E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.93 | backward-compute: 79.80 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.52 | batch-generator: 16.10
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 220000 | lm loss value: 2.013452E+00 | lm loss PPL: 7.489127E+00 | sop loss value: 1.174341E-01 | sop loss PPL: 1.124608E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   221000/10000000 | consumed samples:     28288000 | elapsed time per iteration (ms): 250.7 | learning rate: 8.065E-05 | global batch size:   128 | lm loss: 1.959663E+00 | sop loss: 8.261998E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.30 | backward-compute: 79.81 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.42
 iteration   222000/10000000 | consumed samples:     28416000 | elapsed time per iteration (ms): 247.6 | learning rate: 8.055E-05 | global batch size:   128 | lm loss: 1.958564E+00 | sop loss: 8.249125E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.92 | backward-compute: 79.86 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 16.94
 iteration   223000/10000000 | consumed samples:     28544000 | elapsed time per iteration (ms): 245.6 | learning rate: 8.046E-05 | global batch size:   128 | lm loss: 1.959092E+00 | sop loss: 8.208440E-02 | loss scale: 8192.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.52 | backward-compute: 79.79 | backward-params-all-reduce: 14.28 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.54 | batch-generator: 14.25
 iteration   224000/10000000 | consumed samples:     28672000 | elapsed time per iteration (ms): 247.4 | learning rate: 8.037E-05 | global batch size:   128 | lm loss: 1.959547E+00 | sop loss: 8.341972E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.83 | backward-compute: 79.77 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 15.76
 iteration   225000/10000000 | consumed samples:     28800000 | elapsed time per iteration (ms): 249.5 | learning rate: 8.028E-05 | global batch size:   128 | lm loss: 1.956607E+00 | sop loss: 8.342774E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.84 | backward-compute: 79.80 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.44 | batch-generator: 21.07
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 225000 | lm loss value: 1.984612E+00 | lm loss PPL: 7.276220E+00 | sop loss value: 1.072302E-01 | sop loss PPL: 1.113190E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   226000/10000000 | consumed samples:     28928000 | elapsed time per iteration (ms): 248.8 | learning rate: 8.019E-05 | global batch size:   128 | lm loss: 1.956051E+00 | sop loss: 8.218435E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.63 | backward-compute: 79.78 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 14.54
 iteration   227000/10000000 | consumed samples:     29056000 | elapsed time per iteration (ms): 248.6 | learning rate: 8.010E-05 | global batch size:   128 | lm loss: 1.953782E+00 | sop loss: 8.365874E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.08 | backward-compute: 79.80 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 15.66
 iteration   228000/10000000 | consumed samples:     29184000 | elapsed time per iteration (ms): 247.7 | learning rate: 8.000E-05 | global batch size:   128 | lm loss: 1.950620E+00 | sop loss: 8.212157E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.03 | backward-compute: 79.83 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 17.54
 iteration   229000/10000000 | consumed samples:     29312000 | elapsed time per iteration (ms): 247.3 | learning rate: 7.991E-05 | global batch size:   128 | lm loss: 1.958834E+00 | sop loss: 8.213536E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.53 | backward-compute: 79.82 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 13.93
 iteration   230000/10000000 | consumed samples:     29440000 | elapsed time per iteration (ms): 247.6 | learning rate: 7.982E-05 | global batch size:   128 | lm loss: 1.951939E+00 | sop loss: 8.158770E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.71 | backward-compute: 79.79 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.11
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 230000 | lm loss value: 2.013987E+00 | lm loss PPL: 7.493135E+00 | sop loss value: 1.005151E-01 | sop loss PPL: 1.105740E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   231000/10000000 | consumed samples:     29568000 | elapsed time per iteration (ms): 250.5 | learning rate: 7.973E-05 | global batch size:   128 | lm loss: 1.954208E+00 | sop loss: 8.321918E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.74 | backward-compute: 79.83 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 15.22
 iteration   232000/10000000 | consumed samples:     29696000 | elapsed time per iteration (ms): 250.8 | learning rate: 7.964E-05 | global batch size:   128 | lm loss: 1.952362E+00 | sop loss: 8.377077E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.19 | backward-compute: 79.77 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 24.00
 iteration   233000/10000000 | consumed samples:     29824000 | elapsed time per iteration (ms): 248.6 | learning rate: 7.954E-05 | global batch size:   128 | lm loss: 1.947651E+00 | sop loss: 8.164145E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.09 | backward-compute: 79.79 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 18.89
 iteration   234000/10000000 | consumed samples:     29952000 | elapsed time per iteration (ms): 248.7 | learning rate: 7.945E-05 | global batch size:   128 | lm loss: 1.950763E+00 | sop loss: 8.236596E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.98 | backward-compute: 79.81 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 14.77
 iteration   235000/10000000 | consumed samples:     30080000 | elapsed time per iteration (ms): 248.0 | learning rate: 7.936E-05 | global batch size:   128 | lm loss: 1.945883E+00 | sop loss: 8.023234E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.86 | backward-compute: 79.77 | backward-params-all-reduce: 14.38 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.54 | batch-generator: 17.97
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 235000 | lm loss value: 2.022636E+00 | lm loss PPL: 7.558220E+00 | sop loss value: 1.039809E-01 | sop loss PPL: 1.109579E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   236000/10000000 | consumed samples:     30208000 | elapsed time per iteration (ms): 250.8 | learning rate: 7.927E-05 | global batch size:   128 | lm loss: 1.949868E+00 | sop loss: 8.091825E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.68 | backward-compute: 79.78 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 23.58
 iteration   237000/10000000 | consumed samples:     30336000 | elapsed time per iteration (ms): 248.0 | learning rate: 7.918E-05 | global batch size:   128 | lm loss: 1.943692E+00 | sop loss: 8.222664E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.49 | backward-compute: 79.83 | backward-params-all-reduce: 13.92 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.76 | optimizer-unscale-and-check-inf: 2.24 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.27 | batch-generator: 16.67
 iteration   238000/10000000 | consumed samples:     30464000 | elapsed time per iteration (ms): 246.9 | learning rate: 7.909E-05 | global batch size:   128 | lm loss: 1.943907E+00 | sop loss: 8.190910E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.41 | backward-compute: 79.78 | backward-params-all-reduce: 13.91 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 18.37
 iteration   239000/10000000 | consumed samples:     30592000 | elapsed time per iteration (ms): 247.8 | learning rate: 7.899E-05 | global batch size:   128 | lm loss: 1.943436E+00 | sop loss: 8.174552E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.85 | backward-compute: 79.85 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 16.47
 iteration   240000/10000000 | consumed samples:     30720000 | elapsed time per iteration (ms): 246.4 | learning rate: 7.890E-05 | global batch size:   128 | lm loss: 1.941653E+00 | sop loss: 7.982720E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.92 | backward-compute: 79.78 | backward-params-all-reduce: 14.58 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.20 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.62 | batch-generator: 16.60
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 240000 | lm loss value: 1.951882E+00 | lm loss PPL: 7.041928E+00 | sop loss value: 9.122337E-02 | sop loss PPL: 1.095514E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   241000/10000000 | consumed samples:     30848000 | elapsed time per iteration (ms): 250.3 | learning rate: 7.881E-05 | global batch size:   128 | lm loss: 1.943531E+00 | sop loss: 8.197940E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.09 | backward-compute: 79.84 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 21.43
 iteration   242000/10000000 | consumed samples:     30976000 | elapsed time per iteration (ms): 248.5 | learning rate: 7.872E-05 | global batch size:   128 | lm loss: 1.939181E+00 | sop loss: 8.323343E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.92 | backward-compute: 79.80 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.30 | batch-generator: 15.35
 iteration   243000/10000000 | consumed samples:     31104000 | elapsed time per iteration (ms): 248.2 | learning rate: 7.863E-05 | global batch size:   128 | lm loss: 1.940903E+00 | sop loss: 8.150538E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.09 | backward-compute: 79.79 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.53 | batch-generator: 14.70
 iteration   244000/10000000 | consumed samples:     31232000 | elapsed time per iteration (ms): 248.5 | learning rate: 7.854E-05 | global batch size:   128 | lm loss: 1.941455E+00 | sop loss: 8.227833E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.46 | backward-compute: 79.86 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 16.42
 iteration   245000/10000000 | consumed samples:     31360000 | elapsed time per iteration (ms): 247.2 | learning rate: 7.844E-05 | global batch size:   128 | lm loss: 1.940483E+00 | sop loss: 8.135543E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.86 | backward-compute: 79.91 | backward-params-all-reduce: 14.92 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.88 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.37 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.89 | batch-generator: 13.46
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 245000 | lm loss value: 1.986924E+00 | lm loss PPL: 7.293063E+00 | sop loss value: 1.037585E-01 | sop loss PPL: 1.109333E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   246000/10000000 | consumed samples:     31488000 | elapsed time per iteration (ms): 249.5 | learning rate: 7.835E-05 | global batch size:   128 | lm loss: 1.940600E+00 | sop loss: 8.097616E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.08 | backward-compute: 79.75 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 15.14
 iteration   247000/10000000 | consumed samples:     31616000 | elapsed time per iteration (ms): 248.3 | learning rate: 7.826E-05 | global batch size:   128 | lm loss: 1.937965E+00 | sop loss: 8.153065E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.69 | backward-compute: 79.84 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 24.84
 iteration   248000/10000000 | consumed samples:     31744000 | elapsed time per iteration (ms): 249.1 | learning rate: 7.817E-05 | global batch size:   128 | lm loss: 1.940282E+00 | sop loss: 8.126754E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.50 | backward-compute: 79.91 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 16.06
 iteration   249000/10000000 | consumed samples:     31872000 | elapsed time per iteration (ms): 248.5 | learning rate: 7.808E-05 | global batch size:   128 | lm loss: 1.938359E+00 | sop loss: 8.313123E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.39 | backward-compute: 79.81 | backward-params-all-reduce: 14.31 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 16.91
 iteration   250000/10000000 | consumed samples:     32000000 | elapsed time per iteration (ms): 249.2 | learning rate: 7.799E-05 | global batch size:   128 | lm loss: 1.933717E+00 | sop loss: 8.181126E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.57 | backward-compute: 79.79 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 14.31
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 250000 | lm loss value: 1.975278E+00 | lm loss PPL: 7.208620E+00 | sop loss value: 9.572866E-02 | sop loss PPL: 1.100460E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration  250000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration  250000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2305.38
 iteration   251000/10000000 | consumed samples:     32128000 | elapsed time per iteration (ms): 254.3 | learning rate: 7.789E-05 | global batch size:   128 | lm loss: 1.930382E+00 | sop loss: 8.064106E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.74 | backward-compute: 79.79 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 22.67
 iteration   252000/10000000 | consumed samples:     32256000 | elapsed time per iteration (ms): 248.5 | learning rate: 7.780E-05 | global batch size:   128 | lm loss: 1.930671E+00 | sop loss: 8.102089E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.08 | backward-compute: 79.79 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.76 | optimizer-unscale-and-check-inf: 2.24 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.24 | batch-generator: 16.77
 iteration   253000/10000000 | consumed samples:     32384000 | elapsed time per iteration (ms): 248.2 | learning rate: 7.771E-05 | global batch size:   128 | lm loss: 1.933912E+00 | sop loss: 8.105849E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.45 | backward-compute: 79.77 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 15.32
 iteration   254000/10000000 | consumed samples:     32512000 | elapsed time per iteration (ms): 246.6 | learning rate: 7.762E-05 | global batch size:   128 | lm loss: 1.926639E+00 | sop loss: 8.014946E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.47 | backward-compute: 79.91 | backward-params-all-reduce: 14.35 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 18.16
 iteration   255000/10000000 | consumed samples:     32640000 | elapsed time per iteration (ms): 249.5 | learning rate: 7.753E-05 | global batch size:   128 | lm loss: 1.928786E+00 | sop loss: 8.025522E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.95 | backward-compute: 79.80 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 15.90
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 255000 | lm loss value: 1.940807E+00 | lm loss PPL: 6.964371E+00 | sop loss value: 7.533865E-02 | sop loss PPL: 1.078249E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   256000/10000000 | consumed samples:     32768000 | elapsed time per iteration (ms): 248.7 | learning rate: 7.744E-05 | global batch size:   128 | lm loss: 1.929312E+00 | sop loss: 8.069868E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.48 | backward-compute: 79.79 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 15.21
 iteration   257000/10000000 | consumed samples:     32896000 | elapsed time per iteration (ms): 246.7 | learning rate: 7.734E-05 | global batch size:   128 | lm loss: 1.929699E+00 | sop loss: 8.013274E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.15 | backward-compute: 79.85 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 15.99
 iteration   258000/10000000 | consumed samples:     33024000 | elapsed time per iteration (ms): 246.1 | learning rate: 7.725E-05 | global batch size:   128 | lm loss: 1.927188E+00 | sop loss: 8.022386E-02 | loss scale: 65536.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.44 | backward-compute: 79.86 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.38 | batch-generator: 19.69
 iteration   259000/10000000 | consumed samples:     33152000 | elapsed time per iteration (ms): 245.3 | learning rate: 7.716E-05 | global batch size:   128 | lm loss: 1.927090E+00 | sop loss: 8.003190E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.84 | backward-compute: 79.73 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.29 | batch-generator: 14.32
 iteration   260000/10000000 | consumed samples:     33280000 | elapsed time per iteration (ms): 247.7 | learning rate: 7.707E-05 | global batch size:   128 | lm loss: 1.924971E+00 | sop loss: 8.137826E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.18 | backward-compute: 79.71 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 14.55
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 260000 | lm loss value: 1.990880E+00 | lm loss PPL: 7.321973E+00 | sop loss value: 8.911125E-02 | sop loss PPL: 1.093202E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   261000/10000000 | consumed samples:     33408000 | elapsed time per iteration (ms): 249.8 | learning rate: 7.698E-05 | global batch size:   128 | lm loss: 1.926099E+00 | sop loss: 8.040051E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.58 | backward-compute: 79.74 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.31 | batch-generator: 16.62
 iteration   262000/10000000 | consumed samples:     33536000 | elapsed time per iteration (ms): 247.2 | learning rate: 7.689E-05 | global batch size:   128 | lm loss: 1.923901E+00 | sop loss: 7.900054E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.36 | backward-compute: 79.79 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 18.12
 iteration   263000/10000000 | consumed samples:     33664000 | elapsed time per iteration (ms): 249.1 | learning rate: 7.679E-05 | global batch size:   128 | lm loss: 1.923991E+00 | sop loss: 7.868020E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.64 | backward-compute: 79.77 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.30 | batch-generator: 19.67
 iteration   264000/10000000 | consumed samples:     33792000 | elapsed time per iteration (ms): 251.2 | learning rate: 7.670E-05 | global batch size:   128 | lm loss: 1.925561E+00 | sop loss: 8.117781E-02 | loss scale: 65536.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.62 | backward-compute: 79.80 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.40 | batch-generator: 14.57
 iteration   265000/10000000 | consumed samples:     33920000 | elapsed time per iteration (ms): 247.9 | learning rate: 7.661E-05 | global batch size:   128 | lm loss: 1.920176E+00 | sop loss: 7.986289E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.37 | backward-compute: 79.79 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 15.70
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 265000 | lm loss value: 1.989914E+00 | lm loss PPL: 7.314903E+00 | sop loss value: 9.660974E-02 | sop loss PPL: 1.101430E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   266000/10000000 | consumed samples:     34048000 | elapsed time per iteration (ms): 250.5 | learning rate: 7.652E-05 | global batch size:   128 | lm loss: 1.920670E+00 | sop loss: 7.877705E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.47 | backward-compute: 79.79 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.32 | batch-generator: 13.98
 iteration   267000/10000000 | consumed samples:     34176000 | elapsed time per iteration (ms): 248.8 | learning rate: 7.643E-05 | global batch size:   128 | lm loss: 1.921407E+00 | sop loss: 8.003774E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.20 | backward-compute: 79.79 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 12.84
 iteration   268000/10000000 | consumed samples:     34304000 | elapsed time per iteration (ms): 246.6 | learning rate: 7.634E-05 | global batch size:   128 | lm loss: 1.921696E+00 | sop loss: 8.139876E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.10 | backward-compute: 79.81 | backward-params-all-reduce: 13.91 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 13.35
 iteration   269000/10000000 | consumed samples:     34432000 | elapsed time per iteration (ms): 248.3 | learning rate: 7.624E-05 | global batch size:   128 | lm loss: 1.919495E+00 | sop loss: 7.962338E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.28 | backward-compute: 79.84 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.51 | batch-generator: 15.13
 iteration   270000/10000000 | consumed samples:     34560000 | elapsed time per iteration (ms): 248.6 | learning rate: 7.615E-05 | global batch size:   128 | lm loss: 1.921857E+00 | sop loss: 7.921204E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.87 | backward-compute: 79.77 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 13.28
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 270000 | lm loss value: 1.989582E+00 | lm loss PPL: 7.312477E+00 | sop loss value: 8.658205E-02 | sop loss PPL: 1.090441E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   271000/10000000 | consumed samples:     34688000 | elapsed time per iteration (ms): 248.5 | learning rate: 7.606E-05 | global batch size:   128 | lm loss: 1.914816E+00 | sop loss: 7.999408E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.50 | backward-compute: 79.75 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.29 | batch-generator: 14.67
 iteration   272000/10000000 | consumed samples:     34816000 | elapsed time per iteration (ms): 248.8 | learning rate: 7.597E-05 | global batch size:   128 | lm loss: 1.914896E+00 | sop loss: 7.909422E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.18 | backward-compute: 79.78 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 13.58
 iteration   273000/10000000 | consumed samples:     34944000 | elapsed time per iteration (ms): 249.5 | learning rate: 7.588E-05 | global batch size:   128 | lm loss: 1.914937E+00 | sop loss: 7.914913E-02 | loss scale: 65536.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.57 | backward-compute: 79.83 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.45 | batch-generator: 14.02
 iteration   274000/10000000 | consumed samples:     35072000 | elapsed time per iteration (ms): 247.3 | learning rate: 7.579E-05 | global batch size:   128 | lm loss: 1.916812E+00 | sop loss: 7.969334E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.85 | backward-compute: 79.86 | backward-params-all-reduce: 15.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.89 | optimizer-unscale-and-check-inf: 2.32 | optimizer-clip-main-grad: 4.42 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.95 | batch-generator: 16.52
 iteration   275000/10000000 | consumed samples:     35200000 | elapsed time per iteration (ms): 249.4 | learning rate: 7.569E-05 | global batch size:   128 | lm loss: 1.915767E+00 | sop loss: 7.912606E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.54 | backward-compute: 79.77 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.46 | batch-generator: 13.83
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 275000 | lm loss value: 1.972381E+00 | lm loss PPL: 7.187770E+00 | sop loss value: 1.019077E-01 | sop loss PPL: 1.107281E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   276000/10000000 | consumed samples:     35328000 | elapsed time per iteration (ms): 247.4 | learning rate: 7.560E-05 | global batch size:   128 | lm loss: 1.916455E+00 | sop loss: 7.958663E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.75 | backward-compute: 79.76 | backward-params-all-reduce: 14.37 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 16.23
 iteration   277000/10000000 | consumed samples:     35456000 | elapsed time per iteration (ms): 247.5 | learning rate: 7.551E-05 | global batch size:   128 | lm loss: 1.914521E+00 | sop loss: 8.001742E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.75 | backward-compute: 79.78 | backward-params-all-reduce: 14.64 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.24 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.69 | batch-generator: 16.81
 iteration   278000/10000000 | consumed samples:     35584000 | elapsed time per iteration (ms): 247.5 | learning rate: 7.542E-05 | global batch size:   128 | lm loss: 1.911459E+00 | sop loss: 7.849213E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.76 | backward-compute: 79.77 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.28 | batch-generator: 13.60
 iteration   279000/10000000 | consumed samples:     35712000 | elapsed time per iteration (ms): 247.0 | learning rate: 7.533E-05 | global batch size:   128 | lm loss: 1.911053E+00 | sop loss: 7.775104E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.53 | backward-compute: 79.83 | backward-params-all-reduce: 14.54 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.57 | batch-generator: 14.76
 iteration   280000/10000000 | consumed samples:     35840000 | elapsed time per iteration (ms): 246.8 | learning rate: 7.524E-05 | global batch size:   128 | lm loss: 1.909756E+00 | sop loss: 7.776972E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.39 | backward-compute: 79.82 | backward-params-all-reduce: 14.53 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.54 | batch-generator: 17.40
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 280000 | lm loss value: 1.907670E+00 | lm loss PPL: 6.737375E+00 | sop loss value: 8.282110E-02 | sop loss PPL: 1.086347E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   281000/10000000 | consumed samples:     35968000 | elapsed time per iteration (ms): 250.6 | learning rate: 7.514E-05 | global batch size:   128 | lm loss: 1.909109E+00 | sop loss: 7.881929E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.67 | backward-compute: 79.81 | backward-params-all-reduce: 14.44 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.56 | batch-generator: 15.95
 iteration   282000/10000000 | consumed samples:     36096000 | elapsed time per iteration (ms): 248.1 | learning rate: 7.505E-05 | global batch size:   128 | lm loss: 1.912809E+00 | sop loss: 7.829027E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.09 | backward-compute: 79.85 | backward-params-all-reduce: 14.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 20.03
 iteration   283000/10000000 | consumed samples:     36224000 | elapsed time per iteration (ms): 245.6 | learning rate: 7.496E-05 | global batch size:   128 | lm loss: 1.906940E+00 | sop loss: 7.783838E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.11 | backward-compute: 79.84 | backward-params-all-reduce: 13.90 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.28 | batch-generator: 22.93
 iteration   284000/10000000 | consumed samples:     36352000 | elapsed time per iteration (ms): 247.4 | learning rate: 7.487E-05 | global batch size:   128 | lm loss: 1.908374E+00 | sop loss: 7.848887E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.72 | backward-compute: 79.77 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 16.01
 iteration   285000/10000000 | consumed samples:     36480000 | elapsed time per iteration (ms): 247.7 | learning rate: 7.478E-05 | global batch size:   128 | lm loss: 1.910214E+00 | sop loss: 7.885738E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.06 | backward-compute: 79.75 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 16.65
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 285000 | lm loss value: 1.968245E+00 | lm loss PPL: 7.158100E+00 | sop loss value: 9.441403E-02 | sop loss PPL: 1.099015E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   286000/10000000 | consumed samples:     36608000 | elapsed time per iteration (ms): 248.0 | learning rate: 7.468E-05 | global batch size:   128 | lm loss: 1.905397E+00 | sop loss: 7.781339E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.65 | backward-compute: 79.78 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.28 | batch-generator: 16.06
 iteration   287000/10000000 | consumed samples:     36736000 | elapsed time per iteration (ms): 247.5 | learning rate: 7.459E-05 | global batch size:   128 | lm loss: 1.906693E+00 | sop loss: 7.624530E-02 | loss scale: 65536.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.74 | backward-compute: 79.87 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 15.72
 iteration   288000/10000000 | consumed samples:     36864000 | elapsed time per iteration (ms): 246.4 | learning rate: 7.450E-05 | global batch size:   128 | lm loss: 1.905757E+00 | sop loss: 7.816777E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.26 | backward-compute: 79.90 | backward-params-all-reduce: 14.28 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 15.66
 iteration   289000/10000000 | consumed samples:     36992000 | elapsed time per iteration (ms): 248.4 | learning rate: 7.441E-05 | global batch size:   128 | lm loss: 1.907873E+00 | sop loss: 7.861397E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.81 | backward-compute: 79.83 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.30 | batch-generator: 20.28
 iteration   290000/10000000 | consumed samples:     37120000 | elapsed time per iteration (ms): 246.8 | learning rate: 7.432E-05 | global batch size:   128 | lm loss: 1.904184E+00 | sop loss: 7.991744E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.25 | backward-compute: 79.83 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.30 | batch-generator: 18.20
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 290000 | lm loss value: 1.951915E+00 | lm loss PPL: 7.042158E+00 | sop loss value: 7.581294E-02 | sop loss PPL: 1.078761E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   291000/10000000 | consumed samples:     37248000 | elapsed time per iteration (ms): 250.8 | learning rate: 7.423E-05 | global batch size:   128 | lm loss: 1.902674E+00 | sop loss: 7.802245E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.58 | backward-compute: 79.79 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 14.29
 iteration   292000/10000000 | consumed samples:     37376000 | elapsed time per iteration (ms): 247.7 | learning rate: 7.413E-05 | global batch size:   128 | lm loss: 1.903671E+00 | sop loss: 7.757454E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.25 | backward-compute: 79.86 | backward-params-all-reduce: 13.88 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 17.88
 iteration   293000/10000000 | consumed samples:     37504000 | elapsed time per iteration (ms): 247.6 | learning rate: 7.404E-05 | global batch size:   128 | lm loss: 1.904349E+00 | sop loss: 7.725690E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.89 | backward-compute: 79.90 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.32 | batch-generator: 13.99
 iteration   294000/10000000 | consumed samples:     37632000 | elapsed time per iteration (ms): 247.3 | learning rate: 7.395E-05 | global batch size:   128 | lm loss: 1.900569E+00 | sop loss: 7.809657E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.75 | backward-compute: 79.86 | backward-params-all-reduce: 14.53 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.62 | batch-generator: 16.60
 iteration   295000/10000000 | consumed samples:     37760000 | elapsed time per iteration (ms): 246.8 | learning rate: 7.386E-05 | global batch size:   128 | lm loss: 1.898304E+00 | sop loss: 7.810561E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.60 | backward-compute: 79.81 | backward-params-all-reduce: 14.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.55 | batch-generator: 16.06
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 295000 | lm loss value: 1.926394E+00 | lm loss PPL: 6.864715E+00 | sop loss value: 9.354013E-02 | sop loss PPL: 1.098055E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   296000/10000000 | consumed samples:     37888000 | elapsed time per iteration (ms): 250.4 | learning rate: 7.377E-05 | global batch size:   128 | lm loss: 1.904252E+00 | sop loss: 7.737694E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.17 | backward-compute: 79.84 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 14.03
 iteration   297000/10000000 | consumed samples:     38016000 | elapsed time per iteration (ms): 246.3 | learning rate: 7.368E-05 | global batch size:   128 | lm loss: 1.900903E+00 | sop loss: 7.682345E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.49 | backward-compute: 79.85 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.31 | batch-generator: 13.66
 iteration   298000/10000000 | consumed samples:     38144000 | elapsed time per iteration (ms): 246.8 | learning rate: 7.358E-05 | global batch size:   128 | lm loss: 1.897580E+00 | sop loss: 7.799293E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.06 | backward-compute: 79.85 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 18.66
 iteration   299000/10000000 | consumed samples:     38272000 | elapsed time per iteration (ms): 246.9 | learning rate: 7.349E-05 | global batch size:   128 | lm loss: 1.899207E+00 | sop loss: 7.806680E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.29 | backward-compute: 79.81 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.30 | batch-generator: 15.83
 iteration   300000/10000000 | consumed samples:     38400000 | elapsed time per iteration (ms): 248.4 | learning rate: 7.340E-05 | global batch size:   128 | lm loss: 1.896983E+00 | sop loss: 7.552606E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.92 | backward-compute: 79.81 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.29 | batch-generator: 17.25
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 300000 | lm loss value: 1.958032E+00 | lm loss PPL: 7.085367E+00 | sop loss value: 1.094015E-01 | sop loss PPL: 1.115610E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration  300000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration  300000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2351.72
 iteration   301000/10000000 | consumed samples:     38528000 | elapsed time per iteration (ms): 251.5 | learning rate: 7.331E-05 | global batch size:   128 | lm loss: 1.894876E+00 | sop loss: 7.747376E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.92 | backward-compute: 79.74 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 13.78
 iteration   302000/10000000 | consumed samples:     38656000 | elapsed time per iteration (ms): 248.8 | learning rate: 7.322E-05 | global batch size:   128 | lm loss: 1.894892E+00 | sop loss: 7.744734E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.25 | backward-compute: 79.80 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.30 | batch-generator: 14.04
 iteration   303000/10000000 | consumed samples:     38784000 | elapsed time per iteration (ms): 249.8 | learning rate: 7.313E-05 | global batch size:   128 | lm loss: 1.897248E+00 | sop loss: 7.861944E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.38 | backward-compute: 79.81 | backward-params-all-reduce: 14.47 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.60 | batch-generator: 16.37
 iteration   304000/10000000 | consumed samples:     38912000 | elapsed time per iteration (ms): 247.3 | learning rate: 7.303E-05 | global batch size:   128 | lm loss: 1.893833E+00 | sop loss: 7.687805E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.19 | backward-compute: 79.85 | backward-params-all-reduce: 14.80 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.88 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.28 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.78 | batch-generator: 18.21
 iteration   305000/10000000 | consumed samples:     39040000 | elapsed time per iteration (ms): 246.7 | learning rate: 7.294E-05 | global batch size:   128 | lm loss: 1.892467E+00 | sop loss: 7.758039E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.08 | backward-compute: 79.85 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 14.99
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 305000 | lm loss value: 1.914124E+00 | lm loss PPL: 6.780995E+00 | sop loss value: 9.208050E-02 | sop loss PPL: 1.096453E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   306000/10000000 | consumed samples:     39168000 | elapsed time per iteration (ms): 248.3 | learning rate: 7.285E-05 | global batch size:   128 | lm loss: 1.892409E+00 | sop loss: 7.711494E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.63 | backward-compute: 79.82 | backward-params-all-reduce: 14.78 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.20 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.65 | batch-generator: 13.91
 iteration   307000/10000000 | consumed samples:     39296000 | elapsed time per iteration (ms): 247.4 | learning rate: 7.276E-05 | global batch size:   128 | lm loss: 1.895221E+00 | sop loss: 7.801090E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.91 | backward-compute: 79.79 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.27 | batch-generator: 14.13
 iteration   308000/10000000 | consumed samples:     39424000 | elapsed time per iteration (ms): 247.9 | learning rate: 7.267E-05 | global batch size:   128 | lm loss: 1.891829E+00 | sop loss: 7.547726E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.34 | backward-compute: 79.81 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.30 | batch-generator: 14.12
 iteration   309000/10000000 | consumed samples:     39552000 | elapsed time per iteration (ms): 248.5 | learning rate: 7.258E-05 | global batch size:   128 | lm loss: 1.893615E+00 | sop loss: 7.730936E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.85 | backward-compute: 79.79 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 16.79
 iteration   310000/10000000 | consumed samples:     39680000 | elapsed time per iteration (ms): 247.4 | learning rate: 7.248E-05 | global batch size:   128 | lm loss: 1.891714E+00 | sop loss: 7.676348E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.87 | backward-compute: 79.78 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.96 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.27 | batch-generator: 15.27
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 310000 | lm loss value: 1.981112E+00 | lm loss PPL: 7.250800E+00 | sop loss value: 7.569572E-02 | sop loss PPL: 1.078634E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   311000/10000000 | consumed samples:     39808000 | elapsed time per iteration (ms): 251.8 | learning rate: 7.239E-05 | global batch size:   128 | lm loss: 1.889827E+00 | sop loss: 7.659456E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.57 | backward-compute: 79.82 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.30 | batch-generator: 17.79
 iteration   312000/10000000 | consumed samples:     39936000 | elapsed time per iteration (ms): 248.8 | learning rate: 7.230E-05 | global batch size:   128 | lm loss: 1.890312E+00 | sop loss: 7.699161E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.08 | backward-compute: 79.87 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 21.06
 iteration   313000/10000000 | consumed samples:     40064000 | elapsed time per iteration (ms): 247.7 | learning rate: 7.221E-05 | global batch size:   128 | lm loss: 1.886540E+00 | sop loss: 7.687086E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.20 | backward-compute: 79.82 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.30 | batch-generator: 19.24
 iteration   314000/10000000 | consumed samples:     40192000 | elapsed time per iteration (ms): 247.7 | learning rate: 7.212E-05 | global batch size:   128 | lm loss: 1.887200E+00 | sop loss: 7.832355E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.14 | backward-compute: 79.81 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.32 | batch-generator: 15.50
 iteration   315000/10000000 | consumed samples:     40320000 | elapsed time per iteration (ms): 248.2 | learning rate: 7.203E-05 | global batch size:   128 | lm loss: 1.884837E+00 | sop loss: 7.698355E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.61 | backward-compute: 79.74 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 20.12
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 315000 | lm loss value: 1.964401E+00 | lm loss PPL: 7.130639E+00 | sop loss value: 1.059393E-01 | sop loss PPL: 1.111754E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   316000/10000000 | consumed samples:     40448000 | elapsed time per iteration (ms): 251.9 | learning rate: 7.193E-05 | global batch size:   128 | lm loss: 1.885070E+00 | sop loss: 7.475883E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.93 | backward-compute: 79.81 | backward-params-all-reduce: 13.90 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 28.31
 iteration   317000/10000000 | consumed samples:     40576000 | elapsed time per iteration (ms): 252.0 | learning rate: 7.184E-05 | global batch size:   128 | lm loss: 1.886906E+00 | sop loss: 7.592092E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.47 | backward-compute: 79.79 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 19.23
 iteration   318000/10000000 | consumed samples:     40704000 | elapsed time per iteration (ms): 247.3 | learning rate: 7.175E-05 | global batch size:   128 | lm loss: 1.887969E+00 | sop loss: 7.779930E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.62 | backward-compute: 79.80 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 15.14
 iteration   319000/10000000 | consumed samples:     40832000 | elapsed time per iteration (ms): 249.2 | learning rate: 7.166E-05 | global batch size:   128 | lm loss: 1.883153E+00 | sop loss: 7.559456E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.77 | backward-compute: 79.74 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.96 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.26 | batch-generator: 14.22
 iteration   320000/10000000 | consumed samples:     40960000 | elapsed time per iteration (ms): 248.8 | learning rate: 7.157E-05 | global batch size:   128 | lm loss: 1.885602E+00 | sop loss: 7.654717E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.20 | backward-compute: 79.90 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.29 | batch-generator: 16.76
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 320000 | lm loss value: 1.922019E+00 | lm loss PPL: 6.834746E+00 | sop loss value: 8.460172E-02 | sop loss PPL: 1.088284E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   321000/10000000 | consumed samples:     41088000 | elapsed time per iteration (ms): 249.0 | learning rate: 7.148E-05 | global batch size:   128 | lm loss: 1.882168E+00 | sop loss: 7.665351E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.63 | backward-compute: 79.81 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.89
 iteration   322000/10000000 | consumed samples:     41216000 | elapsed time per iteration (ms): 247.8 | learning rate: 7.138E-05 | global batch size:   128 | lm loss: 1.881235E+00 | sop loss: 7.656855E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.11 | backward-compute: 79.81 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.30 | batch-generator: 13.42
 iteration   323000/10000000 | consumed samples:     41344000 | elapsed time per iteration (ms): 247.7 | learning rate: 7.129E-05 | global batch size:   128 | lm loss: 1.883958E+00 | sop loss: 7.625954E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.07 | backward-compute: 79.79 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 14.66
 iteration   324000/10000000 | consumed samples:     41472000 | elapsed time per iteration (ms): 247.9 | learning rate: 7.120E-05 | global batch size:   128 | lm loss: 1.880801E+00 | sop loss: 7.629313E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.37 | backward-compute: 79.76 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.32 | batch-generator: 13.10
 iteration   325000/10000000 | consumed samples:     41600000 | elapsed time per iteration (ms): 248.2 | learning rate: 7.111E-05 | global batch size:   128 | lm loss: 1.881741E+00 | sop loss: 7.708643E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.78 | backward-compute: 79.73 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.31 | batch-generator: 12.40
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 325000 | lm loss value: 1.934729E+00 | lm loss PPL: 6.922169E+00 | sop loss value: 8.929708E-02 | sop loss PPL: 1.093405E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   326000/10000000 | consumed samples:     41728000 | elapsed time per iteration (ms): 248.5 | learning rate: 7.102E-05 | global batch size:   128 | lm loss: 1.879776E+00 | sop loss: 7.533500E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.39 | backward-compute: 79.81 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.33 | batch-generator: 17.33
 iteration   327000/10000000 | consumed samples:     41856000 | elapsed time per iteration (ms): 248.1 | learning rate: 7.093E-05 | global batch size:   128 | lm loss: 1.880832E+00 | sop loss: 7.401274E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.47 | backward-compute: 79.81 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 19.87
 iteration   328000/10000000 | consumed samples:     41984000 | elapsed time per iteration (ms): 247.6 | learning rate: 7.083E-05 | global batch size:   128 | lm loss: 1.881247E+00 | sop loss: 7.536291E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.98 | backward-compute: 79.84 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.28 | batch-generator: 15.41
 iteration   329000/10000000 | consumed samples:     42112000 | elapsed time per iteration (ms): 248.3 | learning rate: 7.074E-05 | global batch size:   128 | lm loss: 1.877008E+00 | sop loss: 7.536604E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.76 | backward-compute: 79.81 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.95 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.23 | batch-generator: 17.17
 iteration   330000/10000000 | consumed samples:     42240000 | elapsed time per iteration (ms): 247.8 | learning rate: 7.065E-05 | global batch size:   128 | lm loss: 1.877741E+00 | sop loss: 7.509284E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.15 | backward-compute: 79.77 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 17.90
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 330000 | lm loss value: 1.916126E+00 | lm loss PPL: 6.794586E+00 | sop loss value: 1.140671E-01 | sop loss PPL: 1.120827E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   331000/10000000 | consumed samples:     42368000 | elapsed time per iteration (ms): 250.5 | learning rate: 7.056E-05 | global batch size:   128 | lm loss: 1.878429E+00 | sop loss: 7.680289E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.19 | backward-compute: 79.77 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.19
 iteration   332000/10000000 | consumed samples:     42496000 | elapsed time per iteration (ms): 248.8 | learning rate: 7.047E-05 | global batch size:   128 | lm loss: 1.876326E+00 | sop loss: 7.345689E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.00 | backward-compute: 79.81 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 13.47
 iteration   333000/10000000 | consumed samples:     42624000 | elapsed time per iteration (ms): 247.2 | learning rate: 7.038E-05 | global batch size:   128 | lm loss: 1.876408E+00 | sop loss: 7.537031E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.77 | backward-compute: 79.82 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.95 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.24 | batch-generator: 16.44
 iteration   334000/10000000 | consumed samples:     42752000 | elapsed time per iteration (ms): 249.5 | learning rate: 7.028E-05 | global batch size:   128 | lm loss: 1.879937E+00 | sop loss: 7.464419E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.90 | backward-compute: 79.82 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.31 | batch-generator: 18.19
 iteration   335000/10000000 | consumed samples:     42880000 | elapsed time per iteration (ms): 247.1 | learning rate: 7.019E-05 | global batch size:   128 | lm loss: 1.876118E+00 | sop loss: 7.732111E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.23 | backward-compute: 79.80 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.46 | batch-generator: 15.27
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 335000 | lm loss value: 1.901974E+00 | lm loss PPL: 6.699108E+00 | sop loss value: 9.275578E-02 | sop loss PPL: 1.097194E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   336000/10000000 | consumed samples:     43008000 | elapsed time per iteration (ms): 248.9 | learning rate: 7.010E-05 | global batch size:   128 | lm loss: 1.872395E+00 | sop loss: 7.560330E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.57 | backward-compute: 79.84 | backward-params-all-reduce: 14.68 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.22 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.69 | batch-generator: 15.06
 iteration   337000/10000000 | consumed samples:     43136000 | elapsed time per iteration (ms): 247.6 | learning rate: 7.001E-05 | global batch size:   128 | lm loss: 1.876413E+00 | sop loss: 7.580315E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.03 | backward-compute: 79.77 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.29 | batch-generator: 15.11
 iteration   338000/10000000 | consumed samples:     43264000 | elapsed time per iteration (ms): 248.2 | learning rate: 6.992E-05 | global batch size:   128 | lm loss: 1.876617E+00 | sop loss: 7.429880E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.32 | backward-compute: 79.74 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 16.09
 iteration   339000/10000000 | consumed samples:     43392000 | elapsed time per iteration (ms): 246.8 | learning rate: 6.982E-05 | global batch size:   128 | lm loss: 1.873240E+00 | sop loss: 7.501366E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.21 | backward-compute: 79.75 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.28 | batch-generator: 18.47
 iteration   340000/10000000 | consumed samples:     43520000 | elapsed time per iteration (ms): 246.8 | learning rate: 6.973E-05 | global batch size:   128 | lm loss: 1.872415E+00 | sop loss: 7.536763E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.34 | backward-compute: 79.77 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.26 | batch-generator: 15.48
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 340000 | lm loss value: 1.912120E+00 | lm loss PPL: 6.767417E+00 | sop loss value: 7.510316E-02 | sop loss PPL: 1.077995E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   341000/10000000 | consumed samples:     43648000 | elapsed time per iteration (ms): 250.1 | learning rate: 6.964E-05 | global batch size:   128 | lm loss: 1.872192E+00 | sop loss: 7.664503E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.84 | backward-compute: 79.82 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.28 | batch-generator: 16.14
 iteration   342000/10000000 | consumed samples:     43776000 | elapsed time per iteration (ms): 247.6 | learning rate: 6.955E-05 | global batch size:   128 | lm loss: 1.871892E+00 | sop loss: 7.534321E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.00 | backward-compute: 79.78 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.32 | batch-generator: 15.81
 iteration   343000/10000000 | consumed samples:     43904000 | elapsed time per iteration (ms): 249.1 | learning rate: 6.946E-05 | global batch size:   128 | lm loss: 1.875956E+00 | sop loss: 7.539150E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.05 | backward-compute: 79.85 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 16.53
 iteration   344000/10000000 | consumed samples:     44032000 | elapsed time per iteration (ms): 247.4 | learning rate: 6.937E-05 | global batch size:   128 | lm loss: 1.869887E+00 | sop loss: 7.542464E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.95 | backward-compute: 79.82 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.96 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.27 | batch-generator: 18.74
 iteration   345000/10000000 | consumed samples:     44160000 | elapsed time per iteration (ms): 249.2 | learning rate: 6.927E-05 | global batch size:   128 | lm loss: 1.869126E+00 | sop loss: 7.431605E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.49 | backward-compute: 79.76 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.97
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 345000 | lm loss value: 1.892090E+00 | lm loss PPL: 6.633218E+00 | sop loss value: 7.351596E-02 | sop loss PPL: 1.076286E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   346000/10000000 | consumed samples:     44288000 | elapsed time per iteration (ms): 249.4 | learning rate: 6.918E-05 | global batch size:   128 | lm loss: 1.872633E+00 | sop loss: 7.472657E-02 | loss scale: 65536.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.00 | backward-compute: 79.91 | backward-params-all-reduce: 14.65 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.24 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.72 | batch-generator: 15.41
 iteration   347000/10000000 | consumed samples:     44416000 | elapsed time per iteration (ms): 247.4 | learning rate: 6.909E-05 | global batch size:   128 | lm loss: 1.868854E+00 | sop loss: 7.432543E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.61 | backward-compute: 79.84 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 13.56
 iteration   348000/10000000 | consumed samples:     44544000 | elapsed time per iteration (ms): 246.9 | learning rate: 6.900E-05 | global batch size:   128 | lm loss: 1.869942E+00 | sop loss: 7.464232E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.37 | backward-compute: 79.86 | backward-params-all-reduce: 13.89 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.30 | batch-generator: 14.93
 iteration   349000/10000000 | consumed samples:     44672000 | elapsed time per iteration (ms): 248.3 | learning rate: 6.891E-05 | global batch size:   128 | lm loss: 1.865116E+00 | sop loss: 7.486674E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.58 | backward-compute: 79.80 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 13.16
 iteration   350000/10000000 | consumed samples:     44800000 | elapsed time per iteration (ms): 249.5 | learning rate: 6.882E-05 | global batch size:   128 | lm loss: 1.868876E+00 | sop loss: 7.599431E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.99 | backward-compute: 79.67 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.29 | batch-generator: 11.53
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 350000 | lm loss value: 1.939764E+00 | lm loss PPL: 6.957107E+00 | sop loss value: 7.780792E-02 | sop loss PPL: 1.080915E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration  350000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration  350000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2350.84
 iteration   351000/10000000 | consumed samples:     44928000 | elapsed time per iteration (ms): 250.0 | learning rate: 6.872E-05 | global batch size:   128 | lm loss: 1.870479E+00 | sop loss: 7.432143E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.46 | backward-compute: 79.81 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.28 | batch-generator: 15.57
 iteration   352000/10000000 | consumed samples:     45056000 | elapsed time per iteration (ms): 250.1 | learning rate: 6.863E-05 | global batch size:   128 | lm loss: 1.864120E+00 | sop loss: 7.426691E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.73 | backward-compute: 79.79 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.96 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.26 | batch-generator: 13.07
 iteration   353000/10000000 | consumed samples:     45184000 | elapsed time per iteration (ms): 246.4 | learning rate: 6.854E-05 | global batch size:   128 | lm loss: 1.864098E+00 | sop loss: 7.343335E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.88 | backward-compute: 79.85 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.28 | batch-generator: 15.48
 iteration   354000/10000000 | consumed samples:     45312000 | elapsed time per iteration (ms): 248.7 | learning rate: 6.845E-05 | global batch size:   128 | lm loss: 1.866624E+00 | sop loss: 7.435283E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.11 | backward-compute: 79.82 | backward-params-all-reduce: 14.57 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.22 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.69 | batch-generator: 17.80
 iteration   355000/10000000 | consumed samples:     45440000 | elapsed time per iteration (ms): 246.2 | learning rate: 6.836E-05 | global batch size:   128 | lm loss: 1.864814E+00 | sop loss: 7.537184E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.49 | backward-compute: 79.83 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 13.60
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 355000 | lm loss value: 1.904234E+00 | lm loss PPL: 6.714264E+00 | sop loss value: 7.863545E-02 | sop loss PPL: 1.081810E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   356000/10000000 | consumed samples:     45568000 | elapsed time per iteration (ms): 248.4 | learning rate: 6.827E-05 | global batch size:   128 | lm loss: 1.867023E+00 | sop loss: 7.634448E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.20 | backward-compute: 79.79 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 20.30
 iteration   357000/10000000 | consumed samples:     45696000 | elapsed time per iteration (ms): 249.8 | learning rate: 6.817E-05 | global batch size:   128 | lm loss: 1.862879E+00 | sop loss: 7.547433E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.94 | backward-compute: 79.80 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 12.49
 iteration   358000/10000000 | consumed samples:     45824000 | elapsed time per iteration (ms): 248.1 | learning rate: 6.808E-05 | global batch size:   128 | lm loss: 1.862215E+00 | sop loss: 7.330424E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.77 | backward-compute: 79.78 | backward-params-all-reduce: 14.41 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.58 | batch-generator: 14.98
 iteration   359000/10000000 | consumed samples:     45952000 | elapsed time per iteration (ms): 245.7 | learning rate: 6.799E-05 | global batch size:   128 | lm loss: 1.860981E+00 | sop loss: 7.438316E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.92 | backward-compute: 79.81 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 15.00
 iteration   360000/10000000 | consumed samples:     46080000 | elapsed time per iteration (ms): 248.3 | learning rate: 6.790E-05 | global batch size:   128 | lm loss: 1.865186E+00 | sop loss: 7.390417E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.13 | backward-compute: 79.83 | backward-params-all-reduce: 14.36 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.50 | batch-generator: 16.30
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 360000 | lm loss value: 1.939279E+00 | lm loss PPL: 6.953737E+00 | sop loss value: 8.433708E-02 | sop loss PPL: 1.087996E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   361000/10000000 | consumed samples:     46208000 | elapsed time per iteration (ms): 248.6 | learning rate: 6.781E-05 | global batch size:   128 | lm loss: 1.866539E+00 | sop loss: 7.450297E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.97 | backward-compute: 79.83 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.98
 iteration   362000/10000000 | consumed samples:     46336000 | elapsed time per iteration (ms): 246.8 | learning rate: 6.772E-05 | global batch size:   128 | lm loss: 1.858074E+00 | sop loss: 7.354740E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.28 | backward-compute: 79.85 | backward-params-all-reduce: 15.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.89 | optimizer-unscale-and-check-inf: 2.31 | optimizer-clip-main-grad: 4.33 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.86 | batch-generator: 13.63
 iteration   363000/10000000 | consumed samples:     46464000 | elapsed time per iteration (ms): 248.2 | learning rate: 6.762E-05 | global batch size:   128 | lm loss: 1.860863E+00 | sop loss: 7.362877E-02 | loss scale: 8192.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.48 | backward-compute: 79.74 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 13.21
 iteration   364000/10000000 | consumed samples:     46592000 | elapsed time per iteration (ms): 245.4 | learning rate: 6.753E-05 | global batch size:   128 | lm loss: 1.862223E+00 | sop loss: 7.325101E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.72 | backward-compute: 79.77 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 15.00
 iteration   365000/10000000 | consumed samples:     46720000 | elapsed time per iteration (ms): 248.1 | learning rate: 6.744E-05 | global batch size:   128 | lm loss: 1.862131E+00 | sop loss: 7.276643E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.37 | backward-compute: 79.80 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.40 | batch-generator: 14.35
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 365000 | lm loss value: 1.883669E+00 | lm loss PPL: 6.577592E+00 | sop loss value: 7.372233E-02 | sop loss PPL: 1.076508E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   366000/10000000 | consumed samples:     46848000 | elapsed time per iteration (ms): 249.8 | learning rate: 6.735E-05 | global batch size:   128 | lm loss: 1.857789E+00 | sop loss: 7.488792E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.02 | backward-compute: 79.80 | backward-params-all-reduce: 14.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.50 | batch-generator: 16.38
 iteration   367000/10000000 | consumed samples:     46976000 | elapsed time per iteration (ms): 247.3 | learning rate: 6.726E-05 | global batch size:   128 | lm loss: 1.862219E+00 | sop loss: 7.356410E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.70 | backward-compute: 79.73 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.30 | batch-generator: 13.10
 iteration   368000/10000000 | consumed samples:     47104000 | elapsed time per iteration (ms): 247.1 | learning rate: 6.717E-05 | global batch size:   128 | lm loss: 1.859637E+00 | sop loss: 7.450894E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.45 | backward-compute: 79.79 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.31 | batch-generator: 18.80
 iteration   369000/10000000 | consumed samples:     47232000 | elapsed time per iteration (ms): 249.3 | learning rate: 6.707E-05 | global batch size:   128 | lm loss: 1.857397E+00 | sop loss: 7.340103E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.79 | backward-compute: 79.90 | backward-params-all-reduce: 14.51 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.61 | batch-generator: 15.26
 iteration   370000/10000000 | consumed samples:     47360000 | elapsed time per iteration (ms): 246.9 | learning rate: 6.698E-05 | global batch size:   128 | lm loss: 1.854546E+00 | sop loss: 7.413728E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.72 | backward-compute: 79.84 | backward-params-all-reduce: 14.31 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.50 | batch-generator: 18.10
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 370000 | lm loss value: 1.892455E+00 | lm loss PPL: 6.635639E+00 | sop loss value: 9.428874E-02 | sop loss PPL: 1.098877E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   371000/10000000 | consumed samples:     47488000 | elapsed time per iteration (ms): 250.2 | learning rate: 6.689E-05 | global batch size:   128 | lm loss: 1.857688E+00 | sop loss: 7.293705E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.93 | backward-compute: 79.84 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.32 | batch-generator: 14.06
 iteration   372000/10000000 | consumed samples:     47616000 | elapsed time per iteration (ms): 245.7 | learning rate: 6.680E-05 | global batch size:   128 | lm loss: 1.854656E+00 | sop loss: 7.342600E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.30 | backward-compute: 79.79 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.24 | optimizer-clip-main-grad: 3.95 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.25 | batch-generator: 16.59
 iteration   373000/10000000 | consumed samples:     47744000 | elapsed time per iteration (ms): 249.8 | learning rate: 6.671E-05 | global batch size:   128 | lm loss: 1.856022E+00 | sop loss: 7.496577E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.33 | backward-compute: 79.74 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.29 | batch-generator: 15.33
 iteration   374000/10000000 | consumed samples:     47872000 | elapsed time per iteration (ms): 250.3 | learning rate: 6.661E-05 | global batch size:   128 | lm loss: 1.853742E+00 | sop loss: 7.353835E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.69 | backward-compute: 79.75 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 14.56
 iteration   375000/10000000 | consumed samples:     48000000 | elapsed time per iteration (ms): 246.9 | learning rate: 6.652E-05 | global batch size:   128 | lm loss: 1.856123E+00 | sop loss: 7.307645E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.20 | backward-compute: 79.76 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 16.76
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 375000 | lm loss value: 1.865322E+00 | lm loss PPL: 6.458017E+00 | sop loss value: 8.973225E-02 | sop loss PPL: 1.093881E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   376000/10000000 | consumed samples:     48128000 | elapsed time per iteration (ms): 250.1 | learning rate: 6.643E-05 | global batch size:   128 | lm loss: 1.852677E+00 | sop loss: 7.312832E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.80 | backward-compute: 79.85 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.33 | batch-generator: 19.37
 iteration   377000/10000000 | consumed samples:     48256000 | elapsed time per iteration (ms): 248.8 | learning rate: 6.634E-05 | global batch size:   128 | lm loss: 1.851834E+00 | sop loss: 7.316524E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.12 | backward-compute: 79.85 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 14.98
 iteration   378000/10000000 | consumed samples:     48384000 | elapsed time per iteration (ms): 248.6 | learning rate: 6.625E-05 | global batch size:   128 | lm loss: 1.850083E+00 | sop loss: 7.446044E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.06 | backward-compute: 79.88 | backward-params-all-reduce: 13.91 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.32 | batch-generator: 14.71
 iteration   379000/10000000 | consumed samples:     48512000 | elapsed time per iteration (ms): 249.3 | learning rate: 6.616E-05 | global batch size:   128 | lm loss: 1.852279E+00 | sop loss: 7.280545E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.81 | backward-compute: 79.79 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.29 | batch-generator: 14.26
 iteration   380000/10000000 | consumed samples:     48640000 | elapsed time per iteration (ms): 246.6 | learning rate: 6.606E-05 | global batch size:   128 | lm loss: 1.852213E+00 | sop loss: 7.376031E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.05 | backward-compute: 79.80 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 13.61
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 380000 | lm loss value: 1.947167E+00 | lm loss PPL: 7.008805E+00 | sop loss value: 9.040134E-02 | sop loss PPL: 1.094614E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   381000/10000000 | consumed samples:     48768000 | elapsed time per iteration (ms): 249.8 | learning rate: 6.597E-05 | global batch size:   128 | lm loss: 1.851364E+00 | sop loss: 7.356557E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.32 | backward-compute: 79.79 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 13.07
 iteration   382000/10000000 | consumed samples:     48896000 | elapsed time per iteration (ms): 245.5 | learning rate: 6.588E-05 | global batch size:   128 | lm loss: 1.850760E+00 | sop loss: 7.442793E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.93 | backward-compute: 79.83 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 15.00
 iteration   383000/10000000 | consumed samples:     49024000 | elapsed time per iteration (ms): 245.5 | learning rate: 6.579E-05 | global batch size:   128 | lm loss: 1.850313E+00 | sop loss: 7.477203E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.89 | backward-compute: 79.76 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 17.10
 iteration   384000/10000000 | consumed samples:     49152000 | elapsed time per iteration (ms): 249.4 | learning rate: 6.570E-05 | global batch size:   128 | lm loss: 1.850684E+00 | sop loss: 7.214550E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.63 | backward-compute: 79.83 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.30 | batch-generator: 12.40
 iteration   385000/10000000 | consumed samples:     49280000 | elapsed time per iteration (ms): 250.5 | learning rate: 6.561E-05 | global batch size:   128 | lm loss: 1.848679E+00 | sop loss: 7.179451E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.57 | backward-compute: 79.86 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 17.46
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 385000 | lm loss value: 1.891854E+00 | lm loss PPL: 6.631650E+00 | sop loss value: 8.883929E-02 | sop loss PPL: 1.092905E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   386000/10000000 | consumed samples:     49408000 | elapsed time per iteration (ms): 253.3 | learning rate: 6.551E-05 | global batch size:   128 | lm loss: 1.848440E+00 | sop loss: 7.244700E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.27 | backward-compute: 79.81 | backward-params-all-reduce: 13.88 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.30 | batch-generator: 25.74
 iteration   387000/10000000 | consumed samples:     49536000 | elapsed time per iteration (ms): 248.0 | learning rate: 6.542E-05 | global batch size:   128 | lm loss: 1.847158E+00 | sop loss: 7.138355E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.33 | backward-compute: 79.84 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 14.33
 iteration   388000/10000000 | consumed samples:     49664000 | elapsed time per iteration (ms): 248.9 | learning rate: 6.533E-05 | global batch size:   128 | lm loss: 1.848499E+00 | sop loss: 7.159580E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.52 | backward-compute: 79.70 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.29 | batch-generator: 14.35
 iteration   389000/10000000 | consumed samples:     49792000 | elapsed time per iteration (ms): 248.4 | learning rate: 6.524E-05 | global batch size:   128 | lm loss: 1.849328E+00 | sop loss: 7.197601E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.56 | backward-compute: 79.78 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 16.47
 iteration   390000/10000000 | consumed samples:     49920000 | elapsed time per iteration (ms): 248.9 | learning rate: 6.515E-05 | global batch size:   128 | lm loss: 1.847638E+00 | sop loss: 7.280261E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.65 | backward-compute: 79.75 | backward-params-all-reduce: 14.48 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 13.92
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 390000 | lm loss value: 1.925030E+00 | lm loss PPL: 6.855355E+00 | sop loss value: 9.711509E-02 | sop loss PPL: 1.101987E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   391000/10000000 | consumed samples:     50048000 | elapsed time per iteration (ms): 250.1 | learning rate: 6.506E-05 | global batch size:   128 | lm loss: 1.844576E+00 | sop loss: 7.143526E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.09 | backward-compute: 79.73 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.24 | optimizer-clip-main-grad: 3.96 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.25 | batch-generator: 12.91
 iteration   392000/10000000 | consumed samples:     50176000 | elapsed time per iteration (ms): 247.2 | learning rate: 6.496E-05 | global batch size:   128 | lm loss: 1.844780E+00 | sop loss: 7.322662E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.31 | backward-compute: 79.77 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 14.23
 iteration   393000/10000000 | consumed samples:     50304000 | elapsed time per iteration (ms): 247.1 | learning rate: 6.487E-05 | global batch size:   128 | lm loss: 1.844076E+00 | sop loss: 7.313096E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.24 | backward-compute: 79.82 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 23.21
 iteration   394000/10000000 | consumed samples:     50432000 | elapsed time per iteration (ms): 248.5 | learning rate: 6.478E-05 | global batch size:   128 | lm loss: 1.844862E+00 | sop loss: 7.163454E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.05 | backward-compute: 79.81 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.95 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.24 | batch-generator: 18.84
 iteration   395000/10000000 | consumed samples:     50560000 | elapsed time per iteration (ms): 250.1 | learning rate: 6.469E-05 | global batch size:   128 | lm loss: 1.844915E+00 | sop loss: 7.101421E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.68 | backward-compute: 79.73 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.29 | batch-generator: 15.75
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 395000 | lm loss value: 1.885825E+00 | lm loss PPL: 6.591789E+00 | sop loss value: 9.593460E-02 | sop loss PPL: 1.100687E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   396000/10000000 | consumed samples:     50688000 | elapsed time per iteration (ms): 250.1 | learning rate: 6.460E-05 | global batch size:   128 | lm loss: 1.844525E+00 | sop loss: 7.305359E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.98 | backward-compute: 79.79 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.29 | batch-generator: 15.56
 iteration   397000/10000000 | consumed samples:     50816000 | elapsed time per iteration (ms): 248.0 | learning rate: 6.451E-05 | global batch size:   128 | lm loss: 1.841584E+00 | sop loss: 7.180113E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.31 | backward-compute: 79.81 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 18.38
 iteration   398000/10000000 | consumed samples:     50944000 | elapsed time per iteration (ms): 245.5 | learning rate: 6.441E-05 | global batch size:   128 | lm loss: 1.844319E+00 | sop loss: 7.326613E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.04 | backward-compute: 79.84 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.27 | batch-generator: 16.08
 iteration   399000/10000000 | consumed samples:     51072000 | elapsed time per iteration (ms): 249.0 | learning rate: 6.432E-05 | global batch size:   128 | lm loss: 1.842028E+00 | sop loss: 7.308945E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.59 | backward-compute: 79.76 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.76 | optimizer-unscale-and-check-inf: 2.24 | optimizer-clip-main-grad: 3.95 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.24 | batch-generator: 17.78
 iteration   400000/10000000 | consumed samples:     51200000 | elapsed time per iteration (ms): 250.9 | learning rate: 6.423E-05 | global batch size:   128 | lm loss: 1.840346E+00 | sop loss: 7.357175E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.48 | backward-compute: 79.80 | backward-params-all-reduce: 13.91 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.30 | batch-generator: 22.57
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 400000 | lm loss value: 1.893998E+00 | lm loss PPL: 6.645888E+00 | sop loss value: 8.745678E-02 | sop loss PPL: 1.091395E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration  400000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration  400000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2324.37
 iteration   401000/10000000 | consumed samples:     51328000 | elapsed time per iteration (ms): 252.0 | learning rate: 6.414E-05 | global batch size:   128 | lm loss: 1.843660E+00 | sop loss: 7.349293E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.69 | backward-compute: 79.76 | backward-params-all-reduce: 13.92 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.31 | batch-generator: 14.03
 iteration   402000/10000000 | consumed samples:     51456000 | elapsed time per iteration (ms): 247.9 | learning rate: 6.405E-05 | global batch size:   128 | lm loss: 1.842196E+00 | sop loss: 7.231142E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.99 | backward-compute: 79.81 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 14.34
 iteration   403000/10000000 | consumed samples:     51584000 | elapsed time per iteration (ms): 248.3 | learning rate: 6.396E-05 | global batch size:   128 | lm loss: 1.840367E+00 | sop loss: 7.322828E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.87 | backward-compute: 79.76 | backward-params-all-reduce: 15.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.89 | optimizer-unscale-and-check-inf: 2.31 | optimizer-clip-main-grad: 4.35 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.88 | batch-generator: 14.08
 iteration   404000/10000000 | consumed samples:     51712000 | elapsed time per iteration (ms): 248.9 | learning rate: 6.386E-05 | global batch size:   128 | lm loss: 1.840909E+00 | sop loss: 7.269062E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.01 | backward-compute: 79.78 | backward-params-all-reduce: 14.71 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.25 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.72 | batch-generator: 13.89
 iteration   405000/10000000 | consumed samples:     51840000 | elapsed time per iteration (ms): 246.2 | learning rate: 6.377E-05 | global batch size:   128 | lm loss: 1.839550E+00 | sop loss: 7.185568E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.50 | backward-compute: 79.82 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.33 | batch-generator: 19.75
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 405000 | lm loss value: 1.893648E+00 | lm loss PPL: 6.643560E+00 | sop loss value: 6.998134E-02 | sop loss PPL: 1.072488E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   406000/10000000 | consumed samples:     51968000 | elapsed time per iteration (ms): 249.1 | learning rate: 6.368E-05 | global batch size:   128 | lm loss: 1.838021E+00 | sop loss: 7.341443E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.65 | backward-compute: 79.80 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.33 | batch-generator: 14.62
 iteration   407000/10000000 | consumed samples:     52096000 | elapsed time per iteration (ms): 247.7 | learning rate: 6.359E-05 | global batch size:   128 | lm loss: 1.837157E+00 | sop loss: 7.139568E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.14 | backward-compute: 79.78 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.28 | batch-generator: 14.41
 iteration   408000/10000000 | consumed samples:     52224000 | elapsed time per iteration (ms): 249.0 | learning rate: 6.350E-05 | global batch size:   128 | lm loss: 1.835573E+00 | sop loss: 7.165215E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.36 | backward-compute: 79.88 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 16.72
 iteration   409000/10000000 | consumed samples:     52352000 | elapsed time per iteration (ms): 246.4 | learning rate: 6.341E-05 | global batch size:   128 | lm loss: 1.834994E+00 | sop loss: 7.154972E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.78 | backward-compute: 79.93 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 16.27
 iteration   410000/10000000 | consumed samples:     52480000 | elapsed time per iteration (ms): 245.8 | learning rate: 6.331E-05 | global batch size:   128 | lm loss: 1.840189E+00 | sop loss: 7.200529E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.05 | backward-compute: 79.90 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 15.98
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 410000 | lm loss value: 1.870062E+00 | lm loss PPL: 6.488696E+00 | sop loss value: 9.181191E-02 | sop loss PPL: 1.096159E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   411000/10000000 | consumed samples:     52608000 | elapsed time per iteration (ms): 250.4 | learning rate: 6.322E-05 | global batch size:   128 | lm loss: 1.835889E+00 | sop loss: 7.285148E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.35 | backward-compute: 79.80 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.95 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.25 | batch-generator: 11.74
 iteration   412000/10000000 | consumed samples:     52736000 | elapsed time per iteration (ms): 248.9 | learning rate: 6.313E-05 | global batch size:   128 | lm loss: 1.835876E+00 | sop loss: 7.041020E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.44 | backward-compute: 79.73 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.27 | batch-generator: 17.30
 iteration   413000/10000000 | consumed samples:     52864000 | elapsed time per iteration (ms): 248.2 | learning rate: 6.304E-05 | global batch size:   128 | lm loss: 1.835516E+00 | sop loss: 7.211718E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.65 | backward-compute: 79.80 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.29 | batch-generator: 17.18
 iteration   414000/10000000 | consumed samples:     52992000 | elapsed time per iteration (ms): 248.9 | learning rate: 6.295E-05 | global batch size:   128 | lm loss: 1.833350E+00 | sop loss: 7.034590E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.44 | backward-compute: 79.78 | backward-params-all-reduce: 13.92 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.27 | batch-generator: 12.21
 iteration   415000/10000000 | consumed samples:     53120000 | elapsed time per iteration (ms): 249.0 | learning rate: 6.286E-05 | global batch size:   128 | lm loss: 1.834455E+00 | sop loss: 7.151367E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.35 | backward-compute: 79.79 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.36 | batch-generator: 14.93
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 415000 | lm loss value: 1.850998E+00 | lm loss PPL: 6.366167E+00 | sop loss value: 8.058932E-02 | sop loss PPL: 1.083926E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   416000/10000000 | consumed samples:     53248000 | elapsed time per iteration (ms): 250.4 | learning rate: 6.276E-05 | global batch size:   128 | lm loss: 1.831681E+00 | sop loss: 7.061136E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.40 | backward-compute: 79.82 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.96 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.29 | batch-generator: 18.61
 iteration   417000/10000000 | consumed samples:     53376000 | elapsed time per iteration (ms): 247.8 | learning rate: 6.267E-05 | global batch size:   128 | lm loss: 1.834700E+00 | sop loss: 7.082956E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.08 | backward-compute: 79.85 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 15.87
 iteration   418000/10000000 | consumed samples:     53504000 | elapsed time per iteration (ms): 247.0 | learning rate: 6.258E-05 | global batch size:   128 | lm loss: 1.833572E+00 | sop loss: 7.156912E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.66 | backward-compute: 79.94 | backward-params-all-reduce: 14.86 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.89 | optimizer-unscale-and-check-inf: 2.31 | optimizer-clip-main-grad: 4.37 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.91 | batch-generator: 16.38
 iteration   419000/10000000 | consumed samples:     53632000 | elapsed time per iteration (ms): 247.0 | learning rate: 6.249E-05 | global batch size:   128 | lm loss: 1.831701E+00 | sop loss: 7.221646E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.44 | backward-compute: 79.92 | backward-params-all-reduce: 15.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.89 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.36 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.91 | batch-generator: 14.48
 iteration   420000/10000000 | consumed samples:     53760000 | elapsed time per iteration (ms): 251.5 | learning rate: 6.240E-05 | global batch size:   128 | lm loss: 1.833044E+00 | sop loss: 7.094785E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.04 | backward-compute: 79.77 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.95 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.27 | batch-generator: 14.68
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 420000 | lm loss value: 1.925722E+00 | lm loss PPL: 6.860097E+00 | sop loss value: 8.257125E-02 | sop loss PPL: 1.086076E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   421000/10000000 | consumed samples:     53888000 | elapsed time per iteration (ms): 248.5 | learning rate: 6.231E-05 | global batch size:   128 | lm loss: 1.833623E+00 | sop loss: 7.280906E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.17 | backward-compute: 79.76 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.32 | batch-generator: 15.84
 iteration   422000/10000000 | consumed samples:     54016000 | elapsed time per iteration (ms): 248.2 | learning rate: 6.221E-05 | global batch size:   128 | lm loss: 1.833619E+00 | sop loss: 7.134225E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.17 | backward-compute: 79.77 | backward-params-all-reduce: 14.28 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.49 | batch-generator: 16.09
 iteration   423000/10000000 | consumed samples:     54144000 | elapsed time per iteration (ms): 248.3 | learning rate: 6.212E-05 | global batch size:   128 | lm loss: 1.830010E+00 | sop loss: 7.131202E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.64 | backward-compute: 79.75 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 18.85
 iteration   424000/10000000 | consumed samples:     54272000 | elapsed time per iteration (ms): 248.4 | learning rate: 6.203E-05 | global batch size:   128 | lm loss: 1.829903E+00 | sop loss: 7.209970E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.45 | backward-compute: 79.73 | backward-params-all-reduce: 14.27 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.50 | batch-generator: 15.15
 iteration   425000/10000000 | consumed samples:     54400000 | elapsed time per iteration (ms): 247.8 | learning rate: 6.194E-05 | global batch size:   128 | lm loss: 1.826428E+00 | sop loss: 7.132304E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.40 | backward-compute: 79.74 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.32 | batch-generator: 14.42
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 425000 | lm loss value: 1.874410E+00 | lm loss PPL: 6.516975E+00 | sop loss value: 6.785416E-02 | sop loss PPL: 1.070209E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   426000/10000000 | consumed samples:     54528000 | elapsed time per iteration (ms): 247.9 | learning rate: 6.185E-05 | global batch size:   128 | lm loss: 1.830148E+00 | sop loss: 7.040613E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.19 | backward-compute: 79.80 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 14.66
 iteration   427000/10000000 | consumed samples:     54656000 | elapsed time per iteration (ms): 248.9 | learning rate: 6.175E-05 | global batch size:   128 | lm loss: 1.828240E+00 | sop loss: 6.886128E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.46 | backward-compute: 79.74 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 20.98
 iteration   428000/10000000 | consumed samples:     54784000 | elapsed time per iteration (ms): 248.7 | learning rate: 6.166E-05 | global batch size:   128 | lm loss: 1.829055E+00 | sop loss: 7.258028E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.21 | backward-compute: 79.75 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.31 | batch-generator: 15.90
 iteration   429000/10000000 | consumed samples:     54912000 | elapsed time per iteration (ms): 247.7 | learning rate: 6.157E-05 | global batch size:   128 | lm loss: 1.831684E+00 | sop loss: 7.334035E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.17 | backward-compute: 79.75 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.29 | batch-generator: 13.79
 iteration   430000/10000000 | consumed samples:     55040000 | elapsed time per iteration (ms): 246.4 | learning rate: 6.148E-05 | global batch size:   128 | lm loss: 1.828512E+00 | sop loss: 7.195637E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.61 | backward-compute: 79.79 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 14.61
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 430000 | lm loss value: 1.885758E+00 | lm loss PPL: 6.591347E+00 | sop loss value: 8.872765E-02 | sop loss PPL: 1.092783E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   431000/10000000 | consumed samples:     55168000 | elapsed time per iteration (ms): 249.4 | learning rate: 6.139E-05 | global batch size:   128 | lm loss: 1.826368E+00 | sop loss: 7.149773E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.09 | backward-compute: 79.79 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.68
 iteration   432000/10000000 | consumed samples:     55296000 | elapsed time per iteration (ms): 248.2 | learning rate: 6.130E-05 | global batch size:   128 | lm loss: 1.828143E+00 | sop loss: 6.997189E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.58 | backward-compute: 79.78 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.30 | batch-generator: 14.83
 iteration   433000/10000000 | consumed samples:     55424000 | elapsed time per iteration (ms): 247.8 | learning rate: 6.120E-05 | global batch size:   128 | lm loss: 1.826785E+00 | sop loss: 7.063342E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.16 | backward-compute: 79.76 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 15.50
 iteration   434000/10000000 | consumed samples:     55552000 | elapsed time per iteration (ms): 248.6 | learning rate: 6.111E-05 | global batch size:   128 | lm loss: 1.823303E+00 | sop loss: 7.136394E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.07 | backward-compute: 79.77 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.96 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.26 | batch-generator: 15.31
 iteration   435000/10000000 | consumed samples:     55680000 | elapsed time per iteration (ms): 247.2 | learning rate: 6.102E-05 | global batch size:   128 | lm loss: 1.827365E+00 | sop loss: 7.205826E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.65 | backward-compute: 79.89 | backward-params-all-reduce: 13.91 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 16.03
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 435000 | lm loss value: 1.814011E+00 | lm loss PPL: 6.135006E+00 | sop loss value: 7.664589E-02 | sop loss PPL: 1.079660E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   436000/10000000 | consumed samples:     55808000 | elapsed time per iteration (ms): 249.7 | learning rate: 6.093E-05 | global batch size:   128 | lm loss: 1.827148E+00 | sop loss: 6.931206E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.55 | backward-compute: 79.73 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.96 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.27 | batch-generator: 16.55
 iteration   437000/10000000 | consumed samples:     55936000 | elapsed time per iteration (ms): 249.5 | learning rate: 6.084E-05 | global batch size:   128 | lm loss: 1.823200E+00 | sop loss: 7.105610E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.17 | backward-compute: 79.72 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.30 | batch-generator: 14.02
 iteration   438000/10000000 | consumed samples:     56064000 | elapsed time per iteration (ms): 248.2 | learning rate: 6.075E-05 | global batch size:   128 | lm loss: 1.823152E+00 | sop loss: 7.196090E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.22 | backward-compute: 79.81 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.48 | batch-generator: 18.32
 iteration   439000/10000000 | consumed samples:     56192000 | elapsed time per iteration (ms): 248.6 | learning rate: 6.065E-05 | global batch size:   128 | lm loss: 1.829118E+00 | sop loss: 6.875896E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.03 | backward-compute: 79.85 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.96 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.29 | batch-generator: 17.16
 iteration   440000/10000000 | consumed samples:     56320000 | elapsed time per iteration (ms): 247.3 | learning rate: 6.056E-05 | global batch size:   128 | lm loss: 1.823434E+00 | sop loss: 7.029817E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.65 | backward-compute: 79.81 | backward-params-all-reduce: 14.66 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.20 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.66 | batch-generator: 13.24
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 440000 | lm loss value: 1.829976E+00 | lm loss PPL: 6.233739E+00 | sop loss value: 8.018575E-02 | sop loss PPL: 1.083488E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   441000/10000000 | consumed samples:     56448000 | elapsed time per iteration (ms): 249.3 | learning rate: 6.047E-05 | global batch size:   128 | lm loss: 1.825227E+00 | sop loss: 7.113971E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.93 | backward-compute: 79.80 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 16.57
 iteration   442000/10000000 | consumed samples:     56576000 | elapsed time per iteration (ms): 247.8 | learning rate: 6.038E-05 | global batch size:   128 | lm loss: 1.822030E+00 | sop loss: 7.191762E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.19 | backward-compute: 79.82 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.30 | batch-generator: 17.21
 iteration   443000/10000000 | consumed samples:     56704000 | elapsed time per iteration (ms): 246.9 | learning rate: 6.029E-05 | global batch size:   128 | lm loss: 1.823360E+00 | sop loss: 7.098819E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.39 | backward-compute: 79.87 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.27 | batch-generator: 14.06
 iteration   444000/10000000 | consumed samples:     56832000 | elapsed time per iteration (ms): 249.3 | learning rate: 6.020E-05 | global batch size:   128 | lm loss: 1.823388E+00 | sop loss: 7.131227E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.77 | backward-compute: 79.76 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.30 | batch-generator: 13.91
 iteration   445000/10000000 | consumed samples:     56960000 | elapsed time per iteration (ms): 247.3 | learning rate: 6.010E-05 | global batch size:   128 | lm loss: 1.818392E+00 | sop loss: 7.058483E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.59 | backward-compute: 79.74 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 17.05
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 445000 | lm loss value: 1.859276E+00 | lm loss PPL: 6.419090E+00 | sop loss value: 1.039436E-01 | sop loss PPL: 1.109538E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   446000/10000000 | consumed samples:     57088000 | elapsed time per iteration (ms): 252.5 | learning rate: 6.001E-05 | global batch size:   128 | lm loss: 1.818913E+00 | sop loss: 7.097908E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.23 | backward-compute: 79.75 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 27.38
 iteration   447000/10000000 | consumed samples:     57216000 | elapsed time per iteration (ms): 248.5 | learning rate: 5.992E-05 | global batch size:   128 | lm loss: 1.822168E+00 | sop loss: 7.118467E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.89 | backward-compute: 79.79 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.29 | batch-generator: 15.36
 iteration   448000/10000000 | consumed samples:     57344000 | elapsed time per iteration (ms): 248.8 | learning rate: 5.983E-05 | global batch size:   128 | lm loss: 1.819350E+00 | sop loss: 7.128508E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.93 | backward-compute: 79.79 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 13.13
 iteration   449000/10000000 | consumed samples:     57472000 | elapsed time per iteration (ms): 248.6 | learning rate: 5.974E-05 | global batch size:   128 | lm loss: 1.817859E+00 | sop loss: 6.948546E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.85 | backward-compute: 79.87 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 18.00
 iteration   450000/10000000 | consumed samples:     57600000 | elapsed time per iteration (ms): 246.6 | learning rate: 5.965E-05 | global batch size:   128 | lm loss: 1.820436E+00 | sop loss: 6.910083E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.78 | backward-compute: 79.79 | backward-params-all-reduce: 14.72 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.22 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.69 | batch-generator: 15.26
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 450000 | lm loss value: 1.880888E+00 | lm loss PPL: 6.559325E+00 | sop loss value: 8.318701E-02 | sop loss PPL: 1.086745E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration  450000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration  450000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2301.82
 iteration   451000/10000000 | consumed samples:     57728000 | elapsed time per iteration (ms): 252.1 | learning rate: 5.955E-05 | global batch size:   128 | lm loss: 1.819583E+00 | sop loss: 7.017021E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.30 | backward-compute: 79.77 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 13.41
 iteration   452000/10000000 | consumed samples:     57856000 | elapsed time per iteration (ms): 248.5 | learning rate: 5.946E-05 | global batch size:   128 | lm loss: 1.817456E+00 | sop loss: 6.862383E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.00 | backward-compute: 79.76 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.96 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.29 | batch-generator: 15.38
 iteration   453000/10000000 | consumed samples:     57984000 | elapsed time per iteration (ms): 249.8 | learning rate: 5.937E-05 | global batch size:   128 | lm loss: 1.818196E+00 | sop loss: 7.146419E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.33 | backward-compute: 79.81 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.33 | batch-generator: 16.95
 iteration   454000/10000000 | consumed samples:     58112000 | elapsed time per iteration (ms): 250.9 | learning rate: 5.928E-05 | global batch size:   128 | lm loss: 1.817962E+00 | sop loss: 7.091773E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.36 | backward-compute: 79.81 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 19.74
 iteration   455000/10000000 | consumed samples:     58240000 | elapsed time per iteration (ms): 245.4 | learning rate: 5.919E-05 | global batch size:   128 | lm loss: 1.817008E+00 | sop loss: 6.932964E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.69 | backward-compute: 79.79 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.33 | batch-generator: 17.75
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 455000 | lm loss value: 1.880711E+00 | lm loss PPL: 6.558169E+00 | sop loss value: 9.802554E-02 | sop loss PPL: 1.102991E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   456000/10000000 | consumed samples:     58368000 | elapsed time per iteration (ms): 250.7 | learning rate: 5.910E-05 | global batch size:   128 | lm loss: 1.817548E+00 | sop loss: 6.957445E-02 | loss scale: 65536.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.45 | backward-compute: 79.81 | backward-params-all-reduce: 14.68 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.21 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.68 | batch-generator: 16.03
 iteration   457000/10000000 | consumed samples:     58496000 | elapsed time per iteration (ms): 246.7 | learning rate: 5.900E-05 | global batch size:   128 | lm loss: 1.818040E+00 | sop loss: 7.180078E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.05 | backward-compute: 79.84 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 17.61
 iteration   458000/10000000 | consumed samples:     58624000 | elapsed time per iteration (ms): 248.3 | learning rate: 5.891E-05 | global batch size:   128 | lm loss: 1.813283E+00 | sop loss: 6.932981E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.72 | backward-compute: 79.85 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.31 | batch-generator: 14.30
 iteration   459000/10000000 | consumed samples:     58752000 | elapsed time per iteration (ms): 247.9 | learning rate: 5.882E-05 | global batch size:   128 | lm loss: 1.814313E+00 | sop loss: 7.069140E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.33 | backward-compute: 79.77 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.96 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.28 | batch-generator: 16.39
 iteration   460000/10000000 | consumed samples:     58880000 | elapsed time per iteration (ms): 249.2 | learning rate: 5.873E-05 | global batch size:   128 | lm loss: 1.816115E+00 | sop loss: 6.964361E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.66 | backward-compute: 79.76 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.34 | batch-generator: 15.62
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 460000 | lm loss value: 1.873361E+00 | lm loss PPL: 6.510143E+00 | sop loss value: 9.777369E-02 | sop loss PPL: 1.102713E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   461000/10000000 | consumed samples:     59008000 | elapsed time per iteration (ms): 250.7 | learning rate: 5.864E-05 | global batch size:   128 | lm loss: 1.812630E+00 | sop loss: 6.815278E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.57 | backward-compute: 79.83 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.31 | batch-generator: 14.78
 iteration   462000/10000000 | consumed samples:     59136000 | elapsed time per iteration (ms): 246.9 | learning rate: 5.855E-05 | global batch size:   128 | lm loss: 1.813492E+00 | sop loss: 6.860362E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.13 | backward-compute: 79.91 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 16.13
 iteration   463000/10000000 | consumed samples:     59264000 | elapsed time per iteration (ms): 248.7 | learning rate: 5.845E-05 | global batch size:   128 | lm loss: 1.811779E+00 | sop loss: 7.057062E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.93 | backward-compute: 79.84 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 13.80
 iteration   464000/10000000 | consumed samples:     59392000 | elapsed time per iteration (ms): 249.7 | learning rate: 5.836E-05 | global batch size:   128 | lm loss: 1.813994E+00 | sop loss: 6.981722E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.21 | backward-compute: 79.82 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.31 | batch-generator: 13.17
 iteration   465000/10000000 | consumed samples:     59520000 | elapsed time per iteration (ms): 248.6 | learning rate: 5.827E-05 | global batch size:   128 | lm loss: 1.813545E+00 | sop loss: 7.045737E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.41 | backward-compute: 79.79 | backward-params-all-reduce: 14.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.52 | batch-generator: 14.78
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 465000 | lm loss value: 1.879131E+00 | lm loss PPL: 6.547814E+00 | sop loss value: 6.799275E-02 | sop loss PPL: 1.070358E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   466000/10000000 | consumed samples:     59648000 | elapsed time per iteration (ms): 249.2 | learning rate: 5.818E-05 | global batch size:   128 | lm loss: 1.809173E+00 | sop loss: 7.005724E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.06 | backward-compute: 79.79 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.31 | batch-generator: 16.20
 iteration   467000/10000000 | consumed samples:     59776000 | elapsed time per iteration (ms): 247.9 | learning rate: 5.809E-05 | global batch size:   128 | lm loss: 1.815507E+00 | sop loss: 6.845157E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.27 | backward-compute: 79.80 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.31 | batch-generator: 14.30
 iteration   468000/10000000 | consumed samples:     59904000 | elapsed time per iteration (ms): 247.5 | learning rate: 5.799E-05 | global batch size:   128 | lm loss: 1.817391E+00 | sop loss: 6.958263E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.78 | backward-compute: 79.82 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 16.30
 iteration   469000/10000000 | consumed samples:     60032000 | elapsed time per iteration (ms): 246.5 | learning rate: 5.790E-05 | global batch size:   128 | lm loss: 1.814547E+00 | sop loss: 6.814685E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.67 | backward-compute: 79.81 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 17.32
 iteration   470000/10000000 | consumed samples:     60160000 | elapsed time per iteration (ms): 247.9 | learning rate: 5.781E-05 | global batch size:   128 | lm loss: 1.811383E+00 | sop loss: 6.860352E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.30 | backward-compute: 79.77 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.31 | batch-generator: 16.38
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 470000 | lm loss value: 1.861475E+00 | lm loss PPL: 6.433218E+00 | sop loss value: 6.961719E-02 | sop loss PPL: 1.072098E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   471000/10000000 | consumed samples:     60288000 | elapsed time per iteration (ms): 249.2 | learning rate: 5.772E-05 | global batch size:   128 | lm loss: 1.809847E+00 | sop loss: 6.869891E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.04 | backward-compute: 79.79 | backward-params-all-reduce: 14.47 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.60 | batch-generator: 17.10
 iteration   472000/10000000 | consumed samples:     60416000 | elapsed time per iteration (ms): 245.8 | learning rate: 5.763E-05 | global batch size:   128 | lm loss: 1.809149E+00 | sop loss: 6.995267E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.19 | backward-compute: 79.75 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.29 | batch-generator: 17.74
 iteration   473000/10000000 | consumed samples:     60544000 | elapsed time per iteration (ms): 249.9 | learning rate: 5.754E-05 | global batch size:   128 | lm loss: 1.809537E+00 | sop loss: 7.071407E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.35 | backward-compute: 79.79 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.30 | batch-generator: 17.86
 iteration   474000/10000000 | consumed samples:     60672000 | elapsed time per iteration (ms): 246.6 | learning rate: 5.744E-05 | global batch size:   128 | lm loss: 1.811541E+00 | sop loss: 6.976485E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.94 | backward-compute: 79.79 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.30 | batch-generator: 15.31
 iteration   475000/10000000 | consumed samples:     60800000 | elapsed time per iteration (ms): 246.8 | learning rate: 5.735E-05 | global batch size:   128 | lm loss: 1.810347E+00 | sop loss: 7.046200E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.93 | backward-compute: 79.88 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 18.88
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 475000 | lm loss value: 1.860443E+00 | lm loss PPL: 6.426586E+00 | sop loss value: 7.779967E-02 | sop loss PPL: 1.080906E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   476000/10000000 | consumed samples:     60928000 | elapsed time per iteration (ms): 249.0 | learning rate: 5.726E-05 | global batch size:   128 | lm loss: 1.811747E+00 | sop loss: 6.925915E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.47 | backward-compute: 79.74 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 13.87
 iteration   477000/10000000 | consumed samples:     61056000 | elapsed time per iteration (ms): 248.3 | learning rate: 5.717E-05 | global batch size:   128 | lm loss: 1.811793E+00 | sop loss: 7.081779E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.63 | backward-compute: 79.80 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 17.92
 iteration   478000/10000000 | consumed samples:     61184000 | elapsed time per iteration (ms): 249.9 | learning rate: 5.708E-05 | global batch size:   128 | lm loss: 1.809356E+00 | sop loss: 6.845596E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.54 | backward-compute: 79.77 | backward-params-all-reduce: 13.92 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.24 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.28 | batch-generator: 14.92
 iteration   479000/10000000 | consumed samples:     61312000 | elapsed time per iteration (ms): 248.7 | learning rate: 5.699E-05 | global batch size:   128 | lm loss: 1.807773E+00 | sop loss: 6.977285E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.16 | backward-compute: 79.79 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.30 | batch-generator: 23.11
 iteration   480000/10000000 | consumed samples:     61440000 | elapsed time per iteration (ms): 247.2 | learning rate: 5.689E-05 | global batch size:   128 | lm loss: 1.809088E+00 | sop loss: 6.842603E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.64 | backward-compute: 79.80 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 17.68
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 480000 | lm loss value: 1.885266E+00 | lm loss PPL: 6.588109E+00 | sop loss value: 9.275115E-02 | sop loss PPL: 1.097189E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   481000/10000000 | consumed samples:     61568000 | elapsed time per iteration (ms): 248.4 | learning rate: 5.680E-05 | global batch size:   128 | lm loss: 1.809296E+00 | sop loss: 6.907236E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.06 | backward-compute: 79.81 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 15.30
 iteration   482000/10000000 | consumed samples:     61696000 | elapsed time per iteration (ms): 248.1 | learning rate: 5.671E-05 | global batch size:   128 | lm loss: 1.803651E+00 | sop loss: 6.996974E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.51 | backward-compute: 79.83 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 14.52
 iteration   483000/10000000 | consumed samples:     61824000 | elapsed time per iteration (ms): 248.9 | learning rate: 5.662E-05 | global batch size:   128 | lm loss: 1.804642E+00 | sop loss: 6.847124E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.23 | backward-compute: 79.84 | backward-params-all-reduce: 14.66 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.21 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.64 | batch-generator: 13.93
 iteration   484000/10000000 | consumed samples:     61952000 | elapsed time per iteration (ms): 250.0 | learning rate: 5.653E-05 | global batch size:   128 | lm loss: 1.806230E+00 | sop loss: 6.844472E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.44 | backward-compute: 79.77 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 12.55
 iteration   485000/10000000 | consumed samples:     62080000 | elapsed time per iteration (ms): 248.3 | learning rate: 5.644E-05 | global batch size:   128 | lm loss: 1.803222E+00 | sop loss: 6.868205E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.53 | backward-compute: 79.73 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 13.81
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 485000 | lm loss value: 1.848771E+00 | lm loss PPL: 6.352011E+00 | sop loss value: 8.671557E-02 | sop loss PPL: 1.090586E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   486000/10000000 | consumed samples:     62208000 | elapsed time per iteration (ms): 250.7 | learning rate: 5.634E-05 | global batch size:   128 | lm loss: 1.804264E+00 | sop loss: 6.973666E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.77 | backward-compute: 79.74 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.31 | batch-generator: 17.11
 iteration   487000/10000000 | consumed samples:     62336000 | elapsed time per iteration (ms): 248.1 | learning rate: 5.625E-05 | global batch size:   128 | lm loss: 1.807339E+00 | sop loss: 6.815353E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.50 | backward-compute: 79.76 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 17.16
 iteration   488000/10000000 | consumed samples:     62464000 | elapsed time per iteration (ms): 247.1 | learning rate: 5.616E-05 | global batch size:   128 | lm loss: 1.804849E+00 | sop loss: 6.826373E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.22 | backward-compute: 79.93 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 13.19
 iteration   489000/10000000 | consumed samples:     62592000 | elapsed time per iteration (ms): 249.0 | learning rate: 5.607E-05 | global batch size:   128 | lm loss: 1.804693E+00 | sop loss: 6.846071E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.45 | backward-compute: 79.92 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.28 | batch-generator: 12.88
 iteration   490000/10000000 | consumed samples:     62720000 | elapsed time per iteration (ms): 246.7 | learning rate: 5.598E-05 | global batch size:   128 | lm loss: 1.802679E+00 | sop loss: 6.713605E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.98 | backward-compute: 79.83 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 14.54
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 490000 | lm loss value: 1.849983E+00 | lm loss PPL: 6.359711E+00 | sop loss value: 8.093134E-02 | sop loss PPL: 1.084296E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   491000/10000000 | consumed samples:     62848000 | elapsed time per iteration (ms): 250.4 | learning rate: 5.589E-05 | global batch size:   128 | lm loss: 1.804726E+00 | sop loss: 6.759034E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.00 | backward-compute: 79.85 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.81
 iteration   492000/10000000 | consumed samples:     62976000 | elapsed time per iteration (ms): 247.7 | learning rate: 5.579E-05 | global batch size:   128 | lm loss: 1.802660E+00 | sop loss: 6.819056E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.35 | backward-compute: 79.86 | backward-params-all-reduce: 14.38 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.61 | batch-generator: 14.96
 iteration   493000/10000000 | consumed samples:     63104000 | elapsed time per iteration (ms): 248.5 | learning rate: 5.570E-05 | global batch size:   128 | lm loss: 1.799921E+00 | sop loss: 6.816398E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.72 | backward-compute: 79.81 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 14.02
 iteration   494000/10000000 | consumed samples:     63232000 | elapsed time per iteration (ms): 249.6 | learning rate: 5.561E-05 | global batch size:   128 | lm loss: 1.801911E+00 | sop loss: 6.963556E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.98 | backward-compute: 79.78 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 16.79
 iteration   495000/10000000 | consumed samples:     63360000 | elapsed time per iteration (ms): 248.9 | learning rate: 5.552E-05 | global batch size:   128 | lm loss: 1.801757E+00 | sop loss: 6.962402E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.35 | backward-compute: 79.76 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 17.20
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 495000 | lm loss value: 1.819199E+00 | lm loss PPL: 6.166920E+00 | sop loss value: 8.517177E-02 | sop loss PPL: 1.088904E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   496000/10000000 | consumed samples:     63488000 | elapsed time per iteration (ms): 248.8 | learning rate: 5.543E-05 | global batch size:   128 | lm loss: 1.798583E+00 | sop loss: 6.843524E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.35 | backward-compute: 79.86 | backward-params-all-reduce: 14.29 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 17.67
 iteration   497000/10000000 | consumed samples:     63616000 | elapsed time per iteration (ms): 247.9 | learning rate: 5.534E-05 | global batch size:   128 | lm loss: 1.799266E+00 | sop loss: 6.918405E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.33 | backward-compute: 79.83 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.26 | batch-generator: 15.89
 iteration   498000/10000000 | consumed samples:     63744000 | elapsed time per iteration (ms): 249.6 | learning rate: 5.524E-05 | global batch size:   128 | lm loss: 1.799914E+00 | sop loss: 6.841674E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.83 | backward-compute: 79.77 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 16.15
 iteration   499000/10000000 | consumed samples:     63872000 | elapsed time per iteration (ms): 246.5 | learning rate: 5.515E-05 | global batch size:   128 | lm loss: 1.801521E+00 | sop loss: 6.822974E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.85 | backward-compute: 79.80 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 17.44
 iteration   500000/10000000 | consumed samples:     64000000 | elapsed time per iteration (ms): 248.3 | learning rate: 5.506E-05 | global batch size:   128 | lm loss: 1.798291E+00 | sop loss: 6.813836E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.84 | backward-compute: 79.78 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 15.35
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 500000 | lm loss value: 1.874424E+00 | lm loss PPL: 6.517066E+00 | sop loss value: 1.109388E-01 | sop loss PPL: 1.117326E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration  500000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration  500000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2339.06
 iteration   501000/10000000 | consumed samples:     64128000 | elapsed time per iteration (ms): 254.1 | learning rate: 5.497E-05 | global batch size:   128 | lm loss: 1.797946E+00 | sop loss: 6.834965E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.69 | backward-compute: 79.76 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 12.16
 iteration   502000/10000000 | consumed samples:     64256000 | elapsed time per iteration (ms): 246.8 | learning rate: 5.488E-05 | global batch size:   128 | lm loss: 1.797390E+00 | sop loss: 6.682130E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.33 | backward-compute: 79.74 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 15.77
 iteration   503000/10000000 | consumed samples:     64384000 | elapsed time per iteration (ms): 247.5 | learning rate: 5.479E-05 | global batch size:   128 | lm loss: 1.799017E+00 | sop loss: 6.697125E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.85 | backward-compute: 79.78 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 16.39
 iteration   504000/10000000 | consumed samples:     64512000 | elapsed time per iteration (ms): 246.8 | learning rate: 5.469E-05 | global batch size:   128 | lm loss: 1.803108E+00 | sop loss: 6.704784E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.95 | backward-compute: 79.83 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 16.19
 iteration   505000/10000000 | consumed samples:     64640000 | elapsed time per iteration (ms): 246.0 | learning rate: 5.460E-05 | global batch size:   128 | lm loss: 1.798408E+00 | sop loss: 6.845607E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.32 | backward-compute: 79.84 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 15.51
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 505000 | lm loss value: 1.887253E+00 | lm loss PPL: 6.601213E+00 | sop loss value: 8.572232E-02 | sop loss PPL: 1.089504E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   506000/10000000 | consumed samples:     64768000 | elapsed time per iteration (ms): 248.0 | learning rate: 5.451E-05 | global batch size:   128 | lm loss: 1.798384E+00 | sop loss: 6.842220E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.81 | backward-compute: 79.79 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.30 | batch-generator: 16.92
 iteration   507000/10000000 | consumed samples:     64896000 | elapsed time per iteration (ms): 247.8 | learning rate: 5.442E-05 | global batch size:   128 | lm loss: 1.797877E+00 | sop loss: 7.056616E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.35 | backward-compute: 79.67 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.28 | batch-generator: 17.17
 iteration   508000/10000000 | consumed samples:     65024000 | elapsed time per iteration (ms): 249.5 | learning rate: 5.433E-05 | global batch size:   128 | lm loss: 1.797436E+00 | sop loss: 6.907512E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.91 | backward-compute: 79.76 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 16.13
 iteration   509000/10000000 | consumed samples:     65152000 | elapsed time per iteration (ms): 247.7 | learning rate: 5.423E-05 | global batch size:   128 | lm loss: 1.794798E+00 | sop loss: 6.711116E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.03 | backward-compute: 79.81 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.33 | batch-generator: 16.09
 iteration   510000/10000000 | consumed samples:     65280000 | elapsed time per iteration (ms): 246.5 | learning rate: 5.414E-05 | global batch size:   128 | lm loss: 1.793348E+00 | sop loss: 6.833998E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.76 | backward-compute: 79.83 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 15.84
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 510000 | lm loss value: 1.838022E+00 | lm loss PPL: 6.284093E+00 | sop loss value: 7.268774E-02 | sop loss PPL: 1.075395E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   511000/10000000 | consumed samples:     65408000 | elapsed time per iteration (ms): 248.4 | learning rate: 5.405E-05 | global batch size:   128 | lm loss: 1.795361E+00 | sop loss: 6.827088E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.54 | backward-compute: 79.75 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.30 | batch-generator: 14.35
 iteration   512000/10000000 | consumed samples:     65536000 | elapsed time per iteration (ms): 247.9 | learning rate: 5.396E-05 | global batch size:   128 | lm loss: 1.796761E+00 | sop loss: 6.782041E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.33 | backward-compute: 79.81 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 14.07
 iteration   513000/10000000 | consumed samples:     65664000 | elapsed time per iteration (ms): 249.3 | learning rate: 5.387E-05 | global batch size:   128 | lm loss: 1.795267E+00 | sop loss: 6.848846E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.67 | backward-compute: 79.82 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.32 | batch-generator: 17.65
 iteration   514000/10000000 | consumed samples:     65792000 | elapsed time per iteration (ms): 247.2 | learning rate: 5.378E-05 | global batch size:   128 | lm loss: 1.797013E+00 | sop loss: 6.855585E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.49 | backward-compute: 79.85 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 17.78
 iteration   515000/10000000 | consumed samples:     65920000 | elapsed time per iteration (ms): 249.5 | learning rate: 5.368E-05 | global batch size:   128 | lm loss: 1.795739E+00 | sop loss: 6.645657E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.98 | backward-compute: 79.82 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 15.16
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 515000 | lm loss value: 1.856060E+00 | lm loss PPL: 6.398480E+00 | sop loss value: 7.968119E-02 | sop loss PPL: 1.082942E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   516000/10000000 | consumed samples:     66048000 | elapsed time per iteration (ms): 249.1 | learning rate: 5.359E-05 | global batch size:   128 | lm loss: 1.794025E+00 | sop loss: 6.836944E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.74 | backward-compute: 79.77 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 16.64
 iteration   517000/10000000 | consumed samples:     66176000 | elapsed time per iteration (ms): 247.3 | learning rate: 5.350E-05 | global batch size:   128 | lm loss: 1.793528E+00 | sop loss: 6.822241E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.92 | backward-compute: 79.75 | backward-params-all-reduce: 14.42 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.20 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.63 | batch-generator: 14.62
 iteration   518000/10000000 | consumed samples:     66304000 | elapsed time per iteration (ms): 247.8 | learning rate: 5.341E-05 | global batch size:   128 | lm loss: 1.795611E+00 | sop loss: 6.852706E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.14 | backward-compute: 79.78 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.33 | batch-generator: 15.23
 iteration   519000/10000000 | consumed samples:     66432000 | elapsed time per iteration (ms): 247.5 | learning rate: 5.332E-05 | global batch size:   128 | lm loss: 1.792218E+00 | sop loss: 6.775876E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.81 | backward-compute: 79.79 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.33 | batch-generator: 11.45
 iteration   520000/10000000 | consumed samples:     66560000 | elapsed time per iteration (ms): 246.8 | learning rate: 5.323E-05 | global batch size:   128 | lm loss: 1.793748E+00 | sop loss: 6.883732E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.12 | backward-compute: 79.87 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.33 | batch-generator: 14.41
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 520000 | lm loss value: 1.860784E+00 | lm loss PPL: 6.428776E+00 | sop loss value: 8.448444E-02 | sop loss PPL: 1.088156E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   521000/10000000 | consumed samples:     66688000 | elapsed time per iteration (ms): 250.3 | learning rate: 5.313E-05 | global batch size:   128 | lm loss: 1.790653E+00 | sop loss: 6.722367E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.56 | backward-compute: 79.80 | backward-params-all-reduce: 14.27 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 15.16
 iteration   522000/10000000 | consumed samples:     66816000 | elapsed time per iteration (ms): 248.3 | learning rate: 5.304E-05 | global batch size:   128 | lm loss: 1.793265E+00 | sop loss: 6.962942E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.73 | backward-compute: 79.80 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 16.40
 iteration   523000/10000000 | consumed samples:     66944000 | elapsed time per iteration (ms): 248.7 | learning rate: 5.295E-05 | global batch size:   128 | lm loss: 1.795557E+00 | sop loss: 6.883237E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.20 | backward-compute: 79.76 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.27 | batch-generator: 14.15
 iteration   524000/10000000 | consumed samples:     67072000 | elapsed time per iteration (ms): 248.8 | learning rate: 5.286E-05 | global batch size:   128 | lm loss: 1.792828E+00 | sop loss: 6.737182E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.38 | backward-compute: 79.90 | backward-params-all-reduce: 14.43 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.57 | batch-generator: 13.97
 iteration   525000/10000000 | consumed samples:     67200000 | elapsed time per iteration (ms): 247.3 | learning rate: 5.277E-05 | global batch size:   128 | lm loss: 1.792604E+00 | sop loss: 6.671458E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.36 | backward-compute: 79.83 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 13.36
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 525000 | lm loss value: 1.842442E+00 | lm loss PPL: 6.311930E+00 | sop loss value: 6.257709E-02 | sop loss PPL: 1.064577E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   526000/10000000 | consumed samples:     67328000 | elapsed time per iteration (ms): 248.0 | learning rate: 5.268E-05 | global batch size:   128 | lm loss: 1.792388E+00 | sop loss: 6.625693E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.87 | backward-compute: 79.82 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 12.31
 iteration   527000/10000000 | consumed samples:     67456000 | elapsed time per iteration (ms): 247.6 | learning rate: 5.258E-05 | global batch size:   128 | lm loss: 1.793374E+00 | sop loss: 6.678775E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.83 | backward-compute: 79.83 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 14.50
 iteration   528000/10000000 | consumed samples:     67584000 | elapsed time per iteration (ms): 248.7 | learning rate: 5.249E-05 | global batch size:   128 | lm loss: 1.790134E+00 | sop loss: 6.703568E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.98 | backward-compute: 79.81 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 14.71
 iteration   529000/10000000 | consumed samples:     67712000 | elapsed time per iteration (ms): 247.0 | learning rate: 5.240E-05 | global batch size:   128 | lm loss: 1.792057E+00 | sop loss: 6.837947E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.64 | backward-compute: 79.80 | backward-params-all-reduce: 14.50 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.60 | batch-generator: 14.23
 iteration   530000/10000000 | consumed samples:     67840000 | elapsed time per iteration (ms): 247.5 | learning rate: 5.231E-05 | global batch size:   128 | lm loss: 1.791532E+00 | sop loss: 6.648200E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.59 | backward-compute: 79.75 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 17.37
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 530000 | lm loss value: 1.827015E+00 | lm loss PPL: 6.215304E+00 | sop loss value: 8.800042E-02 | sop loss PPL: 1.091989E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   531000/10000000 | consumed samples:     67968000 | elapsed time per iteration (ms): 248.6 | learning rate: 5.222E-05 | global batch size:   128 | lm loss: 1.787024E+00 | sop loss: 6.830740E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.27 | backward-compute: 79.71 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 12.30
 iteration   532000/10000000 | consumed samples:     68096000 | elapsed time per iteration (ms): 247.5 | learning rate: 5.213E-05 | global batch size:   128 | lm loss: 1.787321E+00 | sop loss: 6.727789E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.85 | backward-compute: 79.77 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 20.71
 iteration   533000/10000000 | consumed samples:     68224000 | elapsed time per iteration (ms): 246.2 | learning rate: 5.203E-05 | global batch size:   128 | lm loss: 1.788065E+00 | sop loss: 6.823897E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.66 | backward-compute: 79.83 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 15.31
 iteration   534000/10000000 | consumed samples:     68352000 | elapsed time per iteration (ms): 247.9 | learning rate: 5.194E-05 | global batch size:   128 | lm loss: 1.786536E+00 | sop loss: 6.915607E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.81 | backward-compute: 79.81 | backward-params-all-reduce: 14.76 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.88 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.32 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.84 | batch-generator: 14.26
 iteration   535000/10000000 | consumed samples:     68480000 | elapsed time per iteration (ms): 247.6 | learning rate: 5.185E-05 | global batch size:   128 | lm loss: 1.785883E+00 | sop loss: 6.644920E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.93 | backward-compute: 79.83 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 15.45
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 535000 | lm loss value: 1.858808E+00 | lm loss PPL: 6.416084E+00 | sop loss value: 8.757581E-02 | sop loss PPL: 1.091525E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   536000/10000000 | consumed samples:     68608000 | elapsed time per iteration (ms): 249.3 | learning rate: 5.176E-05 | global batch size:   128 | lm loss: 1.788917E+00 | sop loss: 6.772987E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.99 | backward-compute: 79.79 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.29 | batch-generator: 15.41
 iteration   537000/10000000 | consumed samples:     68736000 | elapsed time per iteration (ms): 249.1 | learning rate: 5.167E-05 | global batch size:   128 | lm loss: 1.786825E+00 | sop loss: 6.813168E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.51 | backward-compute: 79.77 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 20.18
 iteration   538000/10000000 | consumed samples:     68864000 | elapsed time per iteration (ms): 248.3 | learning rate: 5.158E-05 | global batch size:   128 | lm loss: 1.784411E+00 | sop loss: 6.563945E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.78 | backward-compute: 79.81 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.30 | batch-generator: 22.74
 iteration   539000/10000000 | consumed samples:     68992000 | elapsed time per iteration (ms): 249.0 | learning rate: 5.148E-05 | global batch size:   128 | lm loss: 1.784998E+00 | sop loss: 6.546639E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.34 | backward-compute: 79.81 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 20.21
 iteration   540000/10000000 | consumed samples:     69120000 | elapsed time per iteration (ms): 250.4 | learning rate: 5.139E-05 | global batch size:   128 | lm loss: 1.785368E+00 | sop loss: 6.714226E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.88 | backward-compute: 79.81 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 16.54
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 540000 | lm loss value: 1.831645E+00 | lm loss PPL: 6.244151E+00 | sop loss value: 7.898542E-02 | sop loss PPL: 1.082189E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   541000/10000000 | consumed samples:     69248000 | elapsed time per iteration (ms): 248.9 | learning rate: 5.130E-05 | global batch size:   128 | lm loss: 1.787178E+00 | sop loss: 6.719202E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.60 | backward-compute: 79.74 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 13.25
 iteration   542000/10000000 | consumed samples:     69376000 | elapsed time per iteration (ms): 246.9 | learning rate: 5.121E-05 | global batch size:   128 | lm loss: 1.786703E+00 | sop loss: 6.769563E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.26 | backward-compute: 79.73 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 15.79
 iteration   543000/10000000 | consumed samples:     69504000 | elapsed time per iteration (ms): 247.8 | learning rate: 5.112E-05 | global batch size:   128 | lm loss: 1.785571E+00 | sop loss: 6.590702E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.49 | backward-compute: 79.80 | backward-params-all-reduce: 14.84 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.88 | optimizer-unscale-and-check-inf: 2.31 | optimizer-clip-main-grad: 4.36 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.88 | batch-generator: 18.79
 iteration   544000/10000000 | consumed samples:     69632000 | elapsed time per iteration (ms): 246.9 | learning rate: 5.103E-05 | global batch size:   128 | lm loss: 1.787507E+00 | sop loss: 6.685209E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.18 | backward-compute: 79.83 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.29 | batch-generator: 13.97
 iteration   545000/10000000 | consumed samples:     69760000 | elapsed time per iteration (ms): 250.2 | learning rate: 5.093E-05 | global batch size:   128 | lm loss: 1.782987E+00 | sop loss: 6.663939E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.79 | backward-compute: 79.74 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.97 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.26 | batch-generator: 15.93
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 545000 | lm loss value: 1.825086E+00 | lm loss PPL: 6.203326E+00 | sop loss value: 7.797401E-02 | sop loss PPL: 1.081095E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   546000/10000000 | consumed samples:     69888000 | elapsed time per iteration (ms): 247.4 | learning rate: 5.084E-05 | global batch size:   128 | lm loss: 1.785545E+00 | sop loss: 6.539065E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.20 | backward-compute: 79.79 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 18.79
 iteration   547000/10000000 | consumed samples:     70016000 | elapsed time per iteration (ms): 247.8 | learning rate: 5.075E-05 | global batch size:   128 | lm loss: 1.785821E+00 | sop loss: 6.585441E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.59 | backward-compute: 79.81 | backward-params-all-reduce: 14.36 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.54 | batch-generator: 16.17
 iteration   548000/10000000 | consumed samples:     70144000 | elapsed time per iteration (ms): 249.4 | learning rate: 5.066E-05 | global batch size:   128 | lm loss: 1.782653E+00 | sop loss: 6.682520E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.81 | backward-compute: 79.88 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 24.81
 iteration   549000/10000000 | consumed samples:     70272000 | elapsed time per iteration (ms): 248.1 | learning rate: 5.057E-05 | global batch size:   128 | lm loss: 1.781938E+00 | sop loss: 6.542557E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.26 | backward-compute: 79.81 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 13.69
 iteration   550000/10000000 | consumed samples:     70400000 | elapsed time per iteration (ms): 248.4 | learning rate: 5.047E-05 | global batch size:   128 | lm loss: 1.780940E+00 | sop loss: 6.780179E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.69 | backward-compute: 79.82 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 16.18
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 550000 | lm loss value: 1.808591E+00 | lm loss PPL: 6.101845E+00 | sop loss value: 6.941008E-02 | sop loss PPL: 1.071876E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration  550000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration  550000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2341.21
 iteration   551000/10000000 | consumed samples:     70528000 | elapsed time per iteration (ms): 251.1 | learning rate: 5.038E-05 | global batch size:   128 | lm loss: 1.781871E+00 | sop loss: 6.638310E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.57 | backward-compute: 79.81 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 15.10
 iteration   552000/10000000 | consumed samples:     70656000 | elapsed time per iteration (ms): 251.9 | learning rate: 5.029E-05 | global batch size:   128 | lm loss: 1.782134E+00 | sop loss: 6.735054E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.38 | backward-compute: 79.78 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.33 | batch-generator: 12.45
 iteration   553000/10000000 | consumed samples:     70784000 | elapsed time per iteration (ms): 248.5 | learning rate: 5.020E-05 | global batch size:   128 | lm loss: 1.781930E+00 | sop loss: 6.739907E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.25 | backward-compute: 79.75 | backward-params-all-reduce: 14.50 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 13.49
 iteration   554000/10000000 | consumed samples:     70912000 | elapsed time per iteration (ms): 247.7 | learning rate: 5.011E-05 | global batch size:   128 | lm loss: 1.782829E+00 | sop loss: 6.703615E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.12 | backward-compute: 79.73 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.31 | batch-generator: 14.26
 iteration   555000/10000000 | consumed samples:     71040000 | elapsed time per iteration (ms): 247.9 | learning rate: 5.002E-05 | global batch size:   128 | lm loss: 1.783184E+00 | sop loss: 6.644245E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.42 | backward-compute: 79.83 | backward-params-all-reduce: 13.91 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.29 | batch-generator: 16.12
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 555000 | lm loss value: 1.845030E+00 | lm loss PPL: 6.328289E+00 | sop loss value: 8.116236E-02 | sop loss PPL: 1.084547E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   556000/10000000 | consumed samples:     71168000 | elapsed time per iteration (ms): 247.6 | learning rate: 4.992E-05 | global batch size:   128 | lm loss: 1.782316E+00 | sop loss: 6.511714E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.32 | backward-compute: 79.80 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 15.24
 iteration   557000/10000000 | consumed samples:     71296000 | elapsed time per iteration (ms): 247.7 | learning rate: 4.983E-05 | global batch size:   128 | lm loss: 1.783403E+00 | sop loss: 6.660357E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.20 | backward-compute: 79.78 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.32 | batch-generator: 15.83
 iteration   558000/10000000 | consumed samples:     71424000 | elapsed time per iteration (ms): 249.9 | learning rate: 4.974E-05 | global batch size:   128 | lm loss: 1.780518E+00 | sop loss: 6.650543E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.13 | backward-compute: 79.79 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.44 | batch-generator: 14.32
 iteration   559000/10000000 | consumed samples:     71552000 | elapsed time per iteration (ms): 246.9 | learning rate: 4.965E-05 | global batch size:   128 | lm loss: 1.783079E+00 | sop loss: 6.671479E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.40 | backward-compute: 79.77 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 14.91
 iteration   560000/10000000 | consumed samples:     71680000 | elapsed time per iteration (ms): 246.5 | learning rate: 4.956E-05 | global batch size:   128 | lm loss: 1.779922E+00 | sop loss: 6.700188E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.89 | backward-compute: 79.76 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 18.36
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 560000 | lm loss value: 1.827852E+00 | lm loss PPL: 6.220510E+00 | sop loss value: 1.011236E-01 | sop loss PPL: 1.106413E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   561000/10000000 | consumed samples:     71808000 | elapsed time per iteration (ms): 249.4 | learning rate: 4.947E-05 | global batch size:   128 | lm loss: 1.780890E+00 | sop loss: 6.742033E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.19 | backward-compute: 79.83 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 20.48
 iteration   562000/10000000 | consumed samples:     71936000 | elapsed time per iteration (ms): 248.8 | learning rate: 4.937E-05 | global batch size:   128 | lm loss: 1.780289E+00 | sop loss: 6.548377E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.29 | backward-compute: 79.83 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.30 | batch-generator: 16.76
 iteration   563000/10000000 | consumed samples:     72064000 | elapsed time per iteration (ms): 247.1 | learning rate: 4.928E-05 | global batch size:   128 | lm loss: 1.777353E+00 | sop loss: 6.750556E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.54 | backward-compute: 79.86 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.76 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.98 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.25 | batch-generator: 18.04
 iteration   564000/10000000 | consumed samples:     72192000 | elapsed time per iteration (ms): 247.8 | learning rate: 4.919E-05 | global batch size:   128 | lm loss: 1.776821E+00 | sop loss: 6.736862E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.20 | backward-compute: 79.75 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 16.76
 iteration   565000/10000000 | consumed samples:     72320000 | elapsed time per iteration (ms): 248.5 | learning rate: 4.910E-05 | global batch size:   128 | lm loss: 1.776298E+00 | sop loss: 6.634091E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.87 | backward-compute: 79.74 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 26.79
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 565000 | lm loss value: 1.835797E+00 | lm loss PPL: 6.270131E+00 | sop loss value: 8.783500E-02 | sop loss PPL: 1.091808E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   566000/10000000 | consumed samples:     72448000 | elapsed time per iteration (ms): 249.8 | learning rate: 4.901E-05 | global batch size:   128 | lm loss: 1.779389E+00 | sop loss: 6.715779E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.85 | backward-compute: 79.76 | backward-params-all-reduce: 14.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.89 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.42 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.97 | batch-generator: 17.95
 iteration   567000/10000000 | consumed samples:     72576000 | elapsed time per iteration (ms): 247.8 | learning rate: 4.892E-05 | global batch size:   128 | lm loss: 1.776610E+00 | sop loss: 6.440825E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.03 | backward-compute: 79.74 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 15.66
 iteration   568000/10000000 | consumed samples:     72704000 | elapsed time per iteration (ms): 248.2 | learning rate: 4.882E-05 | global batch size:   128 | lm loss: 1.774178E+00 | sop loss: 6.778621E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.20 | backward-compute: 79.82 | backward-params-all-reduce: 14.31 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.47 | batch-generator: 14.52
 iteration   569000/10000000 | consumed samples:     72832000 | elapsed time per iteration (ms): 249.2 | learning rate: 4.873E-05 | global batch size:   128 | lm loss: 1.778557E+00 | sop loss: 6.708250E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.55 | backward-compute: 79.81 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 16.18
 iteration   570000/10000000 | consumed samples:     72960000 | elapsed time per iteration (ms): 251.5 | learning rate: 4.864E-05 | global batch size:   128 | lm loss: 1.777675E+00 | sop loss: 6.534185E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.78 | backward-compute: 79.82 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 14.55
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 570000 | lm loss value: 1.816539E+00 | lm loss PPL: 6.150536E+00 | sop loss value: 9.284181E-02 | sop loss PPL: 1.097288E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   571000/10000000 | consumed samples:     73088000 | elapsed time per iteration (ms): 249.7 | learning rate: 4.855E-05 | global batch size:   128 | lm loss: 1.779240E+00 | sop loss: 6.690790E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.33 | backward-compute: 79.87 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 17.56
 iteration   572000/10000000 | consumed samples:     73216000 | elapsed time per iteration (ms): 247.6 | learning rate: 4.846E-05 | global batch size:   128 | lm loss: 1.778387E+00 | sop loss: 6.602791E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.04 | backward-compute: 79.85 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 19.02
 iteration   573000/10000000 | consumed samples:     73344000 | elapsed time per iteration (ms): 247.8 | learning rate: 4.837E-05 | global batch size:   128 | lm loss: 1.774647E+00 | sop loss: 6.610255E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.18 | backward-compute: 79.81 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 16.56
 iteration   574000/10000000 | consumed samples:     73472000 | elapsed time per iteration (ms): 252.2 | learning rate: 4.827E-05 | global batch size:   128 | lm loss: 1.774282E+00 | sop loss: 6.647915E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.63 | backward-compute: 79.77 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 14.75
 iteration   575000/10000000 | consumed samples:     73600000 | elapsed time per iteration (ms): 247.8 | learning rate: 4.818E-05 | global batch size:   128 | lm loss: 1.771890E+00 | sop loss: 6.700233E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.04 | backward-compute: 79.91 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 15.24
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 575000 | lm loss value: 1.777968E+00 | lm loss PPL: 5.917822E+00 | sop loss value: 6.288184E-02 | sop loss PPL: 1.064901E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   576000/10000000 | consumed samples:     73728000 | elapsed time per iteration (ms): 250.3 | learning rate: 4.809E-05 | global batch size:   128 | lm loss: 1.774267E+00 | sop loss: 6.572528E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.56 | backward-compute: 79.88 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.55 | batch-generator: 18.13
 iteration   577000/10000000 | consumed samples:     73856000 | elapsed time per iteration (ms): 246.3 | learning rate: 4.800E-05 | global batch size:   128 | lm loss: 1.770037E+00 | sop loss: 6.460422E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.95 | backward-compute: 79.89 | backward-params-all-reduce: 14.34 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.58 | batch-generator: 18.20
 iteration   578000/10000000 | consumed samples:     73984000 | elapsed time per iteration (ms): 246.9 | learning rate: 4.791E-05 | global batch size:   128 | lm loss: 1.777154E+00 | sop loss: 6.717220E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.21 | backward-compute: 79.82 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 18.69
 iteration   579000/10000000 | consumed samples:     74112000 | elapsed time per iteration (ms): 248.0 | learning rate: 4.782E-05 | global batch size:   128 | lm loss: 1.773791E+00 | sop loss: 6.571586E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.38 | backward-compute: 79.80 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 17.13
 iteration   580000/10000000 | consumed samples:     74240000 | elapsed time per iteration (ms): 249.7 | learning rate: 4.772E-05 | global batch size:   128 | lm loss: 1.773142E+00 | sop loss: 6.540595E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.29 | backward-compute: 79.81 | backward-params-all-reduce: 13.87 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 20.02
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 580000 | lm loss value: 1.832364E+00 | lm loss PPL: 6.248639E+00 | sop loss value: 8.102836E-02 | sop loss PPL: 1.084402E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   581000/10000000 | consumed samples:     74368000 | elapsed time per iteration (ms): 247.9 | learning rate: 4.763E-05 | global batch size:   128 | lm loss: 1.773624E+00 | sop loss: 6.396683E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.74 | backward-compute: 79.78 | backward-params-all-reduce: 13.90 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.33 | batch-generator: 15.94
 iteration   582000/10000000 | consumed samples:     74496000 | elapsed time per iteration (ms): 247.0 | learning rate: 4.754E-05 | global batch size:   128 | lm loss: 1.776691E+00 | sop loss: 6.512240E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.42 | backward-compute: 79.80 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 13.97
 iteration   583000/10000000 | consumed samples:     74624000 | elapsed time per iteration (ms): 248.4 | learning rate: 4.745E-05 | global batch size:   128 | lm loss: 1.770525E+00 | sop loss: 6.653442E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.14 | backward-compute: 79.82 | backward-params-all-reduce: 14.35 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 13.18
 iteration   584000/10000000 | consumed samples:     74752000 | elapsed time per iteration (ms): 248.5 | learning rate: 4.736E-05 | global batch size:   128 | lm loss: 1.770427E+00 | sop loss: 6.584463E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.48 | backward-compute: 79.71 | backward-params-all-reduce: 14.38 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.52 | batch-generator: 14.61
 iteration   585000/10000000 | consumed samples:     74880000 | elapsed time per iteration (ms): 246.2 | learning rate: 4.726E-05 | global batch size:   128 | lm loss: 1.772036E+00 | sop loss: 6.494749E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.15 | backward-compute: 79.79 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.53 | batch-generator: 15.88
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 585000 | lm loss value: 1.816607E+00 | lm loss PPL: 6.150951E+00 | sop loss value: 7.317571E-02 | sop loss PPL: 1.075920E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   586000/10000000 | consumed samples:     75008000 | elapsed time per iteration (ms): 248.7 | learning rate: 4.717E-05 | global batch size:   128 | lm loss: 1.771287E+00 | sop loss: 6.506873E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.61 | backward-compute: 79.80 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 17.05
 iteration   587000/10000000 | consumed samples:     75136000 | elapsed time per iteration (ms): 249.7 | learning rate: 4.708E-05 | global batch size:   128 | lm loss: 1.768929E+00 | sop loss: 6.602816E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.20 | backward-compute: 79.78 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.33 | batch-generator: 14.64
 iteration   588000/10000000 | consumed samples:     75264000 | elapsed time per iteration (ms): 247.5 | learning rate: 4.699E-05 | global batch size:   128 | lm loss: 1.771559E+00 | sop loss: 6.697748E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.44 | backward-compute: 79.78 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.50 | batch-generator: 17.20
 iteration   589000/10000000 | consumed samples:     75392000 | elapsed time per iteration (ms): 245.9 | learning rate: 4.690E-05 | global batch size:   128 | lm loss: 1.768940E+00 | sop loss: 6.453225E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.94 | backward-compute: 79.85 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 15.32
 iteration   590000/10000000 | consumed samples:     75520000 | elapsed time per iteration (ms): 247.5 | learning rate: 4.681E-05 | global batch size:   128 | lm loss: 1.769142E+00 | sop loss: 6.489477E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.83 | backward-compute: 79.82 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 19.41
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 590000 | lm loss value: 1.777749E+00 | lm loss PPL: 5.916525E+00 | sop loss value: 7.461941E-02 | sop loss PPL: 1.077474E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   591000/10000000 | consumed samples:     75648000 | elapsed time per iteration (ms): 251.3 | learning rate: 4.671E-05 | global batch size:   128 | lm loss: 1.766837E+00 | sop loss: 6.624197E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.12 | backward-compute: 79.77 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 20.58
 iteration   592000/10000000 | consumed samples:     75776000 | elapsed time per iteration (ms): 248.6 | learning rate: 4.662E-05 | global batch size:   128 | lm loss: 1.769348E+00 | sop loss: 6.522375E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.59 | backward-compute: 79.79 | backward-params-all-reduce: 14.81 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.87 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.28 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.78 | batch-generator: 16.12
 iteration   593000/10000000 | consumed samples:     75904000 | elapsed time per iteration (ms): 246.8 | learning rate: 4.653E-05 | global batch size:   128 | lm loss: 1.768030E+00 | sop loss: 6.466160E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.09 | backward-compute: 79.78 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 15.45
 iteration   594000/10000000 | consumed samples:     76032000 | elapsed time per iteration (ms): 247.4 | learning rate: 4.644E-05 | global batch size:   128 | lm loss: 1.761464E+00 | sop loss: 6.578774E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.84 | backward-compute: 79.76 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 18.72
 iteration   595000/10000000 | consumed samples:     76160000 | elapsed time per iteration (ms): 245.5 | learning rate: 4.635E-05 | global batch size:   128 | lm loss: 1.766359E+00 | sop loss: 6.517126E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.38 | backward-compute: 79.79 | backward-params-all-reduce: 14.29 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 15.22
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 595000 | lm loss value: 1.866785E+00 | lm loss PPL: 6.467472E+00 | sop loss value: 8.560031E-02 | sop loss PPL: 1.089371E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   596000/10000000 | consumed samples:     76288000 | elapsed time per iteration (ms): 250.0 | learning rate: 4.626E-05 | global batch size:   128 | lm loss: 1.773450E+00 | sop loss: 6.645711E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.77 | backward-compute: 79.79 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 19.40
 iteration   597000/10000000 | consumed samples:     76416000 | elapsed time per iteration (ms): 248.8 | learning rate: 4.616E-05 | global batch size:   128 | lm loss: 1.766100E+00 | sop loss: 6.427878E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.36 | backward-compute: 79.80 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 21.01
 iteration   598000/10000000 | consumed samples:     76544000 | elapsed time per iteration (ms): 246.8 | learning rate: 4.607E-05 | global batch size:   128 | lm loss: 1.763705E+00 | sop loss: 6.462953E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.21 | backward-compute: 79.82 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 14.30
 iteration   599000/10000000 | consumed samples:     76672000 | elapsed time per iteration (ms): 248.5 | learning rate: 4.598E-05 | global batch size:   128 | lm loss: 1.763986E+00 | sop loss: 6.515220E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.01 | backward-compute: 79.79 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.29 | batch-generator: 14.75
 iteration   600000/10000000 | consumed samples:     76800000 | elapsed time per iteration (ms): 248.4 | learning rate: 4.589E-05 | global batch size:   128 | lm loss: 1.763833E+00 | sop loss: 6.601491E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.64 | backward-compute: 79.88 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.40 | batch-generator: 14.73
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 600000 | lm loss value: 1.793747E+00 | lm loss PPL: 6.011939E+00 | sop loss value: 7.304754E-02 | sop loss PPL: 1.075782E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration  600000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration  600000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2339.74
 iteration   601000/10000000 | consumed samples:     76928000 | elapsed time per iteration (ms): 250.7 | learning rate: 4.580E-05 | global batch size:   128 | lm loss: 1.765916E+00 | sop loss: 6.487848E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.13 | backward-compute: 79.87 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 12.64
 iteration   602000/10000000 | consumed samples:     77056000 | elapsed time per iteration (ms): 248.3 | learning rate: 4.571E-05 | global batch size:   128 | lm loss: 1.763595E+00 | sop loss: 6.507785E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.68 | backward-compute: 79.86 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 15.16
 iteration   603000/10000000 | consumed samples:     77184000 | elapsed time per iteration (ms): 245.5 | learning rate: 4.561E-05 | global batch size:   128 | lm loss: 1.766777E+00 | sop loss: 6.524427E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.42 | backward-compute: 79.86 | backward-params-all-reduce: 14.28 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.46 | batch-generator: 13.76
 iteration   604000/10000000 | consumed samples:     77312000 | elapsed time per iteration (ms): 246.6 | learning rate: 4.552E-05 | global batch size:   128 | lm loss: 1.766035E+00 | sop loss: 6.446173E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.96 | backward-compute: 79.83 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.38
 iteration   605000/10000000 | consumed samples:     77440000 | elapsed time per iteration (ms): 246.5 | learning rate: 4.543E-05 | global batch size:   128 | lm loss: 1.766662E+00 | sop loss: 6.460941E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.75 | backward-compute: 79.88 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 12.17
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 605000 | lm loss value: 1.823155E+00 | lm loss PPL: 6.191360E+00 | sop loss value: 6.477566E-02 | sop loss PPL: 1.066920E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   606000/10000000 | consumed samples:     77568000 | elapsed time per iteration (ms): 249.4 | learning rate: 4.534E-05 | global batch size:   128 | lm loss: 1.764436E+00 | sop loss: 6.356745E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.25 | backward-compute: 79.77 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.76 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.27 | batch-generator: 15.62
 iteration   607000/10000000 | consumed samples:     77696000 | elapsed time per iteration (ms): 247.9 | learning rate: 4.525E-05 | global batch size:   128 | lm loss: 1.760991E+00 | sop loss: 6.446221E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.35 | backward-compute: 79.77 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.76 | optimizer-unscale-and-check-inf: 2.24 | optimizer-clip-main-grad: 3.99 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.26 | batch-generator: 13.37
 iteration   608000/10000000 | consumed samples:     77824000 | elapsed time per iteration (ms): 246.9 | learning rate: 4.516E-05 | global batch size:   128 | lm loss: 1.765743E+00 | sop loss: 6.542194E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.34 | backward-compute: 79.83 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 15.62
 iteration   609000/10000000 | consumed samples:     77952000 | elapsed time per iteration (ms): 249.8 | learning rate: 4.506E-05 | global batch size:   128 | lm loss: 1.765065E+00 | sop loss: 6.553173E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.10 | backward-compute: 79.82 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.46 | batch-generator: 17.64
 iteration   610000/10000000 | consumed samples:     78080000 | elapsed time per iteration (ms): 246.8 | learning rate: 4.497E-05 | global batch size:   128 | lm loss: 1.764398E+00 | sop loss: 6.423746E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.01 | backward-compute: 79.88 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 14.59
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 610000 | lm loss value: 1.815183E+00 | lm loss PPL: 6.142198E+00 | sop loss value: 7.951009E-02 | sop loss PPL: 1.082756E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   611000/10000000 | consumed samples:     78208000 | elapsed time per iteration (ms): 249.0 | learning rate: 4.488E-05 | global batch size:   128 | lm loss: 1.762601E+00 | sop loss: 6.493026E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.78 | backward-compute: 79.87 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 15.93
 iteration   612000/10000000 | consumed samples:     78336000 | elapsed time per iteration (ms): 246.9 | learning rate: 4.479E-05 | global batch size:   128 | lm loss: 1.760628E+00 | sop loss: 6.643658E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.12 | backward-compute: 79.87 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.48
 iteration   613000/10000000 | consumed samples:     78464000 | elapsed time per iteration (ms): 248.1 | learning rate: 4.470E-05 | global batch size:   128 | lm loss: 1.765358E+00 | sop loss: 6.428562E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.18 | backward-compute: 79.83 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.32 | batch-generator: 11.57
 iteration   614000/10000000 | consumed samples:     78592000 | elapsed time per iteration (ms): 246.9 | learning rate: 4.461E-05 | global batch size:   128 | lm loss: 1.763863E+00 | sop loss: 6.449333E-02 | loss scale: 8192.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.42 | backward-compute: 79.80 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 13.45
 iteration   615000/10000000 | consumed samples:     78720000 | elapsed time per iteration (ms): 245.5 | learning rate: 4.451E-05 | global batch size:   128 | lm loss: 1.765063E+00 | sop loss: 6.460924E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.54 | backward-compute: 79.82 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.47 | batch-generator: 16.09
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 615000 | lm loss value: 1.804134E+00 | lm loss PPL: 6.074711E+00 | sop loss value: 8.442760E-02 | sop loss PPL: 1.088094E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   616000/10000000 | consumed samples:     78848000 | elapsed time per iteration (ms): 249.2 | learning rate: 4.442E-05 | global batch size:   128 | lm loss: 1.762119E+00 | sop loss: 6.506155E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.29 | backward-compute: 79.77 | backward-params-all-reduce: 13.90 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.32 | batch-generator: 17.27
 iteration   617000/10000000 | consumed samples:     78976000 | elapsed time per iteration (ms): 246.6 | learning rate: 4.433E-05 | global batch size:   128 | lm loss: 1.760830E+00 | sop loss: 6.494686E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.81 | backward-compute: 80.00 | backward-params-all-reduce: 13.91 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 15.14
 iteration   618000/10000000 | consumed samples:     79104000 | elapsed time per iteration (ms): 246.2 | learning rate: 4.424E-05 | global batch size:   128 | lm loss: 1.761641E+00 | sop loss: 6.545264E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.38 | backward-compute: 79.77 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 13.37
 iteration   619000/10000000 | consumed samples:     79232000 | elapsed time per iteration (ms): 246.9 | learning rate: 4.415E-05 | global batch size:   128 | lm loss: 1.760419E+00 | sop loss: 6.423555E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.13 | backward-compute: 79.81 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.35
 iteration   620000/10000000 | consumed samples:     79360000 | elapsed time per iteration (ms): 247.3 | learning rate: 4.406E-05 | global batch size:   128 | lm loss: 1.762946E+00 | sop loss: 6.375684E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.39 | backward-compute: 79.82 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 18.59
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 620000 | lm loss value: 1.815931E+00 | lm loss PPL: 6.146794E+00 | sop loss value: 8.362255E-02 | sop loss PPL: 1.087218E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   621000/10000000 | consumed samples:     79488000 | elapsed time per iteration (ms): 249.1 | learning rate: 4.396E-05 | global batch size:   128 | lm loss: 1.758399E+00 | sop loss: 6.303269E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.85 | backward-compute: 79.76 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 13.79
 iteration   622000/10000000 | consumed samples:     79616000 | elapsed time per iteration (ms): 247.3 | learning rate: 4.387E-05 | global batch size:   128 | lm loss: 1.759706E+00 | sop loss: 6.416354E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.22 | backward-compute: 79.81 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.53 | batch-generator: 15.81
 iteration   623000/10000000 | consumed samples:     79744000 | elapsed time per iteration (ms): 250.0 | learning rate: 4.378E-05 | global batch size:   128 | lm loss: 1.760532E+00 | sop loss: 6.506707E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.51 | backward-compute: 79.83 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 19.37
 iteration   624000/10000000 | consumed samples:     79872000 | elapsed time per iteration (ms): 248.4 | learning rate: 4.369E-05 | global batch size:   128 | lm loss: 1.756488E+00 | sop loss: 6.523077E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.87 | backward-compute: 79.81 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 14.74
 iteration   625000/10000000 | consumed samples:     80000000 | elapsed time per iteration (ms): 246.8 | learning rate: 4.360E-05 | global batch size:   128 | lm loss: 1.755537E+00 | sop loss: 6.490561E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.07 | backward-compute: 79.84 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 16.23
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 625000 | lm loss value: 1.828499E+00 | lm loss PPL: 6.224535E+00 | sop loss value: 7.705580E-02 | sop loss PPL: 1.080102E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   626000/10000000 | consumed samples:     80128000 | elapsed time per iteration (ms): 249.6 | learning rate: 4.350E-05 | global batch size:   128 | lm loss: 1.757581E+00 | sop loss: 6.324579E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.45 | backward-compute: 79.80 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 20.28
 iteration   627000/10000000 | consumed samples:     80256000 | elapsed time per iteration (ms): 247.1 | learning rate: 4.341E-05 | global batch size:   128 | lm loss: 1.756792E+00 | sop loss: 6.319695E-02 | loss scale: 8192.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.49 | backward-compute: 79.77 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 15.32
 iteration   628000/10000000 | consumed samples:     80384000 | elapsed time per iteration (ms): 247.7 | learning rate: 4.332E-05 | global batch size:   128 | lm loss: 1.761360E+00 | sop loss: 6.586928E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.20 | backward-compute: 79.90 | backward-params-all-reduce: 13.84 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 15.00
 iteration   629000/10000000 | consumed samples:     80512000 | elapsed time per iteration (ms): 247.7 | learning rate: 4.323E-05 | global batch size:   128 | lm loss: 1.762262E+00 | sop loss: 6.403250E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.98 | backward-compute: 79.82 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 20.58
 iteration   630000/10000000 | consumed samples:     80640000 | elapsed time per iteration (ms): 249.4 | learning rate: 4.314E-05 | global batch size:   128 | lm loss: 1.755574E+00 | sop loss: 6.479074E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.39 | backward-compute: 79.82 | backward-params-all-reduce: 14.29 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.47 | batch-generator: 14.46
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 630000 | lm loss value: 1.826546E+00 | lm loss PPL: 6.212390E+00 | sop loss value: 7.113332E-02 | sop loss PPL: 1.073724E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   631000/10000000 | consumed samples:     80768000 | elapsed time per iteration (ms): 249.9 | learning rate: 4.305E-05 | global batch size:   128 | lm loss: 1.756602E+00 | sop loss: 6.438375E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.81 | backward-compute: 79.82 | backward-params-all-reduce: 14.55 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.24 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.68 | batch-generator: 19.98
 iteration   632000/10000000 | consumed samples:     80896000 | elapsed time per iteration (ms): 249.1 | learning rate: 4.295E-05 | global batch size:   128 | lm loss: 1.756868E+00 | sop loss: 6.440768E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.37 | backward-compute: 79.82 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 15.61
 iteration   633000/10000000 | consumed samples:     81024000 | elapsed time per iteration (ms): 250.3 | learning rate: 4.286E-05 | global batch size:   128 | lm loss: 1.758320E+00 | sop loss: 6.343187E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.72 | backward-compute: 79.76 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 13.96
 iteration   634000/10000000 | consumed samples:     81152000 | elapsed time per iteration (ms): 248.0 | learning rate: 4.277E-05 | global batch size:   128 | lm loss: 1.754095E+00 | sop loss: 6.466351E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.36 | backward-compute: 79.77 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 14.50
 iteration   635000/10000000 | consumed samples:     81280000 | elapsed time per iteration (ms): 248.0 | learning rate: 4.268E-05 | global batch size:   128 | lm loss: 1.758935E+00 | sop loss: 6.339791E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.44 | backward-compute: 79.79 | backward-params-all-reduce: 13.87 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 18.34
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 635000 | lm loss value: 1.819066E+00 | lm loss PPL: 6.166098E+00 | sop loss value: 8.433023E-02 | sop loss PPL: 1.087988E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   636000/10000000 | consumed samples:     81408000 | elapsed time per iteration (ms): 250.5 | learning rate: 4.259E-05 | global batch size:   128 | lm loss: 1.755180E+00 | sop loss: 6.408067E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.36 | backward-compute: 79.76 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 15.32
 iteration   637000/10000000 | consumed samples:     81536000 | elapsed time per iteration (ms): 248.3 | learning rate: 4.250E-05 | global batch size:   128 | lm loss: 1.754678E+00 | sop loss: 6.407731E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.42 | backward-compute: 79.81 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 18.71
 iteration   638000/10000000 | consumed samples:     81664000 | elapsed time per iteration (ms): 248.3 | learning rate: 4.240E-05 | global batch size:   128 | lm loss: 1.758444E+00 | sop loss: 6.463816E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.76 | backward-compute: 79.79 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.76 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.28 | batch-generator: 13.01
 iteration   639000/10000000 | consumed samples:     81792000 | elapsed time per iteration (ms): 246.7 | learning rate: 4.231E-05 | global batch size:   128 | lm loss: 1.751377E+00 | sop loss: 6.206150E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.05 | backward-compute: 79.78 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 13.03
 iteration   640000/10000000 | consumed samples:     81920000 | elapsed time per iteration (ms): 247.1 | learning rate: 4.222E-05 | global batch size:   128 | lm loss: 1.752443E+00 | sop loss: 6.369473E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.21 | backward-compute: 79.77 | backward-params-all-reduce: 14.76 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.87 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.27 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.77 | batch-generator: 15.99
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 640000 | lm loss value: 1.824165E+00 | lm loss PPL: 6.197616E+00 | sop loss value: 7.519313E-02 | sop loss PPL: 1.078092E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   641000/10000000 | consumed samples:     82048000 | elapsed time per iteration (ms): 249.9 | learning rate: 4.213E-05 | global batch size:   128 | lm loss: 1.754206E+00 | sop loss: 6.494320E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.75 | backward-compute: 79.82 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 12.33
 iteration   642000/10000000 | consumed samples:     82176000 | elapsed time per iteration (ms): 250.2 | learning rate: 4.204E-05 | global batch size:   128 | lm loss: 1.751363E+00 | sop loss: 6.340734E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.47 | backward-compute: 79.79 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 14.06
 iteration   643000/10000000 | consumed samples:     82304000 | elapsed time per iteration (ms): 248.5 | learning rate: 4.195E-05 | global batch size:   128 | lm loss: 1.753208E+00 | sop loss: 6.434302E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.71 | backward-compute: 79.90 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 15.83
 iteration   644000/10000000 | consumed samples:     82432000 | elapsed time per iteration (ms): 247.6 | learning rate: 4.185E-05 | global batch size:   128 | lm loss: 1.752753E+00 | sop loss: 6.327803E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.80 | backward-compute: 79.84 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 17.31
 iteration   645000/10000000 | consumed samples:     82560000 | elapsed time per iteration (ms): 247.3 | learning rate: 4.176E-05 | global batch size:   128 | lm loss: 1.754002E+00 | sop loss: 6.414266E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.16 | backward-compute: 79.84 | backward-params-all-reduce: 14.31 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.54 | batch-generator: 14.07
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 645000 | lm loss value: 1.820953E+00 | lm loss PPL: 6.177741E+00 | sop loss value: 6.845503E-02 | sop loss PPL: 1.070852E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   646000/10000000 | consumed samples:     82688000 | elapsed time per iteration (ms): 248.5 | learning rate: 4.167E-05 | global batch size:   128 | lm loss: 1.752481E+00 | sop loss: 6.448121E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.20 | backward-compute: 79.83 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 17.02
 iteration   647000/10000000 | consumed samples:     82816000 | elapsed time per iteration (ms): 246.5 | learning rate: 4.158E-05 | global batch size:   128 | lm loss: 1.754674E+00 | sop loss: 6.217287E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.78 | backward-compute: 79.78 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 16.20
 iteration   648000/10000000 | consumed samples:     82944000 | elapsed time per iteration (ms): 248.4 | learning rate: 4.149E-05 | global batch size:   128 | lm loss: 1.751367E+00 | sop loss: 6.338360E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.66 | backward-compute: 79.77 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 19.96
 iteration   649000/10000000 | consumed samples:     83072000 | elapsed time per iteration (ms): 247.2 | learning rate: 4.140E-05 | global batch size:   128 | lm loss: 1.751874E+00 | sop loss: 6.345588E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.58 | backward-compute: 79.74 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 15.18
 iteration   650000/10000000 | consumed samples:     83200000 | elapsed time per iteration (ms): 248.6 | learning rate: 4.130E-05 | global batch size:   128 | lm loss: 1.750327E+00 | sop loss: 6.283199E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.00 | backward-compute: 79.84 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 19.37
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 650000 | lm loss value: 1.833337E+00 | lm loss PPL: 6.254725E+00 | sop loss value: 7.650904E-02 | sop loss PPL: 1.079512E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration  650000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration  650000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2351.00
 iteration   651000/10000000 | consumed samples:     83328000 | elapsed time per iteration (ms): 250.4 | learning rate: 4.121E-05 | global batch size:   128 | lm loss: 1.751550E+00 | sop loss: 6.271802E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.34 | backward-compute: 79.83 | backward-params-all-reduce: 14.29 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 16.75
 iteration   652000/10000000 | consumed samples:     83456000 | elapsed time per iteration (ms): 247.3 | learning rate: 4.112E-05 | global batch size:   128 | lm loss: 1.750273E+00 | sop loss: 6.346617E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.72 | backward-compute: 79.79 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 20.04
 iteration   653000/10000000 | consumed samples:     83584000 | elapsed time per iteration (ms): 248.4 | learning rate: 4.103E-05 | global batch size:   128 | lm loss: 1.749637E+00 | sop loss: 6.150162E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.10 | backward-compute: 79.78 | backward-params-all-reduce: 13.89 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.75 | optimizer-unscale-and-check-inf: 2.24 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.22 | optimizer: 16.25 | batch-generator: 16.56
 iteration   654000/10000000 | consumed samples:     83712000 | elapsed time per iteration (ms): 248.3 | learning rate: 4.094E-05 | global batch size:   128 | lm loss: 1.749271E+00 | sop loss: 6.380182E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.02 | backward-compute: 79.76 | backward-params-all-reduce: 14.42 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.61 | batch-generator: 14.53
 iteration   655000/10000000 | consumed samples:     83840000 | elapsed time per iteration (ms): 247.2 | learning rate: 4.085E-05 | global batch size:   128 | lm loss: 1.748551E+00 | sop loss: 6.328663E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.54 | backward-compute: 79.77 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 12.06
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 655000 | lm loss value: 1.765151E+00 | lm loss PPL: 5.842456E+00 | sop loss value: 8.918627E-02 | sop loss PPL: 1.093284E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   656000/10000000 | consumed samples:     83968000 | elapsed time per iteration (ms): 250.8 | learning rate: 4.075E-05 | global batch size:   128 | lm loss: 1.751649E+00 | sop loss: 6.447047E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.53 | backward-compute: 79.75 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.78
 iteration   657000/10000000 | consumed samples:     84096000 | elapsed time per iteration (ms): 248.5 | learning rate: 4.066E-05 | global batch size:   128 | lm loss: 1.749975E+00 | sop loss: 6.356664E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.44 | backward-compute: 79.83 | backward-params-all-reduce: 14.34 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 15.50
 iteration   658000/10000000 | consumed samples:     84224000 | elapsed time per iteration (ms): 248.0 | learning rate: 4.057E-05 | global batch size:   128 | lm loss: 1.750679E+00 | sop loss: 6.374298E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.55 | backward-compute: 79.83 | backward-params-all-reduce: 14.39 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.21 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.64 | batch-generator: 15.21
 iteration   659000/10000000 | consumed samples:     84352000 | elapsed time per iteration (ms): 248.2 | learning rate: 4.048E-05 | global batch size:   128 | lm loss: 1.750966E+00 | sop loss: 6.262999E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.51 | backward-compute: 79.76 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.98
 iteration   660000/10000000 | consumed samples:     84480000 | elapsed time per iteration (ms): 249.1 | learning rate: 4.039E-05 | global batch size:   128 | lm loss: 1.749979E+00 | sop loss: 6.364308E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.48 | backward-compute: 79.81 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 15.98
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 660000 | lm loss value: 1.793283E+00 | lm loss PPL: 6.009150E+00 | sop loss value: 7.426771E-02 | sop loss PPL: 1.077095E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   661000/10000000 | consumed samples:     84608000 | elapsed time per iteration (ms): 248.4 | learning rate: 4.029E-05 | global batch size:   128 | lm loss: 1.746461E+00 | sop loss: 6.213128E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.28 | backward-compute: 79.77 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 14.52
 iteration   662000/10000000 | consumed samples:     84736000 | elapsed time per iteration (ms): 249.2 | learning rate: 4.020E-05 | global batch size:   128 | lm loss: 1.748935E+00 | sop loss: 6.437761E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.75 | backward-compute: 79.79 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 15.49
 iteration   663000/10000000 | consumed samples:     84864000 | elapsed time per iteration (ms): 246.9 | learning rate: 4.011E-05 | global batch size:   128 | lm loss: 1.748851E+00 | sop loss: 6.273131E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.90 | backward-compute: 79.74 | backward-params-all-reduce: 14.35 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 13.87
 iteration   664000/10000000 | consumed samples:     84992000 | elapsed time per iteration (ms): 247.6 | learning rate: 4.002E-05 | global batch size:   128 | lm loss: 1.745253E+00 | sop loss: 6.346109E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.45 | backward-compute: 79.80 | backward-params-all-reduce: 14.37 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.55 | batch-generator: 14.98
 iteration   665000/10000000 | consumed samples:     85120000 | elapsed time per iteration (ms): 246.3 | learning rate: 3.993E-05 | global batch size:   128 | lm loss: 1.750447E+00 | sop loss: 6.305754E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.49 | backward-compute: 79.83 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 13.66
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 665000 | lm loss value: 1.816734E+00 | lm loss PPL: 6.151732E+00 | sop loss value: 7.316790E-02 | sop loss PPL: 1.075911E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   666000/10000000 | consumed samples:     85248000 | elapsed time per iteration (ms): 251.2 | learning rate: 3.984E-05 | global batch size:   128 | lm loss: 1.744681E+00 | sop loss: 6.305118E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.99 | backward-compute: 79.84 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.76 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.22 | optimizer: 16.27 | batch-generator: 14.51
 iteration   667000/10000000 | consumed samples:     85376000 | elapsed time per iteration (ms): 248.4 | learning rate: 3.974E-05 | global batch size:   128 | lm loss: 1.748223E+00 | sop loss: 6.314861E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.02 | backward-compute: 79.77 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 15.55
 iteration   668000/10000000 | consumed samples:     85504000 | elapsed time per iteration (ms): 247.5 | learning rate: 3.965E-05 | global batch size:   128 | lm loss: 1.745936E+00 | sop loss: 6.266091E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.72 | backward-compute: 79.77 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 18.73
 iteration   669000/10000000 | consumed samples:     85632000 | elapsed time per iteration (ms): 250.3 | learning rate: 3.956E-05 | global batch size:   128 | lm loss: 1.742675E+00 | sop loss: 6.327389E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.64 | backward-compute: 79.79 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 23.95
 iteration   670000/10000000 | consumed samples:     85760000 | elapsed time per iteration (ms): 247.6 | learning rate: 3.947E-05 | global batch size:   128 | lm loss: 1.741994E+00 | sop loss: 6.260304E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.89 | backward-compute: 79.95 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 15.60
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 670000 | lm loss value: 1.798114E+00 | lm loss PPL: 6.038251E+00 | sop loss value: 7.967520E-02 | sop loss PPL: 1.082935E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   671000/10000000 | consumed samples:     85888000 | elapsed time per iteration (ms): 248.0 | learning rate: 3.938E-05 | global batch size:   128 | lm loss: 1.741995E+00 | sop loss: 6.379347E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.71 | backward-compute: 79.87 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 17.14
 iteration   672000/10000000 | consumed samples:     86016000 | elapsed time per iteration (ms): 248.9 | learning rate: 3.929E-05 | global batch size:   128 | lm loss: 1.745873E+00 | sop loss: 6.274954E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.31 | backward-compute: 79.91 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 17.25
 iteration   673000/10000000 | consumed samples:     86144000 | elapsed time per iteration (ms): 251.4 | learning rate: 3.919E-05 | global batch size:   128 | lm loss: 1.747565E+00 | sop loss: 6.274739E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.85 | backward-compute: 79.81 | backward-params-all-reduce: 13.89 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 15.88
 iteration   674000/10000000 | consumed samples:     86272000 | elapsed time per iteration (ms): 248.0 | learning rate: 3.910E-05 | global batch size:   128 | lm loss: 1.742346E+00 | sop loss: 6.262717E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.01 | backward-compute: 79.93 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 17.72
 iteration   675000/10000000 | consumed samples:     86400000 | elapsed time per iteration (ms): 247.8 | learning rate: 3.901E-05 | global batch size:   128 | lm loss: 1.739582E+00 | sop loss: 6.443715E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.00 | backward-compute: 79.89 | backward-params-all-reduce: 14.57 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.30 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.78 | batch-generator: 15.84
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 675000 | lm loss value: 1.783845E+00 | lm loss PPL: 5.952702E+00 | sop loss value: 8.549299E-02 | sop loss PPL: 1.089254E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   676000/10000000 | consumed samples:     86528000 | elapsed time per iteration (ms): 250.5 | learning rate: 3.892E-05 | global batch size:   128 | lm loss: 1.742968E+00 | sop loss: 6.354411E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.38 | backward-compute: 79.77 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 15.48
 iteration   677000/10000000 | consumed samples:     86656000 | elapsed time per iteration (ms): 249.5 | learning rate: 3.883E-05 | global batch size:   128 | lm loss: 1.743755E+00 | sop loss: 6.486017E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.93 | backward-compute: 79.81 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 15.15
 iteration   678000/10000000 | consumed samples:     86784000 | elapsed time per iteration (ms): 249.1 | learning rate: 3.874E-05 | global batch size:   128 | lm loss: 1.746574E+00 | sop loss: 6.143585E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.58 | backward-compute: 79.83 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 14.70
 iteration   679000/10000000 | consumed samples:     86912000 | elapsed time per iteration (ms): 250.4 | learning rate: 3.864E-05 | global batch size:   128 | lm loss: 1.741447E+00 | sop loss: 6.309248E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.97 | backward-compute: 79.85 | backward-params-all-reduce: 13.83 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 18.42
 iteration   680000/10000000 | consumed samples:     87040000 | elapsed time per iteration (ms): 251.4 | learning rate: 3.855E-05 | global batch size:   128 | lm loss: 1.743413E+00 | sop loss: 6.166640E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.87 | backward-compute: 79.76 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 13.30
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 680000 | lm loss value: 1.797294E+00 | lm loss PPL: 6.033299E+00 | sop loss value: 7.025202E-02 | sop loss PPL: 1.072779E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   681000/10000000 | consumed samples:     87168000 | elapsed time per iteration (ms): 248.4 | learning rate: 3.846E-05 | global batch size:   128 | lm loss: 1.741955E+00 | sop loss: 6.387480E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.10 | backward-compute: 79.84 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 16.26
 iteration   682000/10000000 | consumed samples:     87296000 | elapsed time per iteration (ms): 249.3 | learning rate: 3.837E-05 | global batch size:   128 | lm loss: 1.744109E+00 | sop loss: 6.242404E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.51 | backward-compute: 79.84 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.61
 iteration   683000/10000000 | consumed samples:     87424000 | elapsed time per iteration (ms): 250.4 | learning rate: 3.828E-05 | global batch size:   128 | lm loss: 1.741333E+00 | sop loss: 6.143809E-02 | loss scale: 8192.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.84 | backward-compute: 79.81 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 15.68
 iteration   684000/10000000 | consumed samples:     87552000 | elapsed time per iteration (ms): 250.7 | learning rate: 3.819E-05 | global batch size:   128 | lm loss: 1.742227E+00 | sop loss: 6.221005E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.09 | backward-compute: 79.83 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 26.05
 iteration   685000/10000000 | consumed samples:     87680000 | elapsed time per iteration (ms): 248.1 | learning rate: 3.809E-05 | global batch size:   128 | lm loss: 1.741878E+00 | sop loss: 6.202953E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.35 | backward-compute: 79.84 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 14.44
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 685000 | lm loss value: 1.795555E+00 | lm loss PPL: 6.022817E+00 | sop loss value: 7.040215E-02 | sop loss PPL: 1.072940E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   686000/10000000 | consumed samples:     87808000 | elapsed time per iteration (ms): 250.8 | learning rate: 3.800E-05 | global batch size:   128 | lm loss: 1.741229E+00 | sop loss: 6.315485E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.80 | backward-compute: 79.80 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 16.48
 iteration   687000/10000000 | consumed samples:     87936000 | elapsed time per iteration (ms): 247.1 | learning rate: 3.791E-05 | global batch size:   128 | lm loss: 1.741603E+00 | sop loss: 6.451275E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.83 | backward-compute: 79.79 | backward-params-all-reduce: 14.39 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.62 | batch-generator: 15.89
 iteration   688000/10000000 | consumed samples:     88064000 | elapsed time per iteration (ms): 247.0 | learning rate: 3.782E-05 | global batch size:   128 | lm loss: 1.740967E+00 | sop loss: 6.343123E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.37 | backward-compute: 79.77 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 16.07
 iteration   689000/10000000 | consumed samples:     88192000 | elapsed time per iteration (ms): 246.2 | learning rate: 3.773E-05 | global batch size:   128 | lm loss: 1.741098E+00 | sop loss: 6.190298E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.76 | backward-compute: 79.78 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 15.73
 iteration   690000/10000000 | consumed samples:     88320000 | elapsed time per iteration (ms): 247.9 | learning rate: 3.764E-05 | global batch size:   128 | lm loss: 1.739676E+00 | sop loss: 6.348117E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.36 | backward-compute: 79.83 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.24 | optimizer-clip-main-grad: 4.00 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.29 | batch-generator: 14.80
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 690000 | lm loss value: 1.765613E+00 | lm loss PPL: 5.845152E+00 | sop loss value: 8.097251E-02 | sop loss PPL: 1.084341E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   691000/10000000 | consumed samples:     88448000 | elapsed time per iteration (ms): 248.3 | learning rate: 3.754E-05 | global batch size:   128 | lm loss: 1.739502E+00 | sop loss: 6.264915E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.85 | backward-compute: 79.87 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 18.90
 iteration   692000/10000000 | consumed samples:     88576000 | elapsed time per iteration (ms): 247.5 | learning rate: 3.745E-05 | global batch size:   128 | lm loss: 1.736418E+00 | sop loss: 6.212301E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.68 | backward-compute: 79.91 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 15.59
 iteration   693000/10000000 | consumed samples:     88704000 | elapsed time per iteration (ms): 247.7 | learning rate: 3.736E-05 | global batch size:   128 | lm loss: 1.741510E+00 | sop loss: 6.241937E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.97 | backward-compute: 79.78 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 15.53
 iteration   694000/10000000 | consumed samples:     88832000 | elapsed time per iteration (ms): 246.5 | learning rate: 3.727E-05 | global batch size:   128 | lm loss: 1.738058E+00 | sop loss: 6.315981E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.92 | backward-compute: 79.73 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 13.81
 iteration   695000/10000000 | consumed samples:     88960000 | elapsed time per iteration (ms): 246.5 | learning rate: 3.718E-05 | global batch size:   128 | lm loss: 1.738468E+00 | sop loss: 6.241372E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.79 | backward-compute: 79.90 | backward-params-all-reduce: 13.92 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 14.77
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 695000 | lm loss value: 1.804472E+00 | lm loss PPL: 6.076763E+00 | sop loss value: 7.901315E-02 | sop loss PPL: 1.082219E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   696000/10000000 | consumed samples:     89088000 | elapsed time per iteration (ms): 249.4 | learning rate: 3.709E-05 | global batch size:   128 | lm loss: 1.737960E+00 | sop loss: 6.217228E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.96 | backward-compute: 79.77 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 16.75
 iteration   697000/10000000 | consumed samples:     89216000 | elapsed time per iteration (ms): 248.7 | learning rate: 3.699E-05 | global batch size:   128 | lm loss: 1.737086E+00 | sop loss: 6.287265E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.05 | backward-compute: 79.81 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 14.08
 iteration   698000/10000000 | consumed samples:     89344000 | elapsed time per iteration (ms): 247.1 | learning rate: 3.690E-05 | global batch size:   128 | lm loss: 1.737079E+00 | sop loss: 6.318287E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.50 | backward-compute: 79.78 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.34 | batch-generator: 15.16
 iteration   699000/10000000 | consumed samples:     89472000 | elapsed time per iteration (ms): 248.7 | learning rate: 3.681E-05 | global batch size:   128 | lm loss: 1.736239E+00 | sop loss: 6.266314E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.85 | backward-compute: 79.82 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 15.95
 iteration   700000/10000000 | consumed samples:     89600000 | elapsed time per iteration (ms): 248.1 | learning rate: 3.672E-05 | global batch size:   128 | lm loss: 1.741973E+00 | sop loss: 6.239267E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.46 | backward-compute: 79.88 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 15.73
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 700000 | lm loss value: 1.770087E+00 | lm loss PPL: 5.871365E+00 | sop loss value: 7.359929E-02 | sop loss PPL: 1.076375E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration  700000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration  700000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2343.82
 iteration   701000/10000000 | consumed samples:     89728000 | elapsed time per iteration (ms): 251.8 | learning rate: 3.663E-05 | global batch size:   128 | lm loss: 1.736708E+00 | sop loss: 6.309425E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.30 | backward-compute: 79.84 | backward-params-all-reduce: 13.91 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 12.18
 iteration   702000/10000000 | consumed samples:     89856000 | elapsed time per iteration (ms): 247.3 | learning rate: 3.653E-05 | global batch size:   128 | lm loss: 1.736639E+00 | sop loss: 6.280562E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.69 | backward-compute: 79.81 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 17.26
 iteration   703000/10000000 | consumed samples:     89984000 | elapsed time per iteration (ms): 248.4 | learning rate: 3.644E-05 | global batch size:   128 | lm loss: 1.739823E+00 | sop loss: 6.177729E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.72 | backward-compute: 79.74 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 16.21
 iteration   704000/10000000 | consumed samples:     90112000 | elapsed time per iteration (ms): 247.4 | learning rate: 3.635E-05 | global batch size:   128 | lm loss: 1.733834E+00 | sop loss: 6.192223E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.28 | backward-compute: 79.82 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.51 | batch-generator: 16.73
 iteration   705000/10000000 | consumed samples:     90240000 | elapsed time per iteration (ms): 248.1 | learning rate: 3.626E-05 | global batch size:   128 | lm loss: 1.735101E+00 | sop loss: 6.120989E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.35 | backward-compute: 79.81 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 14.54
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 705000 | lm loss value: 1.793496E+00 | lm loss PPL: 6.010428E+00 | sop loss value: 6.865699E-02 | sop loss PPL: 1.071069E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   706000/10000000 | consumed samples:     90368000 | elapsed time per iteration (ms): 249.6 | learning rate: 3.617E-05 | global batch size:   128 | lm loss: 1.733114E+00 | sop loss: 6.391483E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.32 | backward-compute: 79.97 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 17.94
 iteration   707000/10000000 | consumed samples:     90496000 | elapsed time per iteration (ms): 246.3 | learning rate: 3.608E-05 | global batch size:   128 | lm loss: 1.734492E+00 | sop loss: 6.199972E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.28 | backward-compute: 79.86 | backward-params-all-reduce: 14.27 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 15.53
 iteration   708000/10000000 | consumed samples:     90624000 | elapsed time per iteration (ms): 248.0 | learning rate: 3.598E-05 | global batch size:   128 | lm loss: 1.734021E+00 | sop loss: 6.248131E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.74 | backward-compute: 79.82 | backward-params-all-reduce: 14.36 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.60 | batch-generator: 15.87
 iteration   709000/10000000 | consumed samples:     90752000 | elapsed time per iteration (ms): 250.5 | learning rate: 3.589E-05 | global batch size:   128 | lm loss: 1.735831E+00 | sop loss: 6.211797E-02 | loss scale: 8192.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.79 | backward-compute: 79.77 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 14.13
 iteration   710000/10000000 | consumed samples:     90880000 | elapsed time per iteration (ms): 248.6 | learning rate: 3.580E-05 | global batch size:   128 | lm loss: 1.735328E+00 | sop loss: 6.288030E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.18 | backward-compute: 79.75 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 14.94
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 710000 | lm loss value: 1.778088E+00 | lm loss PPL: 5.918529E+00 | sop loss value: 7.696556E-02 | sop loss PPL: 1.080005E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   711000/10000000 | consumed samples:     91008000 | elapsed time per iteration (ms): 249.8 | learning rate: 3.571E-05 | global batch size:   128 | lm loss: 1.735992E+00 | sop loss: 6.146112E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.60 | backward-compute: 79.76 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.18
 iteration   712000/10000000 | consumed samples:     91136000 | elapsed time per iteration (ms): 246.3 | learning rate: 3.562E-05 | global batch size:   128 | lm loss: 1.735394E+00 | sop loss: 6.227804E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.53 | backward-compute: 79.83 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 17.27
 iteration   713000/10000000 | consumed samples:     91264000 | elapsed time per iteration (ms): 246.8 | learning rate: 3.553E-05 | global batch size:   128 | lm loss: 1.732482E+00 | sop loss: 6.189024E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.91 | backward-compute: 79.83 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.94
 iteration   714000/10000000 | consumed samples:     91392000 | elapsed time per iteration (ms): 248.4 | learning rate: 3.543E-05 | global batch size:   128 | lm loss: 1.731909E+00 | sop loss: 6.332024E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.67 | backward-compute: 79.83 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 14.77
 iteration   715000/10000000 | consumed samples:     91520000 | elapsed time per iteration (ms): 248.3 | learning rate: 3.534E-05 | global batch size:   128 | lm loss: 1.731822E+00 | sop loss: 6.168828E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.18 | backward-compute: 79.80 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.54 | batch-generator: 17.17
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 715000 | lm loss value: 1.762029E+00 | lm loss PPL: 5.824243E+00 | sop loss value: 5.806968E-02 | sop loss PPL: 1.059789E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   716000/10000000 | consumed samples:     91648000 | elapsed time per iteration (ms): 249.9 | learning rate: 3.525E-05 | global batch size:   128 | lm loss: 1.735308E+00 | sop loss: 6.073388E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.80 | backward-compute: 79.76 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 13.36
 iteration   717000/10000000 | consumed samples:     91776000 | elapsed time per iteration (ms): 247.1 | learning rate: 3.516E-05 | global batch size:   128 | lm loss: 1.735991E+00 | sop loss: 6.225289E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.17 | backward-compute: 79.74 | backward-params-all-reduce: 14.27 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 14.90
 iteration   718000/10000000 | consumed samples:     91904000 | elapsed time per iteration (ms): 248.4 | learning rate: 3.507E-05 | global batch size:   128 | lm loss: 1.732846E+00 | sop loss: 6.187069E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.80 | backward-compute: 79.77 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 16.31
 iteration   719000/10000000 | consumed samples:     92032000 | elapsed time per iteration (ms): 251.0 | learning rate: 3.498E-05 | global batch size:   128 | lm loss: 1.733303E+00 | sop loss: 6.342343E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.33 | backward-compute: 79.79 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 18.37
 iteration   720000/10000000 | consumed samples:     92160000 | elapsed time per iteration (ms): 249.6 | learning rate: 3.488E-05 | global batch size:   128 | lm loss: 1.730858E+00 | sop loss: 6.274255E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.95 | backward-compute: 79.88 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 21.31
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 720000 | lm loss value: 1.811017E+00 | lm loss PPL: 6.116667E+00 | sop loss value: 8.369040E-02 | sop loss PPL: 1.087292E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   721000/10000000 | consumed samples:     92288000 | elapsed time per iteration (ms): 249.3 | learning rate: 3.479E-05 | global batch size:   128 | lm loss: 1.731425E+00 | sop loss: 6.245672E-02 | loss scale: 8192.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.78 | backward-compute: 79.79 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 19.28
 iteration   722000/10000000 | consumed samples:     92416000 | elapsed time per iteration (ms): 247.3 | learning rate: 3.470E-05 | global batch size:   128 | lm loss: 1.731659E+00 | sop loss: 6.137086E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.70 | backward-compute: 79.76 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 17.08
 iteration   723000/10000000 | consumed samples:     92544000 | elapsed time per iteration (ms): 248.7 | learning rate: 3.461E-05 | global batch size:   128 | lm loss: 1.730349E+00 | sop loss: 6.149587E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.15 | backward-compute: 79.74 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 15.85
 iteration   724000/10000000 | consumed samples:     92672000 | elapsed time per iteration (ms): 248.6 | learning rate: 3.452E-05 | global batch size:   128 | lm loss: 1.732863E+00 | sop loss: 6.111521E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.89 | backward-compute: 79.73 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 17.81
 iteration   725000/10000000 | consumed samples:     92800000 | elapsed time per iteration (ms): 250.5 | learning rate: 3.443E-05 | global batch size:   128 | lm loss: 1.729540E+00 | sop loss: 6.115713E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.87 | backward-compute: 79.82 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 14.77
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 725000 | lm loss value: 1.785791E+00 | lm loss PPL: 5.964295E+00 | sop loss value: 6.478722E-02 | sop loss PPL: 1.066932E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   726000/10000000 | consumed samples:     92928000 | elapsed time per iteration (ms): 248.7 | learning rate: 3.433E-05 | global batch size:   128 | lm loss: 1.731241E+00 | sop loss: 6.190670E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.46 | backward-compute: 79.84 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 16.92
 iteration   727000/10000000 | consumed samples:     93056000 | elapsed time per iteration (ms): 250.3 | learning rate: 3.424E-05 | global batch size:   128 | lm loss: 1.732188E+00 | sop loss: 6.138134E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.90 | backward-compute: 79.80 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.01 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 16.98
 iteration   728000/10000000 | consumed samples:     93184000 | elapsed time per iteration (ms): 250.1 | learning rate: 3.415E-05 | global batch size:   128 | lm loss: 1.728401E+00 | sop loss: 6.210534E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.64 | backward-compute: 79.77 | backward-params-all-reduce: 13.90 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 15.86
 iteration   729000/10000000 | consumed samples:     93312000 | elapsed time per iteration (ms): 247.0 | learning rate: 3.406E-05 | global batch size:   128 | lm loss: 1.731421E+00 | sop loss: 6.137199E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.17 | backward-compute: 79.77 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.14
 iteration   730000/10000000 | consumed samples:     93440000 | elapsed time per iteration (ms): 248.5 | learning rate: 3.397E-05 | global batch size:   128 | lm loss: 1.727163E+00 | sop loss: 6.172952E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.01 | backward-compute: 79.73 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 13.94
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 730000 | lm loss value: 1.759337E+00 | lm loss PPL: 5.808583E+00 | sop loss value: 9.387791E-02 | sop loss PPL: 1.098426E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   731000/10000000 | consumed samples:     93568000 | elapsed time per iteration (ms): 248.7 | learning rate: 3.388E-05 | global batch size:   128 | lm loss: 1.730315E+00 | sop loss: 6.146188E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.53 | backward-compute: 79.78 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.22 | optimizer: 16.30 | batch-generator: 14.31
 iteration   732000/10000000 | consumed samples:     93696000 | elapsed time per iteration (ms): 247.2 | learning rate: 3.378E-05 | global batch size:   128 | lm loss: 1.730339E+00 | sop loss: 6.253477E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.53 | backward-compute: 79.81 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.35
 iteration   733000/10000000 | consumed samples:     93824000 | elapsed time per iteration (ms): 248.3 | learning rate: 3.369E-05 | global batch size:   128 | lm loss: 1.730518E+00 | sop loss: 6.074022E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.43 | backward-compute: 79.85 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 20.24
 iteration   734000/10000000 | consumed samples:     93952000 | elapsed time per iteration (ms): 250.4 | learning rate: 3.360E-05 | global batch size:   128 | lm loss: 1.727961E+00 | sop loss: 6.180760E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.77 | backward-compute: 79.86 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 18.53
 iteration   735000/10000000 | consumed samples:     94080000 | elapsed time per iteration (ms): 247.5 | learning rate: 3.351E-05 | global batch size:   128 | lm loss: 1.726093E+00 | sop loss: 6.150458E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.01 | backward-compute: 79.84 | backward-params-all-reduce: 14.50 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.22 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.66 | batch-generator: 15.55
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 735000 | lm loss value: 1.777282E+00 | lm loss PPL: 5.913762E+00 | sop loss value: 7.498606E-02 | sop loss PPL: 1.077869E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   736000/10000000 | consumed samples:     94208000 | elapsed time per iteration (ms): 249.9 | learning rate: 3.342E-05 | global batch size:   128 | lm loss: 1.730979E+00 | sop loss: 6.120962E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.69 | backward-compute: 79.86 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 15.03
 iteration   737000/10000000 | consumed samples:     94336000 | elapsed time per iteration (ms): 248.6 | learning rate: 3.332E-05 | global batch size:   128 | lm loss: 1.727667E+00 | sop loss: 6.354741E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.06 | backward-compute: 79.75 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 15.51
 iteration   738000/10000000 | consumed samples:     94464000 | elapsed time per iteration (ms): 248.4 | learning rate: 3.323E-05 | global batch size:   128 | lm loss: 1.726433E+00 | sop loss: 5.997236E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.89 | backward-compute: 79.75 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 23.86
 iteration   739000/10000000 | consumed samples:     94592000 | elapsed time per iteration (ms): 247.5 | learning rate: 3.314E-05 | global batch size:   128 | lm loss: 1.730347E+00 | sop loss: 6.225853E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.69 | backward-compute: 79.85 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.50 | batch-generator: 21.21
 iteration   740000/10000000 | consumed samples:     94720000 | elapsed time per iteration (ms): 249.9 | learning rate: 3.305E-05 | global batch size:   128 | lm loss: 1.729059E+00 | sop loss: 6.124161E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.23 | backward-compute: 79.75 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 25.68
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 740000 | lm loss value: 1.737892E+00 | lm loss PPL: 5.685347E+00 | sop loss value: 8.068564E-02 | sop loss PPL: 1.084030E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   741000/10000000 | consumed samples:     94848000 | elapsed time per iteration (ms): 249.4 | learning rate: 3.296E-05 | global batch size:   128 | lm loss: 1.725578E+00 | sop loss: 6.132299E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.31 | backward-compute: 79.81 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 17.32
 iteration   742000/10000000 | consumed samples:     94976000 | elapsed time per iteration (ms): 248.6 | learning rate: 3.287E-05 | global batch size:   128 | lm loss: 1.725869E+00 | sop loss: 6.090435E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.09 | backward-compute: 79.82 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 14.39
 iteration   743000/10000000 | consumed samples:     95104000 | elapsed time per iteration (ms): 248.9 | learning rate: 3.277E-05 | global batch size:   128 | lm loss: 1.726855E+00 | sop loss: 6.244062E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.34 | backward-compute: 79.81 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 24.99
 iteration   744000/10000000 | consumed samples:     95232000 | elapsed time per iteration (ms): 247.7 | learning rate: 3.268E-05 | global batch size:   128 | lm loss: 1.725243E+00 | sop loss: 6.091119E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.88 | backward-compute: 79.82 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 18.97
 iteration   745000/10000000 | consumed samples:     95360000 | elapsed time per iteration (ms): 247.6 | learning rate: 3.259E-05 | global batch size:   128 | lm loss: 1.726044E+00 | sop loss: 6.133763E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.02 | backward-compute: 79.78 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 15.44
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 745000 | lm loss value: 1.783641E+00 | lm loss PPL: 5.951485E+00 | sop loss value: 8.075820E-02 | sop loss PPL: 1.084109E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   746000/10000000 | consumed samples:     95488000 | elapsed time per iteration (ms): 250.4 | learning rate: 3.250E-05 | global batch size:   128 | lm loss: 1.722657E+00 | sop loss: 6.181926E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.04 | backward-compute: 79.77 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 15.48
 iteration   747000/10000000 | consumed samples:     95616000 | elapsed time per iteration (ms): 248.4 | learning rate: 3.241E-05 | global batch size:   128 | lm loss: 1.723534E+00 | sop loss: 6.063256E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.61 | backward-compute: 79.81 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 18.55
 iteration   748000/10000000 | consumed samples:     95744000 | elapsed time per iteration (ms): 249.6 | learning rate: 3.232E-05 | global batch size:   128 | lm loss: 1.723705E+00 | sop loss: 6.160785E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.05 | backward-compute: 79.76 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 13.17
 iteration   749000/10000000 | consumed samples:     95872000 | elapsed time per iteration (ms): 248.7 | learning rate: 3.222E-05 | global batch size:   128 | lm loss: 1.724818E+00 | sop loss: 5.991431E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.15 | backward-compute: 79.74 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 14.71
 iteration   750000/10000000 | consumed samples:     96000000 | elapsed time per iteration (ms): 247.6 | learning rate: 3.213E-05 | global batch size:   128 | lm loss: 1.723548E+00 | sop loss: 6.094472E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.74 | backward-compute: 79.77 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 17.08
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 750000 | lm loss value: 1.805268E+00 | lm loss PPL: 6.081601E+00 | sop loss value: 6.075733E-02 | sop loss PPL: 1.062641E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration  750000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration  750000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2347.23
 iteration   751000/10000000 | consumed samples:     96128000 | elapsed time per iteration (ms): 251.4 | learning rate: 3.204E-05 | global batch size:   128 | lm loss: 1.726000E+00 | sop loss: 6.013141E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.05 | backward-compute: 79.74 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 22.25
 iteration   752000/10000000 | consumed samples:     96256000 | elapsed time per iteration (ms): 248.8 | learning rate: 3.195E-05 | global batch size:   128 | lm loss: 1.727680E+00 | sop loss: 6.003839E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.25 | backward-compute: 79.78 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 17.53
 iteration   753000/10000000 | consumed samples:     96384000 | elapsed time per iteration (ms): 247.1 | learning rate: 3.186E-05 | global batch size:   128 | lm loss: 1.723422E+00 | sop loss: 6.148963E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.31 | backward-compute: 79.86 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 14.58
 iteration   754000/10000000 | consumed samples:     96512000 | elapsed time per iteration (ms): 247.3 | learning rate: 3.177E-05 | global batch size:   128 | lm loss: 1.721510E+00 | sop loss: 6.232277E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.04 | backward-compute: 79.82 | backward-params-all-reduce: 14.42 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.54 | batch-generator: 15.58
 iteration   755000/10000000 | consumed samples:     96640000 | elapsed time per iteration (ms): 247.5 | learning rate: 3.167E-05 | global batch size:   128 | lm loss: 1.719386E+00 | sop loss: 6.243567E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.75 | backward-compute: 79.83 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 17.58
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 755000 | lm loss value: 1.794149E+00 | lm loss PPL: 6.014353E+00 | sop loss value: 6.705606E-02 | sop loss PPL: 1.069355E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   756000/10000000 | consumed samples:     96768000 | elapsed time per iteration (ms): 251.1 | learning rate: 3.158E-05 | global batch size:   128 | lm loss: 1.723800E+00 | sop loss: 6.184112E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.92 | backward-compute: 79.79 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 13.99
 iteration   757000/10000000 | consumed samples:     96896000 | elapsed time per iteration (ms): 248.3 | learning rate: 3.149E-05 | global batch size:   128 | lm loss: 1.726317E+00 | sop loss: 6.152738E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.69 | backward-compute: 79.83 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 16.47
 iteration   758000/10000000 | consumed samples:     97024000 | elapsed time per iteration (ms): 247.1 | learning rate: 3.140E-05 | global batch size:   128 | lm loss: 1.721930E+00 | sop loss: 6.067433E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.31 | backward-compute: 79.86 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 14.02
 iteration   759000/10000000 | consumed samples:     97152000 | elapsed time per iteration (ms): 248.3 | learning rate: 3.131E-05 | global batch size:   128 | lm loss: 1.724039E+00 | sop loss: 6.109407E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.86 | backward-compute: 79.85 | backward-params-all-reduce: 15.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.89 | optimizer-unscale-and-check-inf: 2.31 | optimizer-clip-main-grad: 4.42 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.97 | batch-generator: 16.45
 iteration   760000/10000000 | consumed samples:     97280000 | elapsed time per iteration (ms): 245.9 | learning rate: 3.122E-05 | global batch size:   128 | lm loss: 1.723870E+00 | sop loss: 6.167115E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.71 | backward-compute: 79.92 | backward-params-all-reduce: 14.35 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 16.69
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 760000 | lm loss value: 1.778102E+00 | lm loss PPL: 5.918614E+00 | sop loss value: 7.590231E-02 | sop loss PPL: 1.078857E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   761000/10000000 | consumed samples:     97408000 | elapsed time per iteration (ms): 251.4 | learning rate: 3.112E-05 | global batch size:   128 | lm loss: 1.720009E+00 | sop loss: 6.083913E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.35 | backward-compute: 79.77 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 17.63
 iteration   762000/10000000 | consumed samples:     97536000 | elapsed time per iteration (ms): 249.8 | learning rate: 3.103E-05 | global batch size:   128 | lm loss: 1.719253E+00 | sop loss: 6.038355E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.16 | backward-compute: 79.77 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 14.17
 iteration   763000/10000000 | consumed samples:     97664000 | elapsed time per iteration (ms): 247.3 | learning rate: 3.094E-05 | global batch size:   128 | lm loss: 1.722411E+00 | sop loss: 6.080142E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.51 | backward-compute: 79.79 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.21
 iteration   764000/10000000 | consumed samples:     97792000 | elapsed time per iteration (ms): 247.1 | learning rate: 3.085E-05 | global batch size:   128 | lm loss: 1.722620E+00 | sop loss: 6.151842E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.57 | backward-compute: 79.78 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.76 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 16.71
 iteration   765000/10000000 | consumed samples:     97920000 | elapsed time per iteration (ms): 249.5 | learning rate: 3.076E-05 | global batch size:   128 | lm loss: 1.723241E+00 | sop loss: 6.129465E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.82 | backward-compute: 79.77 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 14.16
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 765000 | lm loss value: 1.794637E+00 | lm loss PPL: 6.017288E+00 | sop loss value: 6.299525E-02 | sop loss PPL: 1.065022E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   766000/10000000 | consumed samples:     98048000 | elapsed time per iteration (ms): 249.5 | learning rate: 3.066E-05 | global batch size:   128 | lm loss: 1.722012E+00 | sop loss: 6.003160E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.36 | backward-compute: 79.77 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 16.08
 iteration   767000/10000000 | consumed samples:     98176000 | elapsed time per iteration (ms): 248.3 | learning rate: 3.057E-05 | global batch size:   128 | lm loss: 1.718016E+00 | sop loss: 6.011523E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.32 | backward-compute: 79.79 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 13.65
 iteration   768000/10000000 | consumed samples:     98304000 | elapsed time per iteration (ms): 247.9 | learning rate: 3.048E-05 | global batch size:   128 | lm loss: 1.718773E+00 | sop loss: 6.015014E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.27 | backward-compute: 79.78 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.15
 iteration   769000/10000000 | consumed samples:     98432000 | elapsed time per iteration (ms): 246.4 | learning rate: 3.039E-05 | global batch size:   128 | lm loss: 1.717308E+00 | sop loss: 6.181413E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.74 | backward-compute: 79.77 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 14.67
 iteration   770000/10000000 | consumed samples:     98560000 | elapsed time per iteration (ms): 249.3 | learning rate: 3.030E-05 | global batch size:   128 | lm loss: 1.722496E+00 | sop loss: 6.025013E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.54 | backward-compute: 79.80 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.23
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 770000 | lm loss value: 1.780648E+00 | lm loss PPL: 5.933703E+00 | sop loss value: 7.076152E-02 | sop loss PPL: 1.073325E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   771000/10000000 | consumed samples:     98688000 | elapsed time per iteration (ms): 249.3 | learning rate: 3.021E-05 | global batch size:   128 | lm loss: 1.715978E+00 | sop loss: 6.013006E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.80 | backward-compute: 79.80 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.49 | batch-generator: 14.81
 iteration   772000/10000000 | consumed samples:     98816000 | elapsed time per iteration (ms): 249.8 | learning rate: 3.011E-05 | global batch size:   128 | lm loss: 1.722157E+00 | sop loss: 6.080059E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.94 | backward-compute: 79.80 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 15.92
 iteration   773000/10000000 | consumed samples:     98944000 | elapsed time per iteration (ms): 248.7 | learning rate: 3.002E-05 | global batch size:   128 | lm loss: 1.717237E+00 | sop loss: 6.091426E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.95 | backward-compute: 79.83 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.74
 iteration   774000/10000000 | consumed samples:     99072000 | elapsed time per iteration (ms): 245.3 | learning rate: 2.993E-05 | global batch size:   128 | lm loss: 1.718733E+00 | sop loss: 6.077669E-02 | loss scale: 8192.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.02 | backward-compute: 79.83 | backward-params-all-reduce: 14.39 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.57 | batch-generator: 15.40
 iteration   775000/10000000 | consumed samples:     99200000 | elapsed time per iteration (ms): 247.8 | learning rate: 2.984E-05 | global batch size:   128 | lm loss: 1.717503E+00 | sop loss: 6.133476E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.02 | backward-compute: 79.77 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 13.65
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 775000 | lm loss value: 1.773538E+00 | lm loss PPL: 5.891661E+00 | sop loss value: 7.921892E-02 | sop loss PPL: 1.082441E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   776000/10000000 | consumed samples:     99328000 | elapsed time per iteration (ms): 250.1 | learning rate: 2.975E-05 | global batch size:   128 | lm loss: 1.719021E+00 | sop loss: 6.092853E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.74 | backward-compute: 79.83 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.41 | batch-generator: 20.06
 iteration   777000/10000000 | consumed samples:     99456000 | elapsed time per iteration (ms): 248.3 | learning rate: 2.966E-05 | global batch size:   128 | lm loss: 1.718432E+00 | sop loss: 6.014551E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.61 | backward-compute: 79.78 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 17.84
 iteration   778000/10000000 | consumed samples:     99584000 | elapsed time per iteration (ms): 245.8 | learning rate: 2.956E-05 | global batch size:   128 | lm loss: 1.719914E+00 | sop loss: 6.102904E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.08 | backward-compute: 79.85 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.02
 iteration   779000/10000000 | consumed samples:     99712000 | elapsed time per iteration (ms): 249.6 | learning rate: 2.947E-05 | global batch size:   128 | lm loss: 1.718573E+00 | sop loss: 5.999137E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.98 | backward-compute: 79.84 | backward-params-all-reduce: 13.89 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 17.80
 iteration   780000/10000000 | consumed samples:     99840000 | elapsed time per iteration (ms): 247.8 | learning rate: 2.938E-05 | global batch size:   128 | lm loss: 1.717027E+00 | sop loss: 6.093734E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.50 | backward-compute: 79.81 | backward-params-all-reduce: 14.33 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.19 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.60 | batch-generator: 15.48
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 780000 | lm loss value: 1.761212E+00 | lm loss PPL: 5.819488E+00 | sop loss value: 6.937612E-02 | sop loss PPL: 1.071839E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   781000/10000000 | consumed samples:     99968000 | elapsed time per iteration (ms): 248.4 | learning rate: 2.929E-05 | global batch size:   128 | lm loss: 1.716088E+00 | sop loss: 6.144657E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.90 | backward-compute: 79.84 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 21.27
 iteration   782000/10000000 | consumed samples:    100096000 | elapsed time per iteration (ms): 251.0 | learning rate: 2.920E-05 | global batch size:   128 | lm loss: 1.715453E+00 | sop loss: 5.889867E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.45 | backward-compute: 79.75 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 20.96
 iteration   783000/10000000 | consumed samples:    100224000 | elapsed time per iteration (ms): 246.1 | learning rate: 2.911E-05 | global batch size:   128 | lm loss: 1.716950E+00 | sop loss: 5.942054E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.53 | backward-compute: 79.83 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 14.97
 iteration   784000/10000000 | consumed samples:    100352000 | elapsed time per iteration (ms): 247.9 | learning rate: 2.901E-05 | global batch size:   128 | lm loss: 1.712641E+00 | sop loss: 5.873364E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.17 | backward-compute: 79.78 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 14.92
 iteration   785000/10000000 | consumed samples:    100480000 | elapsed time per iteration (ms): 246.9 | learning rate: 2.892E-05 | global batch size:   128 | lm loss: 1.716128E+00 | sop loss: 6.115710E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.10 | backward-compute: 79.81 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 16.45
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 785000 | lm loss value: 1.731068E+00 | lm loss PPL: 5.646683E+00 | sop loss value: 6.431432E-02 | sop loss PPL: 1.066428E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   786000/10000000 | consumed samples:    100608000 | elapsed time per iteration (ms): 249.4 | learning rate: 2.883E-05 | global batch size:   128 | lm loss: 1.717341E+00 | sop loss: 6.145008E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.00 | backward-compute: 79.85 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 19.34
 iteration   787000/10000000 | consumed samples:    100736000 | elapsed time per iteration (ms): 246.6 | learning rate: 2.874E-05 | global batch size:   128 | lm loss: 1.715002E+00 | sop loss: 5.935018E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.72 | backward-compute: 79.87 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 20.06
 iteration   788000/10000000 | consumed samples:    100864000 | elapsed time per iteration (ms): 248.2 | learning rate: 2.865E-05 | global batch size:   128 | lm loss: 1.717563E+00 | sop loss: 6.015784E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.61 | backward-compute: 79.84 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 17.33
 iteration   789000/10000000 | consumed samples:    100992000 | elapsed time per iteration (ms): 247.8 | learning rate: 2.856E-05 | global batch size:   128 | lm loss: 1.716740E+00 | sop loss: 6.173027E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.95 | backward-compute: 79.79 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 14.69
 iteration   790000/10000000 | consumed samples:    101120000 | elapsed time per iteration (ms): 249.1 | learning rate: 2.846E-05 | global batch size:   128 | lm loss: 1.713492E+00 | sop loss: 6.093746E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.24 | backward-compute: 79.74 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 15.10
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 790000 | lm loss value: 1.754787E+00 | lm loss PPL: 5.782217E+00 | sop loss value: 6.308098E-02 | sop loss PPL: 1.065113E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   791000/10000000 | consumed samples:    101248000 | elapsed time per iteration (ms): 251.2 | learning rate: 2.837E-05 | global batch size:   128 | lm loss: 1.717364E+00 | sop loss: 6.066077E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.11 | backward-compute: 79.75 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 18.01
 iteration   792000/10000000 | consumed samples:    101376000 | elapsed time per iteration (ms): 248.3 | learning rate: 2.828E-05 | global batch size:   128 | lm loss: 1.714759E+00 | sop loss: 6.072532E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.61 | backward-compute: 79.80 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.15
 iteration   793000/10000000 | consumed samples:    101504000 | elapsed time per iteration (ms): 247.9 | learning rate: 2.819E-05 | global batch size:   128 | lm loss: 1.714813E+00 | sop loss: 6.093673E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.11 | backward-compute: 79.81 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 24.35
 iteration   794000/10000000 | consumed samples:    101632000 | elapsed time per iteration (ms): 248.9 | learning rate: 2.810E-05 | global batch size:   128 | lm loss: 1.713779E+00 | sop loss: 5.976011E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.85 | backward-compute: 79.86 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.54 | batch-generator: 21.25
 iteration   795000/10000000 | consumed samples:    101760000 | elapsed time per iteration (ms): 247.1 | learning rate: 2.801E-05 | global batch size:   128 | lm loss: 1.711170E+00 | sop loss: 5.883157E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.05 | backward-compute: 79.86 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 16.56
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 795000 | lm loss value: 1.779130E+00 | lm loss PPL: 5.924702E+00 | sop loss value: 9.186293E-02 | sop loss PPL: 1.096215E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   796000/10000000 | consumed samples:    101888000 | elapsed time per iteration (ms): 249.3 | learning rate: 2.791E-05 | global batch size:   128 | lm loss: 1.713702E+00 | sop loss: 6.008174E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.59 | backward-compute: 79.89 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 16.61
 iteration   797000/10000000 | consumed samples:    102016000 | elapsed time per iteration (ms): 250.5 | learning rate: 2.782E-05 | global batch size:   128 | lm loss: 1.711774E+00 | sop loss: 5.917861E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.36 | backward-compute: 79.77 | backward-params-all-reduce: 14.29 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.54 | batch-generator: 14.63
 iteration   798000/10000000 | consumed samples:    102144000 | elapsed time per iteration (ms): 247.8 | learning rate: 2.773E-05 | global batch size:   128 | lm loss: 1.711625E+00 | sop loss: 6.007783E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.12 | backward-compute: 79.77 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 15.70
 iteration   799000/10000000 | consumed samples:    102272000 | elapsed time per iteration (ms): 249.1 | learning rate: 2.764E-05 | global batch size:   128 | lm loss: 1.712532E+00 | sop loss: 5.971379E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.96 | backward-compute: 79.74 | backward-params-all-reduce: 14.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.55 | batch-generator: 13.84
 iteration   800000/10000000 | consumed samples:    102400000 | elapsed time per iteration (ms): 248.2 | learning rate: 2.755E-05 | global batch size:   128 | lm loss: 1.713832E+00 | sop loss: 5.951250E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.99 | backward-compute: 79.84 | backward-params-all-reduce: 14.86 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.87 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.34 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.85 | batch-generator: 15.44
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 800000 | lm loss value: 1.764726E+00 | lm loss PPL: 5.839972E+00 | sop loss value: 7.613309E-02 | sop loss PPL: 1.079106E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration  800000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration  800000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2336.40
 iteration   801000/10000000 | consumed samples:    102528000 | elapsed time per iteration (ms): 254.4 | learning rate: 2.746E-05 | global batch size:   128 | lm loss: 1.710403E+00 | sop loss: 6.019465E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.94 | backward-compute: 79.84 | backward-params-all-reduce: 13.87 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 28.26
 iteration   802000/10000000 | consumed samples:    102656000 | elapsed time per iteration (ms): 247.5 | learning rate: 2.736E-05 | global batch size:   128 | lm loss: 1.712805E+00 | sop loss: 6.150417E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.33 | backward-compute: 79.80 | backward-params-all-reduce: 14.31 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.54 | batch-generator: 12.52
 iteration   803000/10000000 | consumed samples:    102784000 | elapsed time per iteration (ms): 250.4 | learning rate: 2.727E-05 | global batch size:   128 | lm loss: 1.705553E+00 | sop loss: 5.832892E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.65 | backward-compute: 79.89 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 12.61
 iteration   804000/10000000 | consumed samples:    102912000 | elapsed time per iteration (ms): 249.4 | learning rate: 2.718E-05 | global batch size:   128 | lm loss: 1.712070E+00 | sop loss: 5.862819E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.83 | backward-compute: 79.81 | backward-params-all-reduce: 13.89 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 13.92
 iteration   805000/10000000 | consumed samples:    103040000 | elapsed time per iteration (ms): 247.9 | learning rate: 2.709E-05 | global batch size:   128 | lm loss: 1.708978E+00 | sop loss: 5.998959E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.62 | backward-compute: 79.83 | backward-params-all-reduce: 14.31 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.62 | batch-generator: 16.39
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 805000 | lm loss value: 1.780966E+00 | lm loss PPL: 5.935586E+00 | sop loss value: 7.915691E-02 | sop loss PPL: 1.082374E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   806000/10000000 | consumed samples:    103168000 | elapsed time per iteration (ms): 249.0 | learning rate: 2.700E-05 | global batch size:   128 | lm loss: 1.709134E+00 | sop loss: 5.937040E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.70 | backward-compute: 79.91 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 16.93
 iteration   807000/10000000 | consumed samples:    103296000 | elapsed time per iteration (ms): 247.9 | learning rate: 2.690E-05 | global batch size:   128 | lm loss: 1.710793E+00 | sop loss: 5.837290E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.11 | backward-compute: 79.87 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 17.92
 iteration   808000/10000000 | consumed samples:    103424000 | elapsed time per iteration (ms): 246.7 | learning rate: 2.681E-05 | global batch size:   128 | lm loss: 1.709307E+00 | sop loss: 6.073109E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.08 | backward-compute: 79.86 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 16.63
 iteration   809000/10000000 | consumed samples:    103552000 | elapsed time per iteration (ms): 247.4 | learning rate: 2.672E-05 | global batch size:   128 | lm loss: 1.710169E+00 | sop loss: 5.962725E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.51 | backward-compute: 79.90 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 16.89
 iteration   810000/10000000 | consumed samples:    103680000 | elapsed time per iteration (ms): 249.6 | learning rate: 2.663E-05 | global batch size:   128 | lm loss: 1.709996E+00 | sop loss: 5.963945E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.04 | backward-compute: 79.79 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 15.53
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 810000 | lm loss value: 1.742254E+00 | lm loss PPL: 5.710199E+00 | sop loss value: 7.726203E-02 | sop loss PPL: 1.080325E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   811000/10000000 | consumed samples:    103808000 | elapsed time per iteration (ms): 249.6 | learning rate: 2.654E-05 | global batch size:   128 | lm loss: 1.711885E+00 | sop loss: 5.877916E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.10 | backward-compute: 79.80 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.48 | batch-generator: 23.48
 iteration   812000/10000000 | consumed samples:    103936000 | elapsed time per iteration (ms): 249.3 | learning rate: 2.645E-05 | global batch size:   128 | lm loss: 1.711701E+00 | sop loss: 6.075406E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.22 | backward-compute: 79.76 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.55 | batch-generator: 18.76
 iteration   813000/10000000 | consumed samples:    104064000 | elapsed time per iteration (ms): 248.9 | learning rate: 2.635E-05 | global batch size:   128 | lm loss: 1.706929E+00 | sop loss: 5.916232E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.17 | backward-compute: 79.82 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 19.39
 iteration   814000/10000000 | consumed samples:    104192000 | elapsed time per iteration (ms): 251.6 | learning rate: 2.626E-05 | global batch size:   128 | lm loss: 1.710704E+00 | sop loss: 6.083334E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.05 | backward-compute: 79.77 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 21.62
 iteration   815000/10000000 | consumed samples:    104320000 | elapsed time per iteration (ms): 247.8 | learning rate: 2.617E-05 | global batch size:   128 | lm loss: 1.707621E+00 | sop loss: 6.068475E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.19 | backward-compute: 79.81 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 17.11
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 815000 | lm loss value: 1.738200E+00 | lm loss PPL: 5.687095E+00 | sop loss value: 7.742783E-02 | sop loss PPL: 1.080504E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   816000/10000000 | consumed samples:    104448000 | elapsed time per iteration (ms): 250.0 | learning rate: 2.608E-05 | global batch size:   128 | lm loss: 1.706198E+00 | sop loss: 5.958065E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.74 | backward-compute: 79.77 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 17.26
 iteration   817000/10000000 | consumed samples:    104576000 | elapsed time per iteration (ms): 249.0 | learning rate: 2.599E-05 | global batch size:   128 | lm loss: 1.705688E+00 | sop loss: 5.865338E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.30 | backward-compute: 79.77 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 14.60
 iteration   818000/10000000 | consumed samples:    104704000 | elapsed time per iteration (ms): 247.7 | learning rate: 2.590E-05 | global batch size:   128 | lm loss: 1.704236E+00 | sop loss: 5.903011E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.06 | backward-compute: 79.82 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 15.90
 iteration   819000/10000000 | consumed samples:    104832000 | elapsed time per iteration (ms): 248.3 | learning rate: 2.580E-05 | global batch size:   128 | lm loss: 1.706179E+00 | sop loss: 5.953139E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.69 | backward-compute: 79.80 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 12.35
 iteration   820000/10000000 | consumed samples:    104960000 | elapsed time per iteration (ms): 247.8 | learning rate: 2.571E-05 | global batch size:   128 | lm loss: 1.710883E+00 | sop loss: 5.912699E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.49 | backward-compute: 79.80 | backward-params-all-reduce: 14.41 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.22 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.63 | batch-generator: 15.88
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 820000 | lm loss value: 1.699141E+00 | lm loss PPL: 5.469245E+00 | sop loss value: 7.552060E-02 | sop loss PPL: 1.078445E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   821000/10000000 | consumed samples:    105088000 | elapsed time per iteration (ms): 250.4 | learning rate: 2.562E-05 | global batch size:   128 | lm loss: 1.701616E+00 | sop loss: 5.809205E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.23 | backward-compute: 79.77 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 17.89
 iteration   822000/10000000 | consumed samples:    105216000 | elapsed time per iteration (ms): 247.7 | learning rate: 2.553E-05 | global batch size:   128 | lm loss: 1.707105E+00 | sop loss: 5.970324E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.88 | backward-compute: 79.76 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.46 | batch-generator: 14.20
 iteration   823000/10000000 | consumed samples:    105344000 | elapsed time per iteration (ms): 246.8 | learning rate: 2.544E-05 | global batch size:   128 | lm loss: 1.706314E+00 | sop loss: 5.833953E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.93 | backward-compute: 79.77 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 11.72
 iteration   824000/10000000 | consumed samples:    105472000 | elapsed time per iteration (ms): 248.7 | learning rate: 2.535E-05 | global batch size:   128 | lm loss: 1.705730E+00 | sop loss: 5.921125E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.08 | backward-compute: 79.81 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 18.33
 iteration   825000/10000000 | consumed samples:    105600000 | elapsed time per iteration (ms): 247.6 | learning rate: 2.525E-05 | global batch size:   128 | lm loss: 1.703940E+00 | sop loss: 5.772611E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.00 | backward-compute: 79.89 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 15.55
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 825000 | lm loss value: 1.736140E+00 | lm loss PPL: 5.675395E+00 | sop loss value: 6.090432E-02 | sop loss PPL: 1.062797E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   826000/10000000 | consumed samples:    105728000 | elapsed time per iteration (ms): 253.2 | learning rate: 2.516E-05 | global batch size:   128 | lm loss: 1.708062E+00 | sop loss: 5.883162E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.15 | backward-compute: 79.76 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 16.29
 iteration   827000/10000000 | consumed samples:    105856000 | elapsed time per iteration (ms): 246.6 | learning rate: 2.507E-05 | global batch size:   128 | lm loss: 1.705131E+00 | sop loss: 5.932509E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.95 | backward-compute: 79.78 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 18.10
 iteration   828000/10000000 | consumed samples:    105984000 | elapsed time per iteration (ms): 247.2 | learning rate: 2.498E-05 | global batch size:   128 | lm loss: 1.704175E+00 | sop loss: 5.945145E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.91 | backward-compute: 79.86 | backward-params-all-reduce: 14.36 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.58 | batch-generator: 15.61
 iteration   829000/10000000 | consumed samples:    106112000 | elapsed time per iteration (ms): 246.9 | learning rate: 2.489E-05 | global batch size:   128 | lm loss: 1.708261E+00 | sop loss: 5.906105E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.98 | backward-compute: 79.80 | backward-params-all-reduce: 14.78 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.29 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.76 | batch-generator: 14.14
 iteration   830000/10000000 | consumed samples:    106240000 | elapsed time per iteration (ms): 248.7 | learning rate: 2.480E-05 | global batch size:   128 | lm loss: 1.703908E+00 | sop loss: 6.079980E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.89 | backward-compute: 79.78 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 14.83
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 830000 | lm loss value: 1.744420E+00 | lm loss PPL: 5.722581E+00 | sop loss value: 5.973113E-02 | sop loss PPL: 1.061551E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   831000/10000000 | consumed samples:    106368000 | elapsed time per iteration (ms): 250.1 | learning rate: 2.470E-05 | global batch size:   128 | lm loss: 1.706726E+00 | sop loss: 5.912360E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.82 | backward-compute: 79.78 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.41 | batch-generator: 12.71
 iteration   832000/10000000 | consumed samples:    106496000 | elapsed time per iteration (ms): 248.3 | learning rate: 2.461E-05 | global batch size:   128 | lm loss: 1.705075E+00 | sop loss: 6.097327E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.85 | backward-compute: 79.78 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 13.26
 iteration   833000/10000000 | consumed samples:    106624000 | elapsed time per iteration (ms): 247.3 | learning rate: 2.452E-05 | global batch size:   128 | lm loss: 1.704474E+00 | sop loss: 5.952712E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.44 | backward-compute: 79.79 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.41 | batch-generator: 15.31
 iteration   834000/10000000 | consumed samples:    106752000 | elapsed time per iteration (ms): 246.3 | learning rate: 2.443E-05 | global batch size:   128 | lm loss: 1.703013E+00 | sop loss: 5.855125E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.54 | backward-compute: 79.83 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 13.84
 iteration   835000/10000000 | consumed samples:    106880000 | elapsed time per iteration (ms): 246.5 | learning rate: 2.434E-05 | global batch size:   128 | lm loss: 1.703609E+00 | sop loss: 5.823494E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.33 | backward-compute: 79.85 | backward-params-all-reduce: 14.29 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.60 | batch-generator: 16.06
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 835000 | lm loss value: 1.776225E+00 | lm loss PPL: 5.907513E+00 | sop loss value: 7.407597E-02 | sop loss PPL: 1.076889E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   836000/10000000 | consumed samples:    107008000 | elapsed time per iteration (ms): 250.2 | learning rate: 2.425E-05 | global batch size:   128 | lm loss: 1.703341E+00 | sop loss: 5.912479E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.88 | backward-compute: 79.80 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 17.28
 iteration   837000/10000000 | consumed samples:    107136000 | elapsed time per iteration (ms): 247.5 | learning rate: 2.415E-05 | global batch size:   128 | lm loss: 1.702410E+00 | sop loss: 5.783826E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.85 | backward-compute: 79.88 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 15.91
 iteration   838000/10000000 | consumed samples:    107264000 | elapsed time per iteration (ms): 249.6 | learning rate: 2.406E-05 | global batch size:   128 | lm loss: 1.701889E+00 | sop loss: 5.898859E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.48 | backward-compute: 79.83 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 14.45
 iteration   839000/10000000 | consumed samples:    107392000 | elapsed time per iteration (ms): 249.1 | learning rate: 2.397E-05 | global batch size:   128 | lm loss: 1.699675E+00 | sop loss: 5.885586E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.41 | backward-compute: 79.82 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 14.02
 iteration   840000/10000000 | consumed samples:    107520000 | elapsed time per iteration (ms): 247.3 | learning rate: 2.388E-05 | global batch size:   128 | lm loss: 1.703453E+00 | sop loss: 5.791569E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.68 | backward-compute: 79.91 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.24 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 11.93
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 840000 | lm loss value: 1.722258E+00 | lm loss PPL: 5.597155E+00 | sop loss value: 6.254146E-02 | sop loss PPL: 1.064539E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   841000/10000000 | consumed samples:    107648000 | elapsed time per iteration (ms): 248.8 | learning rate: 2.379E-05 | global batch size:   128 | lm loss: 1.699427E+00 | sop loss: 5.869354E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.60 | backward-compute: 79.87 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 18.97
 iteration   842000/10000000 | consumed samples:    107776000 | elapsed time per iteration (ms): 250.0 | learning rate: 2.370E-05 | global batch size:   128 | lm loss: 1.701744E+00 | sop loss: 5.865498E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.22 | backward-compute: 79.80 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 21.77
 iteration   843000/10000000 | consumed samples:    107904000 | elapsed time per iteration (ms): 250.0 | learning rate: 2.360E-05 | global batch size:   128 | lm loss: 1.702323E+00 | sop loss: 5.813544E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.22 | backward-compute: 79.84 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.50 | batch-generator: 22.83
 iteration   844000/10000000 | consumed samples:    108032000 | elapsed time per iteration (ms): 249.0 | learning rate: 2.351E-05 | global batch size:   128 | lm loss: 1.698683E+00 | sop loss: 5.846164E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.77 | backward-compute: 79.80 | backward-params-all-reduce: 14.40 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 13.28
 iteration   845000/10000000 | consumed samples:    108160000 | elapsed time per iteration (ms): 247.9 | learning rate: 2.342E-05 | global batch size:   128 | lm loss: 1.700600E+00 | sop loss: 5.881453E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.75 | backward-compute: 79.84 | backward-params-all-reduce: 14.81 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.87 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.37 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.88 | batch-generator: 14.92
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 845000 | lm loss value: 1.729020E+00 | lm loss PPL: 5.635129E+00 | sop loss value: 7.434558E-02 | sop loss PPL: 1.077179E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   846000/10000000 | consumed samples:    108288000 | elapsed time per iteration (ms): 248.5 | learning rate: 2.333E-05 | global batch size:   128 | lm loss: 1.701097E+00 | sop loss: 5.855894E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.41 | backward-compute: 79.90 | backward-params-all-reduce: 14.35 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.19 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.63 | batch-generator: 18.43
 iteration   847000/10000000 | consumed samples:    108416000 | elapsed time per iteration (ms): 249.1 | learning rate: 2.324E-05 | global batch size:   128 | lm loss: 1.699357E+00 | sop loss: 5.921767E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.46 | backward-compute: 79.80 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 15.09
 iteration   848000/10000000 | consumed samples:    108544000 | elapsed time per iteration (ms): 249.2 | learning rate: 2.315E-05 | global batch size:   128 | lm loss: 1.698929E+00 | sop loss: 5.939755E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.28 | backward-compute: 79.83 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 17.89
 iteration   849000/10000000 | consumed samples:    108672000 | elapsed time per iteration (ms): 247.6 | learning rate: 2.305E-05 | global batch size:   128 | lm loss: 1.702624E+00 | sop loss: 5.799692E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.96 | backward-compute: 79.80 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 17.21
 iteration   850000/10000000 | consumed samples:    108800000 | elapsed time per iteration (ms): 246.8 | learning rate: 2.296E-05 | global batch size:   128 | lm loss: 1.700412E+00 | sop loss: 5.904930E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.06 | backward-compute: 79.81 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.45 | batch-generator: 16.12
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 850000 | lm loss value: 1.759243E+00 | lm loss PPL: 5.808040E+00 | sop loss value: 7.058017E-02 | sop loss PPL: 1.073131E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration  850000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration  850000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2340.41
 iteration   851000/10000000 | consumed samples:    108928000 | elapsed time per iteration (ms): 251.3 | learning rate: 2.287E-05 | global batch size:   128 | lm loss: 1.700935E+00 | sop loss: 5.919383E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.68 | backward-compute: 79.88 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 17.15
 iteration   852000/10000000 | consumed samples:    109056000 | elapsed time per iteration (ms): 246.7 | learning rate: 2.278E-05 | global batch size:   128 | lm loss: 1.698629E+00 | sop loss: 5.877274E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.87 | backward-compute: 79.89 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 18.16
 iteration   853000/10000000 | consumed samples:    109184000 | elapsed time per iteration (ms): 250.1 | learning rate: 2.269E-05 | global batch size:   128 | lm loss: 1.705295E+00 | sop loss: 5.693167E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.42 | backward-compute: 79.80 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 19.75
 iteration   854000/10000000 | consumed samples:    109312000 | elapsed time per iteration (ms): 246.7 | learning rate: 2.260E-05 | global batch size:   128 | lm loss: 1.699914E+00 | sop loss: 5.913472E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.01 | backward-compute: 79.83 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 16.86
 iteration   855000/10000000 | consumed samples:    109440000 | elapsed time per iteration (ms): 248.7 | learning rate: 2.250E-05 | global batch size:   128 | lm loss: 1.698655E+00 | sop loss: 5.950919E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.21 | backward-compute: 79.78 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 17.48
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 855000 | lm loss value: 1.715602E+00 | lm loss PPL: 5.560023E+00 | sop loss value: 6.195024E-02 | sop loss PPL: 1.063909E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   856000/10000000 | consumed samples:    109568000 | elapsed time per iteration (ms): 249.7 | learning rate: 2.241E-05 | global batch size:   128 | lm loss: 1.703221E+00 | sop loss: 5.905727E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.24 | backward-compute: 79.82 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 18.58
 iteration   857000/10000000 | consumed samples:    109696000 | elapsed time per iteration (ms): 246.2 | learning rate: 2.232E-05 | global batch size:   128 | lm loss: 1.703831E+00 | sop loss: 5.731804E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.46 | backward-compute: 79.81 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 12.78
 iteration   858000/10000000 | consumed samples:    109824000 | elapsed time per iteration (ms): 249.6 | learning rate: 2.223E-05 | global batch size:   128 | lm loss: 1.699816E+00 | sop loss: 5.871883E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.00 | backward-compute: 79.80 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 11.91
 iteration   859000/10000000 | consumed samples:    109952000 | elapsed time per iteration (ms): 251.3 | learning rate: 2.214E-05 | global batch size:   128 | lm loss: 1.698037E+00 | sop loss: 5.840479E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.79 | backward-compute: 79.79 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 14.37
 iteration   860000/10000000 | consumed samples:    110080000 | elapsed time per iteration (ms): 247.5 | learning rate: 2.204E-05 | global batch size:   128 | lm loss: 1.695938E+00 | sop loss: 5.781342E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.32 | backward-compute: 79.90 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.55 | batch-generator: 17.41
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 860000 | lm loss value: 1.750280E+00 | lm loss PPL: 5.756213E+00 | sop loss value: 5.930491E-02 | sop loss PPL: 1.061099E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   861000/10000000 | consumed samples:    110208000 | elapsed time per iteration (ms): 248.3 | learning rate: 2.195E-05 | global batch size:   128 | lm loss: 1.694483E+00 | sop loss: 5.701743E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.98 | backward-compute: 79.80 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.24
 iteration   862000/10000000 | consumed samples:    110336000 | elapsed time per iteration (ms): 250.4 | learning rate: 2.186E-05 | global batch size:   128 | lm loss: 1.696340E+00 | sop loss: 5.829952E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.84 | backward-compute: 79.82 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 15.75
 iteration   863000/10000000 | consumed samples:    110464000 | elapsed time per iteration (ms): 247.6 | learning rate: 2.177E-05 | global batch size:   128 | lm loss: 1.695777E+00 | sop loss: 5.847993E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.05 | backward-compute: 79.76 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 18.47
 iteration   864000/10000000 | consumed samples:    110592000 | elapsed time per iteration (ms): 248.7 | learning rate: 2.168E-05 | global batch size:   128 | lm loss: 1.696420E+00 | sop loss: 6.051893E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.01 | backward-compute: 79.80 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 19.79
 iteration   865000/10000000 | consumed samples:    110720000 | elapsed time per iteration (ms): 248.5 | learning rate: 2.159E-05 | global batch size:   128 | lm loss: 1.694298E+00 | sop loss: 5.792487E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.79 | backward-compute: 79.85 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 20.49
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 865000 | lm loss value: 1.735477E+00 | lm loss PPL: 5.671631E+00 | sop loss value: 6.035785E-02 | sop loss PPL: 1.062217E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   866000/10000000 | consumed samples:    110848000 | elapsed time per iteration (ms): 249.9 | learning rate: 2.149E-05 | global batch size:   128 | lm loss: 1.696751E+00 | sop loss: 5.933574E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.63 | backward-compute: 79.85 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 13.64
 iteration   867000/10000000 | consumed samples:    110976000 | elapsed time per iteration (ms): 248.1 | learning rate: 2.140E-05 | global batch size:   128 | lm loss: 1.695769E+00 | sop loss: 5.752451E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.38 | backward-compute: 79.83 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 13.01
 iteration   868000/10000000 | consumed samples:    111104000 | elapsed time per iteration (ms): 249.9 | learning rate: 2.131E-05 | global batch size:   128 | lm loss: 1.696939E+00 | sop loss: 5.775145E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.24 | backward-compute: 79.81 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.14
 iteration   869000/10000000 | consumed samples:    111232000 | elapsed time per iteration (ms): 247.4 | learning rate: 2.122E-05 | global batch size:   128 | lm loss: 1.697427E+00 | sop loss: 5.894008E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.60 | backward-compute: 79.80 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 11.62
 iteration   870000/10000000 | consumed samples:    111360000 | elapsed time per iteration (ms): 250.8 | learning rate: 2.113E-05 | global batch size:   128 | lm loss: 1.689304E+00 | sop loss: 5.822987E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.35 | backward-compute: 79.78 | backward-params-all-reduce: 13.90 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 25.28
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 870000 | lm loss value: 1.746147E+00 | lm loss PPL: 5.732470E+00 | sop loss value: 8.372729E-02 | sop loss PPL: 1.087332E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   871000/10000000 | consumed samples:    111488000 | elapsed time per iteration (ms): 249.5 | learning rate: 2.104E-05 | global batch size:   128 | lm loss: 1.697717E+00 | sop loss: 5.852445E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.56 | backward-compute: 79.85 | backward-params-all-reduce: 13.79 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 22.14
 iteration   872000/10000000 | consumed samples:    111616000 | elapsed time per iteration (ms): 249.4 | learning rate: 2.094E-05 | global batch size:   128 | lm loss: 1.698057E+00 | sop loss: 5.873944E-02 | loss scale: 8192.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.66 | backward-compute: 79.74 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.45 | batch-generator: 14.04
 iteration   873000/10000000 | consumed samples:    111744000 | elapsed time per iteration (ms): 247.6 | learning rate: 2.085E-05 | global batch size:   128 | lm loss: 1.696713E+00 | sop loss: 5.796920E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.92 | backward-compute: 79.81 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 13.27
 iteration   874000/10000000 | consumed samples:    111872000 | elapsed time per iteration (ms): 247.9 | learning rate: 2.076E-05 | global batch size:   128 | lm loss: 1.696914E+00 | sop loss: 5.704822E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.23 | backward-compute: 79.85 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 20.74
 iteration   875000/10000000 | consumed samples:    112000000 | elapsed time per iteration (ms): 246.4 | learning rate: 2.067E-05 | global batch size:   128 | lm loss: 1.697388E+00 | sop loss: 5.793455E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.83 | backward-compute: 79.80 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 16.88
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 875000 | lm loss value: 1.721798E+00 | lm loss PPL: 5.594577E+00 | sop loss value: 6.800653E-02 | sop loss PPL: 1.070372E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   876000/10000000 | consumed samples:    112128000 | elapsed time per iteration (ms): 251.5 | learning rate: 2.058E-05 | global batch size:   128 | lm loss: 1.693311E+00 | sop loss: 5.894132E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.38 | backward-compute: 79.77 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.24 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 13.69
 iteration   877000/10000000 | consumed samples:    112256000 | elapsed time per iteration (ms): 250.4 | learning rate: 2.049E-05 | global batch size:   128 | lm loss: 1.693123E+00 | sop loss: 5.847312E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.49 | backward-compute: 79.75 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.47 | batch-generator: 12.06
 iteration   878000/10000000 | consumed samples:    112384000 | elapsed time per iteration (ms): 247.9 | learning rate: 2.039E-05 | global batch size:   128 | lm loss: 1.694888E+00 | sop loss: 5.780787E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.91 | backward-compute: 79.74 | backward-params-all-reduce: 14.28 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 12.65
 iteration   879000/10000000 | consumed samples:    112512000 | elapsed time per iteration (ms): 250.5 | learning rate: 2.030E-05 | global batch size:   128 | lm loss: 1.694595E+00 | sop loss: 5.858472E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.98 | backward-compute: 79.78 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 14.49
 iteration   880000/10000000 | consumed samples:    112640000 | elapsed time per iteration (ms): 248.7 | learning rate: 2.021E-05 | global batch size:   128 | lm loss: 1.692046E+00 | sop loss: 5.675693E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.12 | backward-compute: 79.78 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 13.90
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 880000 | lm loss value: 1.738404E+00 | lm loss PPL: 5.688259E+00 | sop loss value: 7.342901E-02 | sop loss PPL: 1.076192E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   881000/10000000 | consumed samples:    112768000 | elapsed time per iteration (ms): 250.8 | learning rate: 2.012E-05 | global batch size:   128 | lm loss: 1.693292E+00 | sop loss: 5.796689E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.56 | backward-compute: 79.78 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 17.25
 iteration   882000/10000000 | consumed samples:    112896000 | elapsed time per iteration (ms): 248.9 | learning rate: 2.003E-05 | global batch size:   128 | lm loss: 1.694938E+00 | sop loss: 5.690770E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.21 | backward-compute: 79.77 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 18.86
 iteration   883000/10000000 | consumed samples:    113024000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.994E-05 | global batch size:   128 | lm loss: 1.693056E+00 | sop loss: 5.834789E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.06 | backward-compute: 79.82 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 17.61
 iteration   884000/10000000 | consumed samples:    113152000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.984E-05 | global batch size:   128 | lm loss: 1.695410E+00 | sop loss: 5.833074E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.15 | backward-compute: 79.85 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 19.27
 iteration   885000/10000000 | consumed samples:    113280000 | elapsed time per iteration (ms): 250.7 | learning rate: 1.975E-05 | global batch size:   128 | lm loss: 1.690011E+00 | sop loss: 5.808088E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.84 | backward-compute: 79.83 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 15.01
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 885000 | lm loss value: 1.733948E+00 | lm loss PPL: 5.662968E+00 | sop loss value: 6.892300E-02 | sop loss PPL: 1.071354E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   886000/10000000 | consumed samples:    113408000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.966E-05 | global batch size:   128 | lm loss: 1.694091E+00 | sop loss: 5.709313E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.44 | backward-compute: 79.84 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 11.84
 iteration   887000/10000000 | consumed samples:    113536000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.957E-05 | global batch size:   128 | lm loss: 1.690973E+00 | sop loss: 5.804526E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.73 | backward-compute: 79.81 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 13.01
 iteration   888000/10000000 | consumed samples:    113664000 | elapsed time per iteration (ms): 250.6 | learning rate: 1.948E-05 | global batch size:   128 | lm loss: 1.693335E+00 | sop loss: 5.656591E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.01 | backward-compute: 79.79 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 12.62
 iteration   889000/10000000 | consumed samples:    113792000 | elapsed time per iteration (ms): 251.3 | learning rate: 1.939E-05 | global batch size:   128 | lm loss: 1.691647E+00 | sop loss: 5.622328E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.60 | backward-compute: 79.78 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 15.36
 iteration   890000/10000000 | consumed samples:    113920000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.929E-05 | global batch size:   128 | lm loss: 1.689892E+00 | sop loss: 5.656236E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.41 | backward-compute: 79.83 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 13.51
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 890000 | lm loss value: 1.714746E+00 | lm loss PPL: 5.555267E+00 | sop loss value: 5.609512E-02 | sop loss PPL: 1.057698E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   891000/10000000 | consumed samples:    114048000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.920E-05 | global batch size:   128 | lm loss: 1.687098E+00 | sop loss: 5.955420E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.97 | backward-compute: 79.75 | backward-params-all-reduce: 14.28 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 13.92
 iteration   892000/10000000 | consumed samples:    114176000 | elapsed time per iteration (ms): 246.4 | learning rate: 1.911E-05 | global batch size:   128 | lm loss: 1.690432E+00 | sop loss: 5.841862E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.50 | backward-compute: 79.90 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 16.31
 iteration   893000/10000000 | consumed samples:    114304000 | elapsed time per iteration (ms): 246.1 | learning rate: 1.902E-05 | global batch size:   128 | lm loss: 1.690723E+00 | sop loss: 5.762388E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.25 | backward-compute: 79.83 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.01
 iteration   894000/10000000 | consumed samples:    114432000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.893E-05 | global batch size:   128 | lm loss: 1.689127E+00 | sop loss: 5.850428E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.67 | backward-compute: 79.83 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 15.05
 iteration   895000/10000000 | consumed samples:    114560000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.884E-05 | global batch size:   128 | lm loss: 1.688204E+00 | sop loss: 5.666118E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.78 | backward-compute: 79.83 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 13.75
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 895000 | lm loss value: 1.774102E+00 | lm loss PPL: 5.894988E+00 | sop loss value: 5.896149E-02 | sop loss PPL: 1.060734E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   896000/10000000 | consumed samples:    114688000 | elapsed time per iteration (ms): 249.6 | learning rate: 1.874E-05 | global batch size:   128 | lm loss: 1.691102E+00 | sop loss: 5.711674E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.50 | backward-compute: 79.84 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 14.85
 iteration   897000/10000000 | consumed samples:    114816000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.865E-05 | global batch size:   128 | lm loss: 1.687287E+00 | sop loss: 5.670725E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.87 | backward-compute: 79.82 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 15.06
 iteration   898000/10000000 | consumed samples:    114944000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.856E-05 | global batch size:   128 | lm loss: 1.689039E+00 | sop loss: 5.815699E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.69 | backward-compute: 79.80 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 17.37
 iteration   899000/10000000 | consumed samples:    115072000 | elapsed time per iteration (ms): 247.0 | learning rate: 1.847E-05 | global batch size:   128 | lm loss: 1.690816E+00 | sop loss: 5.807521E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.14 | backward-compute: 79.85 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 13.68
 iteration   900000/10000000 | consumed samples:    115200000 | elapsed time per iteration (ms): 246.8 | learning rate: 1.838E-05 | global batch size:   128 | lm loss: 1.690039E+00 | sop loss: 5.841646E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.22 | backward-compute: 79.79 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 17.26
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 900000 | lm loss value: 1.760086E+00 | lm loss PPL: 5.812936E+00 | sop loss value: 5.321661E-02 | sop loss PPL: 1.054658E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration  900000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration  900000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2345.05
 iteration   901000/10000000 | consumed samples:    115328000 | elapsed time per iteration (ms): 253.3 | learning rate: 1.829E-05 | global batch size:   128 | lm loss: 1.688847E+00 | sop loss: 5.743052E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.58 | backward-compute: 79.79 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.47 | batch-generator: 14.84
 iteration   902000/10000000 | consumed samples:    115456000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.819E-05 | global batch size:   128 | lm loss: 1.689104E+00 | sop loss: 5.727979E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.28 | backward-compute: 79.87 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 16.44
 iteration   903000/10000000 | consumed samples:    115584000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.810E-05 | global batch size:   128 | lm loss: 1.689502E+00 | sop loss: 5.719984E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.10 | backward-compute: 79.96 | backward-params-all-reduce: 13.85 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 15.17
 iteration   904000/10000000 | consumed samples:    115712000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.801E-05 | global batch size:   128 | lm loss: 1.686804E+00 | sop loss: 5.771067E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.44 | backward-compute: 79.83 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.43 | batch-generator: 14.92
 iteration   905000/10000000 | consumed samples:    115840000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.792E-05 | global batch size:   128 | lm loss: 1.689013E+00 | sop loss: 5.557410E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.59 | backward-compute: 79.86 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 19.88
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 905000 | lm loss value: 1.761988E+00 | lm loss PPL: 5.824006E+00 | sop loss value: 7.990035E-02 | sop loss PPL: 1.083179E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   906000/10000000 | consumed samples:    115968000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.783E-05 | global batch size:   128 | lm loss: 1.684867E+00 | sop loss: 5.773566E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.63 | backward-compute: 79.97 | backward-params-all-reduce: 13.91 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 17.21
 iteration   907000/10000000 | consumed samples:    116096000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.773E-05 | global batch size:   128 | lm loss: 1.691319E+00 | sop loss: 5.688107E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.25 | backward-compute: 79.83 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 22.88
 iteration   908000/10000000 | consumed samples:    116224000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.764E-05 | global batch size:   128 | lm loss: 1.685782E+00 | sop loss: 5.726346E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.66 | backward-compute: 79.85 | backward-params-all-reduce: 14.61 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.25 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.69 | batch-generator: 16.50
 iteration   909000/10000000 | consumed samples:    116352000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.755E-05 | global batch size:   128 | lm loss: 1.687624E+00 | sop loss: 5.806631E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.33 | backward-compute: 79.80 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 18.52
 iteration   910000/10000000 | consumed samples:    116480000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.746E-05 | global batch size:   128 | lm loss: 1.688694E+00 | sop loss: 5.703231E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.67 | backward-compute: 79.81 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 18.70
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 910000 | lm loss value: 1.729770E+00 | lm loss PPL: 5.639355E+00 | sop loss value: 6.509854E-02 | sop loss PPL: 1.067264E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   911000/10000000 | consumed samples:    116608000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.737E-05 | global batch size:   128 | lm loss: 1.687163E+00 | sop loss: 5.639443E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.65 | backward-compute: 79.77 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 18.28
 iteration   912000/10000000 | consumed samples:    116736000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.728E-05 | global batch size:   128 | lm loss: 1.686634E+00 | sop loss: 5.902083E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.88 | backward-compute: 79.83 | backward-params-all-reduce: 13.89 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 22.77
 iteration   913000/10000000 | consumed samples:    116864000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.718E-05 | global batch size:   128 | lm loss: 1.688180E+00 | sop loss: 5.754794E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.18 | backward-compute: 79.78 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 12.55
 iteration   914000/10000000 | consumed samples:    116992000 | elapsed time per iteration (ms): 249.9 | learning rate: 1.709E-05 | global batch size:   128 | lm loss: 1.686990E+00 | sop loss: 5.587383E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.32 | backward-compute: 79.79 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 18.63
 iteration   915000/10000000 | consumed samples:    117120000 | elapsed time per iteration (ms): 246.0 | learning rate: 1.700E-05 | global batch size:   128 | lm loss: 1.688985E+00 | sop loss: 5.718767E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.33 | backward-compute: 79.79 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 15.64
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 915000 | lm loss value: 1.728915E+00 | lm loss PPL: 5.634540E+00 | sop loss value: 6.768620E-02 | sop loss PPL: 1.070029E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   916000/10000000 | consumed samples:    117248000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.691E-05 | global batch size:   128 | lm loss: 1.685670E+00 | sop loss: 5.823533E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.58 | backward-compute: 79.81 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.53 | batch-generator: 19.78
 iteration   917000/10000000 | consumed samples:    117376000 | elapsed time per iteration (ms): 245.7 | learning rate: 1.682E-05 | global batch size:   128 | lm loss: 1.681446E+00 | sop loss: 5.766022E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.80 | backward-compute: 79.85 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 15.02
 iteration   918000/10000000 | consumed samples:    117504000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.673E-05 | global batch size:   128 | lm loss: 1.684966E+00 | sop loss: 5.751288E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.76 | backward-compute: 79.90 | backward-params-all-reduce: 13.87 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 14.44
 iteration   919000/10000000 | consumed samples:    117632000 | elapsed time per iteration (ms): 247.0 | learning rate: 1.663E-05 | global batch size:   128 | lm loss: 1.683702E+00 | sop loss: 5.685798E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.38 | backward-compute: 79.75 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 16.39
 iteration   920000/10000000 | consumed samples:    117760000 | elapsed time per iteration (ms): 246.7 | learning rate: 1.654E-05 | global batch size:   128 | lm loss: 1.685080E+00 | sop loss: 5.701120E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.79 | backward-compute: 79.86 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.48 | batch-generator: 16.64
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 920000 | lm loss value: 1.719355E+00 | lm loss PPL: 5.580926E+00 | sop loss value: 5.965089E-02 | sop loss PPL: 1.061466E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   921000/10000000 | consumed samples:    117888000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.645E-05 | global batch size:   128 | lm loss: 1.683729E+00 | sop loss: 5.697483E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.45 | backward-compute: 79.82 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 16.04
 iteration   922000/10000000 | consumed samples:    118016000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.636E-05 | global batch size:   128 | lm loss: 1.685144E+00 | sop loss: 5.935165E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.95 | backward-compute: 79.85 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 18.62
 iteration   923000/10000000 | consumed samples:    118144000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.627E-05 | global batch size:   128 | lm loss: 1.684488E+00 | sop loss: 5.829981E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.30 | backward-compute: 79.87 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 17.78
 iteration   924000/10000000 | consumed samples:    118272000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.618E-05 | global batch size:   128 | lm loss: 1.683863E+00 | sop loss: 5.477736E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.18 | backward-compute: 80.04 | backward-params-all-reduce: 13.77 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.37
 iteration   925000/10000000 | consumed samples:    118400000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.608E-05 | global batch size:   128 | lm loss: 1.681594E+00 | sop loss: 5.656618E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.30 | backward-compute: 79.81 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 14.10
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 925000 | lm loss value: 1.699096E+00 | lm loss PPL: 5.469000E+00 | sop loss value: 7.134074E-02 | sop loss PPL: 1.073947E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   926000/10000000 | consumed samples:    118528000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.599E-05 | global batch size:   128 | lm loss: 1.685175E+00 | sop loss: 5.629002E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.48 | backward-compute: 79.92 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 16.56
 iteration   927000/10000000 | consumed samples:    118656000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.590E-05 | global batch size:   128 | lm loss: 1.682992E+00 | sop loss: 5.673046E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.26 | backward-compute: 79.76 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 13.65
 iteration   928000/10000000 | consumed samples:    118784000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.581E-05 | global batch size:   128 | lm loss: 1.681262E+00 | sop loss: 5.601652E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.71 | backward-compute: 79.80 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 14.87
 iteration   929000/10000000 | consumed samples:    118912000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.572E-05 | global batch size:   128 | lm loss: 1.680997E+00 | sop loss: 5.746234E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.38 | backward-compute: 79.86 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 20.67
 iteration   930000/10000000 | consumed samples:    119040000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.563E-05 | global batch size:   128 | lm loss: 1.683825E+00 | sop loss: 5.627652E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.74 | backward-compute: 79.77 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.50 | batch-generator: 17.64
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 930000 | lm loss value: 1.693991E+00 | lm loss PPL: 5.441155E+00 | sop loss value: 7.876483E-02 | sop loss PPL: 1.081950E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   931000/10000000 | consumed samples:    119168000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.553E-05 | global batch size:   128 | lm loss: 1.688004E+00 | sop loss: 5.655088E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.60 | backward-compute: 79.79 | backward-params-all-reduce: 14.79 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.29 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.76 | batch-generator: 14.81
 iteration   932000/10000000 | consumed samples:    119296000 | elapsed time per iteration (ms): 246.6 | learning rate: 1.544E-05 | global batch size:   128 | lm loss: 1.684417E+00 | sop loss: 5.754698E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.92 | backward-compute: 79.76 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 11.56
 iteration   933000/10000000 | consumed samples:    119424000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.535E-05 | global batch size:   128 | lm loss: 1.681878E+00 | sop loss: 5.544404E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.39 | backward-compute: 79.83 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 17.32
 iteration   934000/10000000 | consumed samples:    119552000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.526E-05 | global batch size:   128 | lm loss: 1.681304E+00 | sop loss: 5.672471E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.06 | backward-compute: 79.86 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 15.98
 iteration   935000/10000000 | consumed samples:    119680000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.517E-05 | global batch size:   128 | lm loss: 1.681826E+00 | sop loss: 5.725296E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.53 | backward-compute: 79.90 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 17.73
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 935000 | lm loss value: 1.696796E+00 | lm loss PPL: 5.456435E+00 | sop loss value: 7.190939E-02 | sop loss PPL: 1.074558E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   936000/10000000 | consumed samples:    119808000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.508E-05 | global batch size:   128 | lm loss: 1.681761E+00 | sop loss: 5.663824E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.82 | backward-compute: 79.85 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 17.63
 iteration   937000/10000000 | consumed samples:    119936000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.498E-05 | global batch size:   128 | lm loss: 1.683476E+00 | sop loss: 5.670174E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.54 | backward-compute: 79.81 | backward-params-all-reduce: 13.92 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 15.86
 iteration   938000/10000000 | consumed samples:    120064000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.489E-05 | global batch size:   128 | lm loss: 1.680583E+00 | sop loss: 5.719116E-02 | loss scale: 8192.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.41 | backward-compute: 79.87 | backward-params-all-reduce: 14.46 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.23 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.67 | batch-generator: 14.56
 iteration   939000/10000000 | consumed samples:    120192000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.480E-05 | global batch size:   128 | lm loss: 1.680428E+00 | sop loss: 5.682766E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.31 | backward-compute: 79.81 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 13.54
 iteration   940000/10000000 | consumed samples:    120320000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.471E-05 | global batch size:   128 | lm loss: 1.681994E+00 | sop loss: 5.751665E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.71 | backward-compute: 79.78 | backward-params-all-reduce: 14.31 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 14.91
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 940000 | lm loss value: 1.747862E+00 | lm loss PPL: 5.742315E+00 | sop loss value: 5.969968E-02 | sop loss PPL: 1.061518E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   941000/10000000 | consumed samples:    120448000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.462E-05 | global batch size:   128 | lm loss: 1.678443E+00 | sop loss: 5.571239E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.70 | backward-compute: 79.83 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 17.58
 iteration   942000/10000000 | consumed samples:    120576000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.452E-05 | global batch size:   128 | lm loss: 1.680140E+00 | sop loss: 5.757275E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.22 | backward-compute: 79.82 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 16.51
 iteration   943000/10000000 | consumed samples:    120704000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.443E-05 | global batch size:   128 | lm loss: 1.680329E+00 | sop loss: 5.498103E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.35 | backward-compute: 79.84 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 16.52
 iteration   944000/10000000 | consumed samples:    120832000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.434E-05 | global batch size:   128 | lm loss: 1.679538E+00 | sop loss: 5.646550E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.19 | backward-compute: 79.81 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 17.56
 iteration   945000/10000000 | consumed samples:    120960000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.425E-05 | global batch size:   128 | lm loss: 1.680133E+00 | sop loss: 5.620906E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.16 | backward-compute: 79.81 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 19.75
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 945000 | lm loss value: 1.724655E+00 | lm loss PPL: 5.610587E+00 | sop loss value: 7.028635E-02 | sop loss PPL: 1.072815E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   946000/10000000 | consumed samples:    121088000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.416E-05 | global batch size:   128 | lm loss: 1.677876E+00 | sop loss: 5.579115E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.98 | backward-compute: 79.78 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.36
 iteration   947000/10000000 | consumed samples:    121216000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.407E-05 | global batch size:   128 | lm loss: 1.679086E+00 | sop loss: 5.755910E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.81 | backward-compute: 79.74 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.76 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 17.47
 iteration   948000/10000000 | consumed samples:    121344000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.397E-05 | global batch size:   128 | lm loss: 1.682594E+00 | sop loss: 5.741372E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.44 | backward-compute: 79.71 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 19.05
 iteration   949000/10000000 | consumed samples:    121472000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.388E-05 | global batch size:   128 | lm loss: 1.676063E+00 | sop loss: 5.682675E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.74 | backward-compute: 79.85 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 14.52
 iteration   950000/10000000 | consumed samples:    121600000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.379E-05 | global batch size:   128 | lm loss: 1.680807E+00 | sop loss: 5.504383E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.96 | backward-compute: 79.76 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 12.79
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 950000 | lm loss value: 1.703171E+00 | lm loss PPL: 5.491334E+00 | sop loss value: 7.499438E-02 | sop loss PPL: 1.077878E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration  950000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration  950000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2333.23
 iteration   951000/10000000 | consumed samples:    121728000 | elapsed time per iteration (ms): 251.7 | learning rate: 1.370E-05 | global batch size:   128 | lm loss: 1.681911E+00 | sop loss: 5.536823E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.16 | backward-compute: 79.80 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 14.70
 iteration   952000/10000000 | consumed samples:    121856000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.361E-05 | global batch size:   128 | lm loss: 1.680739E+00 | sop loss: 5.710149E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.26 | backward-compute: 79.79 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 17.92
 iteration   953000/10000000 | consumed samples:    121984000 | elapsed time per iteration (ms): 247.0 | learning rate: 1.352E-05 | global batch size:   128 | lm loss: 1.676616E+00 | sop loss: 5.676112E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.15 | backward-compute: 79.82 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 15.25
 iteration   954000/10000000 | consumed samples:    122112000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.342E-05 | global batch size:   128 | lm loss: 1.675971E+00 | sop loss: 5.575238E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.57 | backward-compute: 79.80 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 14.61
 iteration   955000/10000000 | consumed samples:    122240000 | elapsed time per iteration (ms): 250.5 | learning rate: 1.333E-05 | global batch size:   128 | lm loss: 1.680533E+00 | sop loss: 5.557566E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.02 | backward-compute: 79.74 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 12.95
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 955000 | lm loss value: 1.727855E+00 | lm loss PPL: 5.628566E+00 | sop loss value: 6.475995E-02 | sop loss PPL: 1.066903E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   956000/10000000 | consumed samples:    122368000 | elapsed time per iteration (ms): 249.9 | learning rate: 1.324E-05 | global batch size:   128 | lm loss: 1.678494E+00 | sop loss: 5.503187E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.28 | backward-compute: 79.74 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.52 | batch-generator: 14.69
 iteration   957000/10000000 | consumed samples:    122496000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.315E-05 | global batch size:   128 | lm loss: 1.678876E+00 | sop loss: 5.499881E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.14 | backward-compute: 79.76 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 17.36
 iteration   958000/10000000 | consumed samples:    122624000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.306E-05 | global batch size:   128 | lm loss: 1.677848E+00 | sop loss: 5.724598E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.71 | backward-compute: 79.84 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 12.55
 iteration   959000/10000000 | consumed samples:    122752000 | elapsed time per iteration (ms): 245.8 | learning rate: 1.297E-05 | global batch size:   128 | lm loss: 1.678781E+00 | sop loss: 5.460173E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.13 | backward-compute: 79.85 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 15.41
 iteration   960000/10000000 | consumed samples:    122880000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.287E-05 | global batch size:   128 | lm loss: 1.677741E+00 | sop loss: 5.563110E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.15 | backward-compute: 79.80 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 19.81
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 960000 | lm loss value: 1.711729E+00 | lm loss PPL: 5.538528E+00 | sop loss value: 7.179572E-02 | sop loss PPL: 1.074436E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   961000/10000000 | consumed samples:    123008000 | elapsed time per iteration (ms): 251.3 | learning rate: 1.278E-05 | global batch size:   128 | lm loss: 1.679107E+00 | sop loss: 5.550664E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.17 | backward-compute: 79.81 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 28.67
 iteration   962000/10000000 | consumed samples:    123136000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.269E-05 | global batch size:   128 | lm loss: 1.675425E+00 | sop loss: 5.570224E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.32 | backward-compute: 79.83 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 20.74
 iteration   963000/10000000 | consumed samples:    123264000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.260E-05 | global batch size:   128 | lm loss: 1.674069E+00 | sop loss: 5.705102E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.62 | backward-compute: 79.79 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 15.12
 iteration   964000/10000000 | consumed samples:    123392000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.251E-05 | global batch size:   128 | lm loss: 1.675716E+00 | sop loss: 5.488192E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.13 | backward-compute: 79.79 | backward-params-all-reduce: 14.37 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.59 | batch-generator: 18.14
 iteration   965000/10000000 | consumed samples:    123520000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.242E-05 | global batch size:   128 | lm loss: 1.676591E+00 | sop loss: 5.560290E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.10 | backward-compute: 79.75 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.11
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 965000 | lm loss value: 1.751815E+00 | lm loss PPL: 5.765055E+00 | sop loss value: 5.354941E-02 | sop loss PPL: 1.055009E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   966000/10000000 | consumed samples:    123648000 | elapsed time per iteration (ms): 249.9 | learning rate: 1.232E-05 | global batch size:   128 | lm loss: 1.675645E+00 | sop loss: 5.591786E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.98 | backward-compute: 79.69 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 16.16
 iteration   967000/10000000 | consumed samples:    123776000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.223E-05 | global batch size:   128 | lm loss: 1.675969E+00 | sop loss: 5.596456E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.53 | backward-compute: 79.80 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 16.15
 iteration   968000/10000000 | consumed samples:    123904000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.214E-05 | global batch size:   128 | lm loss: 1.675994E+00 | sop loss: 5.461330E-02 | loss scale: 8192.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.52 | backward-compute: 79.80 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.85
 iteration   969000/10000000 | consumed samples:    124032000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.205E-05 | global batch size:   128 | lm loss: 1.679225E+00 | sop loss: 5.496027E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.02 | backward-compute: 79.73 | backward-params-all-reduce: 14.33 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.57 | batch-generator: 14.57
 iteration   970000/10000000 | consumed samples:    124160000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.196E-05 | global batch size:   128 | lm loss: 1.675391E+00 | sop loss: 5.579098E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.86 | backward-compute: 79.83 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 13.92
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 970000 | lm loss value: 1.709714E+00 | lm loss PPL: 5.527382E+00 | sop loss value: 7.928647E-02 | sop loss PPL: 1.082514E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   971000/10000000 | consumed samples:    124288000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.187E-05 | global batch size:   128 | lm loss: 1.675979E+00 | sop loss: 5.567463E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.43 | backward-compute: 79.79 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.47
 iteration   972000/10000000 | consumed samples:    124416000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.177E-05 | global batch size:   128 | lm loss: 1.671293E+00 | sop loss: 5.530985E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.92 | backward-compute: 79.85 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 16.87
 iteration   973000/10000000 | consumed samples:    124544000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.168E-05 | global batch size:   128 | lm loss: 1.676554E+00 | sop loss: 5.685805E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.18 | backward-compute: 79.81 | backward-params-all-reduce: 14.37 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.53 | batch-generator: 19.62
 iteration   974000/10000000 | consumed samples:    124672000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.159E-05 | global batch size:   128 | lm loss: 1.674473E+00 | sop loss: 5.580769E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.15 | backward-compute: 79.84 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.57 | batch-generator: 20.71
 iteration   975000/10000000 | consumed samples:    124800000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.150E-05 | global batch size:   128 | lm loss: 1.672026E+00 | sop loss: 5.475569E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.46 | backward-compute: 79.82 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.49
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 975000 | lm loss value: 1.710187E+00 | lm loss PPL: 5.529997E+00 | sop loss value: 7.929505E-02 | sop loss PPL: 1.082524E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   976000/10000000 | consumed samples:    124928000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.141E-05 | global batch size:   128 | lm loss: 1.676535E+00 | sop loss: 5.494666E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.67 | backward-compute: 79.81 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 15.12
 iteration   977000/10000000 | consumed samples:    125056000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.132E-05 | global batch size:   128 | lm loss: 1.674793E+00 | sop loss: 5.558055E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.72 | backward-compute: 79.95 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 16.16
 iteration   978000/10000000 | consumed samples:    125184000 | elapsed time per iteration (ms): 250.4 | learning rate: 1.122E-05 | global batch size:   128 | lm loss: 1.669191E+00 | sop loss: 5.526757E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.67 | backward-compute: 79.78 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 13.60
 iteration   979000/10000000 | consumed samples:    125312000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.113E-05 | global batch size:   128 | lm loss: 1.670750E+00 | sop loss: 5.461384E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.04 | backward-compute: 79.79 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 14.34
 iteration   980000/10000000 | consumed samples:    125440000 | elapsed time per iteration (ms): 249.6 | learning rate: 1.104E-05 | global batch size:   128 | lm loss: 1.670857E+00 | sop loss: 5.422753E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.11 | backward-compute: 79.88 | backward-params-all-reduce: 13.87 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 16.28
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 980000 | lm loss value: 1.695931E+00 | lm loss PPL: 5.451718E+00 | sop loss value: 7.467631E-02 | sop loss PPL: 1.077535E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   981000/10000000 | consumed samples:    125568000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.095E-05 | global batch size:   128 | lm loss: 1.673671E+00 | sop loss: 5.506862E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.58 | backward-compute: 79.84 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 16.98
 iteration   982000/10000000 | consumed samples:    125696000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.086E-05 | global batch size:   128 | lm loss: 1.672092E+00 | sop loss: 5.427033E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.17 | backward-compute: 79.82 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.20 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.61 | batch-generator: 15.44
 iteration   983000/10000000 | consumed samples:    125824000 | elapsed time per iteration (ms): 246.5 | learning rate: 1.077E-05 | global batch size:   128 | lm loss: 1.671857E+00 | sop loss: 5.537393E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.26 | backward-compute: 79.84 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.57 | batch-generator: 15.73
 iteration   984000/10000000 | consumed samples:    125952000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.067E-05 | global batch size:   128 | lm loss: 1.670830E+00 | sop loss: 5.555367E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.98 | backward-compute: 79.84 | backward-params-all-reduce: 14.66 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.87 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.31 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.80 | batch-generator: 14.38
 iteration   985000/10000000 | consumed samples:    126080000 | elapsed time per iteration (ms): 246.1 | learning rate: 1.058E-05 | global batch size:   128 | lm loss: 1.675190E+00 | sop loss: 5.462714E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.97 | backward-compute: 79.85 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 17.42
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 985000 | lm loss value: 1.719279E+00 | lm loss PPL: 5.580505E+00 | sop loss value: 6.308600E-02 | sop loss PPL: 1.065118E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   986000/10000000 | consumed samples:    126208000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.049E-05 | global batch size:   128 | lm loss: 1.670312E+00 | sop loss: 5.395013E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.74 | backward-compute: 79.82 | backward-params-all-reduce: 14.60 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.22 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.64 | batch-generator: 15.30
 iteration   987000/10000000 | consumed samples:    126336000 | elapsed time per iteration (ms): 250.4 | learning rate: 1.040E-05 | global batch size:   128 | lm loss: 1.674382E+00 | sop loss: 5.464548E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.47 | backward-compute: 79.84 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 16.10
 iteration   988000/10000000 | consumed samples:    126464000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.031E-05 | global batch size:   128 | lm loss: 1.670925E+00 | sop loss: 5.507442E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.45 | backward-compute: 79.89 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 18.14
 iteration   989000/10000000 | consumed samples:    126592000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.022E-05 | global batch size:   128 | lm loss: 1.672876E+00 | sop loss: 5.642785E-02 | loss scale: 8192.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.37 | backward-compute: 79.74 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 14.83
 iteration   990000/10000000 | consumed samples:    126720000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.012E-05 | global batch size:   128 | lm loss: 1.673116E+00 | sop loss: 5.636368E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.33 | backward-compute: 79.76 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.39
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 990000 | lm loss value: 1.758908E+00 | lm loss PPL: 5.806095E+00 | sop loss value: 7.209136E-02 | sop loss PPL: 1.074754E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   991000/10000000 | consumed samples:    126848000 | elapsed time per iteration (ms): 250.6 | learning rate: 1.003E-05 | global batch size:   128 | lm loss: 1.669991E+00 | sop loss: 5.435747E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.15 | backward-compute: 79.90 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 12.35
 iteration   992000/10000000 | consumed samples:    126976000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.668620E+00 | sop loss: 5.445060E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.94 | backward-compute: 79.97 | backward-params-all-reduce: 13.90 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 12.33
 iteration   993000/10000000 | consumed samples:    127104000 | elapsed time per iteration (ms): 245.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.670850E+00 | sop loss: 5.462480E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 131.55 | backward-compute: 79.88 | backward-params-all-reduce: 14.76 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.88 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.37 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.90 | batch-generator: 14.04
 iteration   994000/10000000 | consumed samples:    127232000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.674585E+00 | sop loss: 5.536555E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.53 | backward-compute: 79.79 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 12.57
 iteration   995000/10000000 | consumed samples:    127360000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.667039E+00 | sop loss: 5.555134E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.21 | backward-compute: 79.87 | backward-params-all-reduce: 14.35 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.58 | batch-generator: 13.65
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 995000 | lm loss value: 1.698621E+00 | lm loss PPL: 5.466402E+00 | sop loss value: 6.300285E-02 | sop loss PPL: 1.065030E+00 | 
--------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration   996000/10000000 | consumed samples:    127488000 | elapsed time per iteration (ms): 250.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.670748E+00 | sop loss: 5.576145E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.45 | backward-compute: 79.81 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 19.34
 iteration   997000/10000000 | consumed samples:    127616000 | elapsed time per iteration (ms): 246.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.673773E+00 | sop loss: 5.558732E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.78 | backward-compute: 79.80 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 16.15
 iteration   998000/10000000 | consumed samples:    127744000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.668560E+00 | sop loss: 5.514623E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.38 | backward-compute: 79.80 | backward-params-all-reduce: 14.53 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.21 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.64 | batch-generator: 15.28
 iteration   999000/10000000 | consumed samples:    127872000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.671972E+00 | sop loss: 5.593357E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.00 | backward-compute: 79.77 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 14.79
 iteration  1000000/10000000 | consumed samples:    128000000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.672109E+00 | sop loss: 5.563475E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.86 | backward-compute: 79.80 | backward-params-all-reduce: 14.45 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.19 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.62 | batch-generator: 17.73
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1000000 | lm loss value: 1.715529E+00 | lm loss PPL: 5.559615E+00 | sop loss value: 6.463094E-02 | sop loss PPL: 1.066765E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 1000000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 1000000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2311.78
 iteration  1001000/10000000 | consumed samples:    128128000 | elapsed time per iteration (ms): 252.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.671136E+00 | sop loss: 5.441794E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.36 | backward-compute: 79.77 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 17.76
 iteration  1002000/10000000 | consumed samples:    128256000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.669148E+00 | sop loss: 5.534190E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.96 | backward-compute: 79.79 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 14.09
 iteration  1003000/10000000 | consumed samples:    128384000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.668314E+00 | sop loss: 5.482939E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.10 | backward-compute: 79.80 | backward-params-all-reduce: 15.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.88 | optimizer-unscale-and-check-inf: 2.31 | optimizer-clip-main-grad: 4.42 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.95 | batch-generator: 13.28
 iteration  1004000/10000000 | consumed samples:    128512000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.668292E+00 | sop loss: 5.680917E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.47 | backward-compute: 79.82 | backward-params-all-reduce: 14.66 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.31 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.80 | batch-generator: 15.62
 iteration  1005000/10000000 | consumed samples:    128640000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.667245E+00 | sop loss: 5.510695E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.36 | backward-compute: 79.79 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 15.55
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1005000 | lm loss value: 1.735180E+00 | lm loss PPL: 5.669951E+00 | sop loss value: 7.281744E-02 | sop loss PPL: 1.075534E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1006000/10000000 | consumed samples:    128768000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.671208E+00 | sop loss: 5.348839E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.47 | backward-compute: 79.76 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 15.21
 iteration  1007000/10000000 | consumed samples:    128896000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.668576E+00 | sop loss: 5.504591E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.30 | backward-compute: 79.83 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 17.50
 iteration  1008000/10000000 | consumed samples:    129024000 | elapsed time per iteration (ms): 246.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.667953E+00 | sop loss: 5.424702E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.16 | backward-compute: 79.89 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 14.44
 iteration  1009000/10000000 | consumed samples:    129152000 | elapsed time per iteration (ms): 250.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.668013E+00 | sop loss: 5.650334E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.01 | backward-compute: 79.80 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 22.04
 iteration  1010000/10000000 | consumed samples:    129280000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.665619E+00 | sop loss: 5.525647E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.44 | backward-compute: 79.78 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 18.14
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1010000 | lm loss value: 1.729167E+00 | lm loss PPL: 5.635955E+00 | sop loss value: 6.053152E-02 | sop loss PPL: 1.062401E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1011000/10000000 | consumed samples:    129408000 | elapsed time per iteration (ms): 251.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.672310E+00 | sop loss: 5.402786E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.27 | backward-compute: 79.78 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 19.24
 iteration  1012000/10000000 | consumed samples:    129536000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.671000E+00 | sop loss: 5.563673E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.65 | backward-compute: 79.84 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 20.78
 iteration  1013000/10000000 | consumed samples:    129664000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.669284E+00 | sop loss: 5.397371E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.32 | backward-compute: 79.81 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 14.41
 iteration  1014000/10000000 | consumed samples:    129792000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.669024E+00 | sop loss: 5.451157E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.77 | backward-compute: 79.81 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 16.45
 iteration  1015000/10000000 | consumed samples:    129920000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.670040E+00 | sop loss: 5.416945E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.66 | backward-compute: 79.80 | backward-params-all-reduce: 14.46 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.60 | batch-generator: 15.21
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1015000 | lm loss value: 1.707087E+00 | lm loss PPL: 5.512878E+00 | sop loss value: 5.769135E-02 | sop loss PPL: 1.059388E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1016000/10000000 | consumed samples:    130048000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.670658E+00 | sop loss: 5.525430E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.47 | backward-compute: 79.76 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 16.79
 iteration  1017000/10000000 | consumed samples:    130176000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.667832E+00 | sop loss: 5.601637E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.81 | backward-compute: 79.81 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.62
 iteration  1018000/10000000 | consumed samples:    130304000 | elapsed time per iteration (ms): 250.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.667657E+00 | sop loss: 5.578339E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.11 | backward-compute: 79.78 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 16.14
 iteration  1019000/10000000 | consumed samples:    130432000 | elapsed time per iteration (ms): 245.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.670097E+00 | sop loss: 5.333076E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.56 | backward-compute: 79.86 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 15.01
 iteration  1020000/10000000 | consumed samples:    130560000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.666073E+00 | sop loss: 5.528885E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.22 | backward-compute: 79.79 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.22
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1020000 | lm loss value: 1.687119E+00 | lm loss PPL: 5.403892E+00 | sop loss value: 5.889354E-02 | sop loss PPL: 1.060662E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1021000/10000000 | consumed samples:    130688000 | elapsed time per iteration (ms): 250.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.666371E+00 | sop loss: 5.367323E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.25 | backward-compute: 79.82 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 14.03
 iteration  1022000/10000000 | consumed samples:    130816000 | elapsed time per iteration (ms): 246.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.667597E+00 | sop loss: 5.396426E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.31 | backward-compute: 79.86 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 13.83
 iteration  1023000/10000000 | consumed samples:    130944000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.666177E+00 | sop loss: 5.582576E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.60 | backward-compute: 79.87 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 15.01
 iteration  1024000/10000000 | consumed samples:    131072000 | elapsed time per iteration (ms): 249.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.669365E+00 | sop loss: 5.476052E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.98 | backward-compute: 79.84 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 14.19
 iteration  1025000/10000000 | consumed samples:    131200000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.664583E+00 | sop loss: 5.529751E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.96 | backward-compute: 79.77 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 14.87
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1025000 | lm loss value: 1.726434E+00 | lm loss PPL: 5.620577E+00 | sop loss value: 6.915496E-02 | sop loss PPL: 1.071602E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1026000/10000000 | consumed samples:    131328000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.666746E+00 | sop loss: 5.551324E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.88 | backward-compute: 79.81 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 13.66
 iteration  1027000/10000000 | consumed samples:    131456000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.668475E+00 | sop loss: 5.452270E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.07 | backward-compute: 79.82 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 17.81
 iteration  1028000/10000000 | consumed samples:    131584000 | elapsed time per iteration (ms): 250.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.667649E+00 | sop loss: 5.553841E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.22 | backward-compute: 79.82 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 13.71
 iteration  1029000/10000000 | consumed samples:    131712000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.665850E+00 | sop loss: 5.478336E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.88 | backward-compute: 79.77 | backward-params-all-reduce: 14.42 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.56 | batch-generator: 12.48
 iteration  1030000/10000000 | consumed samples:    131840000 | elapsed time per iteration (ms): 246.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.667433E+00 | sop loss: 5.556091E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.40 | backward-compute: 79.79 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 19.64
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1030000 | lm loss value: 1.703091E+00 | lm loss PPL: 5.490894E+00 | sop loss value: 6.800602E-02 | sop loss PPL: 1.070372E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1031000/10000000 | consumed samples:    131968000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.668209E+00 | sop loss: 5.513215E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.46 | backward-compute: 79.81 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 17.09
 iteration  1032000/10000000 | consumed samples:    132096000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.666706E+00 | sop loss: 5.465375E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.58 | backward-compute: 79.93 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 21.17
 iteration  1033000/10000000 | consumed samples:    132224000 | elapsed time per iteration (ms): 250.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.667982E+00 | sop loss: 5.510466E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.26 | backward-compute: 79.84 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 15.96
 iteration  1034000/10000000 | consumed samples:    132352000 | elapsed time per iteration (ms): 247.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.666564E+00 | sop loss: 5.369855E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.08 | backward-compute: 79.83 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 19.22
 iteration  1035000/10000000 | consumed samples:    132480000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.670949E+00 | sop loss: 5.486615E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.01 | backward-compute: 79.79 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 17.78
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1035000 | lm loss value: 1.694418E+00 | lm loss PPL: 5.443475E+00 | sop loss value: 6.974620E-02 | sop loss PPL: 1.072236E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1036000/10000000 | consumed samples:    132608000 | elapsed time per iteration (ms): 251.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.666376E+00 | sop loss: 5.456078E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.24 | backward-compute: 79.81 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 20.13
 iteration  1037000/10000000 | consumed samples:    132736000 | elapsed time per iteration (ms): 246.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.669961E+00 | sop loss: 5.446817E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.50 | backward-compute: 79.85 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 15.04
 iteration  1038000/10000000 | consumed samples:    132864000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.669277E+00 | sop loss: 5.449406E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.38 | backward-compute: 79.87 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 17.87
 iteration  1039000/10000000 | consumed samples:    132992000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.665168E+00 | sop loss: 5.444925E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.69 | backward-compute: 79.82 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 13.86
 iteration  1040000/10000000 | consumed samples:    133120000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.668271E+00 | sop loss: 5.435334E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.94 | backward-compute: 79.82 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 19.82
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1040000 | lm loss value: 1.705156E+00 | lm loss PPL: 5.502245E+00 | sop loss value: 4.724756E-02 | sop loss PPL: 1.048382E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1041000/10000000 | consumed samples:    133248000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.665986E+00 | sop loss: 5.511830E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.74 | backward-compute: 79.83 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 18.05
 iteration  1042000/10000000 | consumed samples:    133376000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.669454E+00 | sop loss: 5.559652E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.33 | backward-compute: 79.84 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 16.76
 iteration  1043000/10000000 | consumed samples:    133504000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.662666E+00 | sop loss: 5.593061E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.18 | backward-compute: 79.85 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 16.08
 iteration  1044000/10000000 | consumed samples:    133632000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.666805E+00 | sop loss: 5.525960E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.63 | backward-compute: 79.85 | backward-params-all-reduce: 14.54 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.26 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.69 | batch-generator: 17.22
 iteration  1045000/10000000 | consumed samples:    133760000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.667157E+00 | sop loss: 5.434866E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.15 | backward-compute: 79.89 | backward-params-all-reduce: 14.59 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.31 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.78 | batch-generator: 14.41
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1045000 | lm loss value: 1.705345E+00 | lm loss PPL: 5.503286E+00 | sop loss value: 6.339070E-02 | sop loss PPL: 1.065443E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1046000/10000000 | consumed samples:    133888000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.665267E+00 | sop loss: 5.542018E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.79 | backward-compute: 79.80 | backward-params-all-reduce: 14.27 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 15.58
 iteration  1047000/10000000 | consumed samples:    134016000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.665466E+00 | sop loss: 5.536152E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.56 | backward-compute: 79.78 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 14.86
 iteration  1048000/10000000 | consumed samples:    134144000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.668369E+00 | sop loss: 5.525219E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.02 | backward-compute: 79.82 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 14.32
 iteration  1049000/10000000 | consumed samples:    134272000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.663496E+00 | sop loss: 5.524468E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.73 | backward-compute: 79.85 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 18.02
 iteration  1050000/10000000 | consumed samples:    134400000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.665083E+00 | sop loss: 5.559342E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.09 | backward-compute: 79.82 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 15.14
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1050000 | lm loss value: 1.729409E+00 | lm loss PPL: 5.637324E+00 | sop loss value: 7.752591E-02 | sop loss PPL: 1.080610E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 1050000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 1050000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2309.10
 iteration  1051000/10000000 | consumed samples:    134528000 | elapsed time per iteration (ms): 254.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.669064E+00 | sop loss: 5.528647E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.82 | backward-compute: 79.77 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 14.70
 iteration  1052000/10000000 | consumed samples:    134656000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.665227E+00 | sop loss: 5.397323E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.97 | backward-compute: 79.77 | backward-params-all-reduce: 14.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.55 | batch-generator: 14.32
 iteration  1053000/10000000 | consumed samples:    134784000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.669346E+00 | sop loss: 5.497757E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.38 | backward-compute: 79.92 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.53 | batch-generator: 16.25
 iteration  1054000/10000000 | consumed samples:    134912000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.667831E+00 | sop loss: 5.411451E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.95 | backward-compute: 79.81 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 18.72
 iteration  1055000/10000000 | consumed samples:    135040000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.666434E+00 | sop loss: 5.482389E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.72 | backward-compute: 79.82 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 14.89
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1055000 | lm loss value: 1.708873E+00 | lm loss PPL: 5.522732E+00 | sop loss value: 6.854627E-02 | sop loss PPL: 1.070950E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1056000/10000000 | consumed samples:    135168000 | elapsed time per iteration (ms): 251.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.666133E+00 | sop loss: 5.586288E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.88 | backward-compute: 79.91 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 20.12
 iteration  1057000/10000000 | consumed samples:    135296000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.663761E+00 | sop loss: 5.466345E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.78 | backward-compute: 79.81 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.06
 iteration  1058000/10000000 | consumed samples:    135424000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.666674E+00 | sop loss: 5.541032E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.44 | backward-compute: 79.76 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.53 | batch-generator: 17.94
 iteration  1059000/10000000 | consumed samples:    135552000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.669807E+00 | sop loss: 5.652091E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.27 | backward-compute: 79.79 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 23.08
 iteration  1060000/10000000 | consumed samples:    135680000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.662770E+00 | sop loss: 5.529220E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.38 | backward-compute: 79.88 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 15.74
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1060000 | lm loss value: 1.728091E+00 | lm loss PPL: 5.629896E+00 | sop loss value: 6.011390E-02 | sop loss PPL: 1.061957E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1061000/10000000 | consumed samples:    135808000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.666029E+00 | sop loss: 5.588010E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.50 | backward-compute: 79.86 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 16.22
 iteration  1062000/10000000 | consumed samples:    135936000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.667113E+00 | sop loss: 5.623911E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.55 | backward-compute: 79.78 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 17.20
 iteration  1063000/10000000 | consumed samples:    136064000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.666898E+00 | sop loss: 5.517781E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.48 | backward-compute: 79.79 | backward-params-all-reduce: 14.38 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.61 | batch-generator: 16.68
 iteration  1064000/10000000 | consumed samples:    136192000 | elapsed time per iteration (ms): 250.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.662262E+00 | sop loss: 5.519826E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.72 | backward-compute: 79.79 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 15.30
 iteration  1065000/10000000 | consumed samples:    136320000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.666492E+00 | sop loss: 5.554855E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.60 | backward-compute: 79.78 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 12.61
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1065000 | lm loss value: 1.729376E+00 | lm loss PPL: 5.637136E+00 | sop loss value: 7.299722E-02 | sop loss PPL: 1.075728E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1066000/10000000 | consumed samples:    136448000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.665400E+00 | sop loss: 5.430545E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.13 | backward-compute: 79.95 | backward-params-all-reduce: 13.92 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 15.39
 iteration  1067000/10000000 | consumed samples:    136576000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.667354E+00 | sop loss: 5.486445E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.17 | backward-compute: 79.84 | backward-params-all-reduce: 13.90 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 13.21
 iteration  1068000/10000000 | consumed samples:    136704000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.667149E+00 | sop loss: 5.386757E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.00 | backward-compute: 79.82 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 18.01
 iteration  1069000/10000000 | consumed samples:    136832000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.665824E+00 | sop loss: 5.566928E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.82 | backward-compute: 79.80 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 17.20
 iteration  1070000/10000000 | consumed samples:    136960000 | elapsed time per iteration (ms): 247.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.666888E+00 | sop loss: 5.508908E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.39 | backward-compute: 79.82 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 18.98
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1070000 | lm loss value: 1.711136E+00 | lm loss PPL: 5.535245E+00 | sop loss value: 7.345653E-02 | sop loss PPL: 1.076222E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1071000/10000000 | consumed samples:    137088000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.667088E+00 | sop loss: 5.553513E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.37 | backward-compute: 79.85 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 18.83
 iteration  1072000/10000000 | consumed samples:    137216000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.664344E+00 | sop loss: 5.426116E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.80 | backward-compute: 79.89 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 14.12
 iteration  1073000/10000000 | consumed samples:    137344000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.665880E+00 | sop loss: 5.388845E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.74 | backward-compute: 79.81 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.42 | batch-generator: 15.23
 iteration  1074000/10000000 | consumed samples:    137472000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.666350E+00 | sop loss: 5.441158E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.19 | backward-compute: 79.83 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 13.75
 iteration  1075000/10000000 | consumed samples:    137600000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.665573E+00 | sop loss: 5.504248E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.46 | backward-compute: 79.76 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 16.31
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1075000 | lm loss value: 1.690064E+00 | lm loss PPL: 5.419829E+00 | sop loss value: 7.045424E-02 | sop loss PPL: 1.072995E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1076000/10000000 | consumed samples:    137728000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.667892E+00 | sop loss: 5.514331E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.72 | backward-compute: 79.78 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 19.58
 iteration  1077000/10000000 | consumed samples:    137856000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.667841E+00 | sop loss: 5.373746E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.97 | backward-compute: 79.80 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.50 | batch-generator: 15.11
 iteration  1078000/10000000 | consumed samples:    137984000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.666424E+00 | sop loss: 5.501808E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.06 | backward-compute: 79.93 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.57 | batch-generator: 20.26
 iteration  1079000/10000000 | consumed samples:    138112000 | elapsed time per iteration (ms): 251.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.662500E+00 | sop loss: 5.466710E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.01 | backward-compute: 79.80 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 15.08
 iteration  1080000/10000000 | consumed samples:    138240000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.665708E+00 | sop loss: 5.407965E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.19 | backward-compute: 79.79 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 13.35
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1080000 | lm loss value: 1.715072E+00 | lm loss PPL: 5.557074E+00 | sop loss value: 6.445336E-02 | sop loss PPL: 1.066576E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1081000/10000000 | consumed samples:    138368000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.664486E+00 | sop loss: 5.432426E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.60 | backward-compute: 79.83 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 16.58
 iteration  1082000/10000000 | consumed samples:    138496000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.663816E+00 | sop loss: 5.367212E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.19 | backward-compute: 79.82 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 13.50
 iteration  1083000/10000000 | consumed samples:    138624000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.661584E+00 | sop loss: 5.449769E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.10 | backward-compute: 79.85 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 17.72
 iteration  1084000/10000000 | consumed samples:    138752000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.665753E+00 | sop loss: 5.420188E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.60 | backward-compute: 79.83 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 16.43
 iteration  1085000/10000000 | consumed samples:    138880000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.662622E+00 | sop loss: 5.491895E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.45 | backward-compute: 79.79 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 15.33
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1085000 | lm loss value: 1.691209E+00 | lm loss PPL: 5.426037E+00 | sop loss value: 7.991345E-02 | sop loss PPL: 1.083193E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1086000/10000000 | consumed samples:    139008000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.664155E+00 | sop loss: 5.497801E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.51 | backward-compute: 79.77 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 21.87
 iteration  1087000/10000000 | consumed samples:    139136000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.664028E+00 | sop loss: 5.467306E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.50 | backward-compute: 79.88 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 17.67
 iteration  1088000/10000000 | consumed samples:    139264000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.665812E+00 | sop loss: 5.343302E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.80 | backward-compute: 79.82 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.36
 iteration  1089000/10000000 | consumed samples:    139392000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.663932E+00 | sop loss: 5.435821E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.39 | backward-compute: 79.88 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 19.82
 iteration  1090000/10000000 | consumed samples:    139520000 | elapsed time per iteration (ms): 249.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.666034E+00 | sop loss: 5.551722E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.25 | backward-compute: 79.79 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 15.64
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1090000 | lm loss value: 1.700996E+00 | lm loss PPL: 5.479402E+00 | sop loss value: 8.339180E-02 | sop loss PPL: 1.086968E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1091000/10000000 | consumed samples:    139648000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.663971E+00 | sop loss: 5.563926E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.78 | backward-compute: 79.85 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 16.72
 iteration  1092000/10000000 | consumed samples:    139776000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.666010E+00 | sop loss: 5.359759E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.62 | backward-compute: 79.86 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 13.18
 iteration  1093000/10000000 | consumed samples:    139904000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.663502E+00 | sop loss: 5.371667E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.54 | backward-compute: 79.81 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 13.91
 iteration  1094000/10000000 | consumed samples:    140032000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.666123E+00 | sop loss: 5.420124E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.18 | backward-compute: 79.81 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 16.27
 iteration  1095000/10000000 | consumed samples:    140160000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.665247E+00 | sop loss: 5.405020E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.68 | backward-compute: 79.81 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 14.90
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1095000 | lm loss value: 1.707327E+00 | lm loss PPL: 5.514201E+00 | sop loss value: 5.228901E-02 | sop loss PPL: 1.053680E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1096000/10000000 | consumed samples:    140288000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.662537E+00 | sop loss: 5.428446E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.15 | backward-compute: 79.83 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 16.81
 iteration  1097000/10000000 | consumed samples:    140416000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.664193E+00 | sop loss: 5.430441E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.95 | backward-compute: 79.78 | backward-params-all-reduce: 14.49 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.20 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.62 | batch-generator: 15.34
 iteration  1098000/10000000 | consumed samples:    140544000 | elapsed time per iteration (ms): 245.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.664461E+00 | sop loss: 5.412806E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.00 | backward-compute: 79.83 | backward-params-all-reduce: 14.40 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.19 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.62 | batch-generator: 15.23
 iteration  1099000/10000000 | consumed samples:    140672000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.661478E+00 | sop loss: 5.620990E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.41 | backward-compute: 79.84 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 13.17
 iteration  1100000/10000000 | consumed samples:    140800000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.662592E+00 | sop loss: 5.341193E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.61 | backward-compute: 79.82 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 18.50
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1100000 | lm loss value: 1.710170E+00 | lm loss PPL: 5.529902E+00 | sop loss value: 6.513512E-02 | sop loss PPL: 1.067303E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 1100000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 1100000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2332.05
 iteration  1101000/10000000 | consumed samples:    140928000 | elapsed time per iteration (ms): 252.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.662434E+00 | sop loss: 5.391599E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.25 | backward-compute: 79.79 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 21.87
 iteration  1102000/10000000 | consumed samples:    141056000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.664510E+00 | sop loss: 5.300367E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.81 | backward-compute: 79.83 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 16.28
 iteration  1103000/10000000 | consumed samples:    141184000 | elapsed time per iteration (ms): 246.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.665113E+00 | sop loss: 5.602713E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.97 | backward-compute: 79.78 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 14.93
 iteration  1104000/10000000 | consumed samples:    141312000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.663729E+00 | sop loss: 5.475686E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.23 | backward-compute: 79.82 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.56 | batch-generator: 24.36
 iteration  1105000/10000000 | consumed samples:    141440000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.664131E+00 | sop loss: 5.260188E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.37 | backward-compute: 79.76 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 14.90
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1105000 | lm loss value: 1.676289E+00 | lm loss PPL: 5.345682E+00 | sop loss value: 8.071457E-02 | sop loss PPL: 1.084061E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1106000/10000000 | consumed samples:    141568000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.665976E+00 | sop loss: 5.431666E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.51 | backward-compute: 79.81 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 15.30
 iteration  1107000/10000000 | consumed samples:    141696000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.666498E+00 | sop loss: 5.608544E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.54 | backward-compute: 79.77 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 16.32
 iteration  1108000/10000000 | consumed samples:    141824000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.661604E+00 | sop loss: 5.471739E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.64 | backward-compute: 79.77 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.82
 iteration  1109000/10000000 | consumed samples:    141952000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.661166E+00 | sop loss: 5.394525E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.05 | backward-compute: 79.77 | backward-params-all-reduce: 14.31 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 13.59
 iteration  1110000/10000000 | consumed samples:    142080000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.664657E+00 | sop loss: 5.332818E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.39 | backward-compute: 79.82 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 13.44
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1110000 | lm loss value: 1.694965E+00 | lm loss PPL: 5.446457E+00 | sop loss value: 5.985044E-02 | sop loss PPL: 1.061678E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1111000/10000000 | consumed samples:    142208000 | elapsed time per iteration (ms): 251.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.660371E+00 | sop loss: 5.523102E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.70 | backward-compute: 79.79 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.24 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 13.62
 iteration  1112000/10000000 | consumed samples:    142336000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.663002E+00 | sop loss: 5.527074E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.11 | backward-compute: 79.76 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 11.60
 iteration  1113000/10000000 | consumed samples:    142464000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.665252E+00 | sop loss: 5.394739E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.17 | backward-compute: 79.83 | backward-params-all-reduce: 14.35 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.21 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.66 | batch-generator: 15.98
 iteration  1114000/10000000 | consumed samples:    142592000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.663509E+00 | sop loss: 5.408351E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.41 | backward-compute: 79.83 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 16.59
 iteration  1115000/10000000 | consumed samples:    142720000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.662993E+00 | sop loss: 5.567327E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.51 | backward-compute: 79.80 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 18.28
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1115000 | lm loss value: 1.691010E+00 | lm loss PPL: 5.424959E+00 | sop loss value: 6.476098E-02 | sop loss PPL: 1.066904E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1116000/10000000 | consumed samples:    142848000 | elapsed time per iteration (ms): 253.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.662154E+00 | sop loss: 5.380217E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.34 | backward-compute: 79.77 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 15.89
 iteration  1117000/10000000 | consumed samples:    142976000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.663148E+00 | sop loss: 5.558110E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.04 | backward-compute: 79.78 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 16.18
 iteration  1118000/10000000 | consumed samples:    143104000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.660875E+00 | sop loss: 5.443739E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.18 | backward-compute: 79.80 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 12.23
 iteration  1119000/10000000 | consumed samples:    143232000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.665248E+00 | sop loss: 5.426702E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.32 | backward-compute: 79.89 | backward-params-all-reduce: 14.89 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.87 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.44 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.94 | batch-generator: 13.67
 iteration  1120000/10000000 | consumed samples:    143360000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.664696E+00 | sop loss: 5.445413E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.60 | backward-compute: 79.84 | backward-params-all-reduce: 14.47 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.20 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.60 | batch-generator: 15.81
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1120000 | lm loss value: 1.691977E+00 | lm loss PPL: 5.430204E+00 | sop loss value: 6.097242E-02 | sop loss PPL: 1.062870E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1121000/10000000 | consumed samples:    143488000 | elapsed time per iteration (ms): 252.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.662114E+00 | sop loss: 5.361022E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.71 | backward-compute: 79.78 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 11.24
 iteration  1122000/10000000 | consumed samples:    143616000 | elapsed time per iteration (ms): 251.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.664669E+00 | sop loss: 5.437456E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.60 | backward-compute: 79.75 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 17.75
 iteration  1123000/10000000 | consumed samples:    143744000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.661321E+00 | sop loss: 5.409727E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.78 | backward-compute: 79.78 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.60
 iteration  1124000/10000000 | consumed samples:    143872000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.661397E+00 | sop loss: 5.312502E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.14 | backward-compute: 79.84 | backward-params-all-reduce: 14.43 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.20 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.64 | batch-generator: 14.17
 iteration  1125000/10000000 | consumed samples:    144000000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.659825E+00 | sop loss: 5.597746E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.00 | backward-compute: 79.83 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 16.61
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1125000 | lm loss value: 1.783265E+00 | lm loss PPL: 5.949252E+00 | sop loss value: 5.474054E-02 | sop loss PPL: 1.056267E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1126000/10000000 | consumed samples:    144128000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.664126E+00 | sop loss: 5.370550E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.67 | backward-compute: 79.85 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 16.76
 iteration  1127000/10000000 | consumed samples:    144256000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.660319E+00 | sop loss: 5.518774E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.98 | backward-compute: 79.86 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 18.06
 iteration  1128000/10000000 | consumed samples:    144384000 | elapsed time per iteration (ms): 249.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.661464E+00 | sop loss: 5.385011E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.28 | backward-compute: 79.76 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.47 | batch-generator: 17.02
 iteration  1129000/10000000 | consumed samples:    144512000 | elapsed time per iteration (ms): 250.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.661039E+00 | sop loss: 5.338911E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.99 | backward-compute: 79.77 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 18.41
 iteration  1130000/10000000 | consumed samples:    144640000 | elapsed time per iteration (ms): 246.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.661678E+00 | sop loss: 5.544108E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.71 | backward-compute: 79.75 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 16.87
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1130000 | lm loss value: 1.740909E+00 | lm loss PPL: 5.702526E+00 | sop loss value: 5.935928E-02 | sop loss PPL: 1.061156E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1131000/10000000 | consumed samples:    144768000 | elapsed time per iteration (ms): 250.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.661805E+00 | sop loss: 5.300580E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.36 | backward-compute: 79.84 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.47 | batch-generator: 17.56
 iteration  1132000/10000000 | consumed samples:    144896000 | elapsed time per iteration (ms): 250.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.658820E+00 | sop loss: 5.419957E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.55 | backward-compute: 79.83 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.90
 iteration  1133000/10000000 | consumed samples:    145024000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.663331E+00 | sop loss: 5.541755E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.34 | backward-compute: 79.82 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 13.97
 iteration  1134000/10000000 | consumed samples:    145152000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.657660E+00 | sop loss: 5.267012E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.01 | backward-compute: 79.81 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 17.91
 iteration  1135000/10000000 | consumed samples:    145280000 | elapsed time per iteration (ms): 246.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.660718E+00 | sop loss: 5.498235E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.69 | backward-compute: 79.80 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 16.32
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1135000 | lm loss value: 1.731322E+00 | lm loss PPL: 5.648115E+00 | sop loss value: 7.211535E-02 | sop loss PPL: 1.074779E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1136000/10000000 | consumed samples:    145408000 | elapsed time per iteration (ms): 250.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.662213E+00 | sop loss: 5.493264E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.62 | backward-compute: 79.81 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 14.40
 iteration  1137000/10000000 | consumed samples:    145536000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.661488E+00 | sop loss: 5.318834E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.02 | backward-compute: 79.82 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 12.69
 iteration  1138000/10000000 | consumed samples:    145664000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.662445E+00 | sop loss: 5.445079E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.92 | backward-compute: 79.82 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 12.58
 iteration  1139000/10000000 | consumed samples:    145792000 | elapsed time per iteration (ms): 246.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.661611E+00 | sop loss: 5.550596E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.56 | backward-compute: 79.82 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.01
 iteration  1140000/10000000 | consumed samples:    145920000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.664090E+00 | sop loss: 5.360838E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.76 | backward-compute: 79.78 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.90
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1140000 | lm loss value: 1.680465E+00 | lm loss PPL: 5.368053E+00 | sop loss value: 5.610312E-02 | sop loss PPL: 1.057707E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1141000/10000000 | consumed samples:    146048000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.660523E+00 | sop loss: 5.417346E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.41 | backward-compute: 79.76 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.44 | batch-generator: 15.74
 iteration  1142000/10000000 | consumed samples:    146176000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.660423E+00 | sop loss: 5.413819E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.74 | backward-compute: 79.83 | backward-params-all-reduce: 13.91 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 15.57
 iteration  1143000/10000000 | consumed samples:    146304000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.663710E+00 | sop loss: 5.553116E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.11 | backward-compute: 79.79 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 14.33
 iteration  1144000/10000000 | consumed samples:    146432000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.660512E+00 | sop loss: 5.401320E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.10 | backward-compute: 79.84 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 14.80
 iteration  1145000/10000000 | consumed samples:    146560000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.661423E+00 | sop loss: 5.493287E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.57 | backward-compute: 79.77 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.32
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1145000 | lm loss value: 1.678046E+00 | lm loss PPL: 5.355079E+00 | sop loss value: 6.131729E-02 | sop loss PPL: 1.063236E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1146000/10000000 | consumed samples:    146688000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.660118E+00 | sop loss: 5.514664E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.28 | backward-compute: 79.77 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.53 | batch-generator: 15.09
 iteration  1147000/10000000 | consumed samples:    146816000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.659759E+00 | sop loss: 5.355192E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.48 | backward-compute: 79.83 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 20.05
 iteration  1148000/10000000 | consumed samples:    146944000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.663757E+00 | sop loss: 5.456004E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.82 | backward-compute: 79.80 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 23.95
 iteration  1149000/10000000 | consumed samples:    147072000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.659887E+00 | sop loss: 5.296380E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.61 | backward-compute: 79.81 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 19.09
 iteration  1150000/10000000 | consumed samples:    147200000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.657653E+00 | sop loss: 5.339937E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.08 | backward-compute: 79.84 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 13.92
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1150000 | lm loss value: 1.702512E+00 | lm loss PPL: 5.487717E+00 | sop loss value: 7.071463E-02 | sop loss PPL: 1.073275E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 1150000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 1150000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2335.16
 iteration  1151000/10000000 | consumed samples:    147328000 | elapsed time per iteration (ms): 251.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.661813E+00 | sop loss: 5.508497E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.12 | backward-compute: 79.83 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 14.65
 iteration  1152000/10000000 | consumed samples:    147456000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.665708E+00 | sop loss: 5.325348E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.87 | backward-compute: 79.79 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 16.08
 iteration  1153000/10000000 | consumed samples:    147584000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.657925E+00 | sop loss: 5.505287E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.70 | backward-compute: 79.79 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 16.84
 iteration  1154000/10000000 | consumed samples:    147712000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.660681E+00 | sop loss: 5.310251E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.21 | backward-compute: 79.79 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 15.90
 iteration  1155000/10000000 | consumed samples:    147840000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.661631E+00 | sop loss: 5.370034E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.32 | backward-compute: 79.78 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 13.77
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1155000 | lm loss value: 1.703913E+00 | lm loss PPL: 5.495411E+00 | sop loss value: 6.369480E-02 | sop loss PPL: 1.065767E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1156000/10000000 | consumed samples:    147968000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.660399E+00 | sop loss: 5.500809E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.89 | backward-compute: 79.77 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 13.77
 iteration  1157000/10000000 | consumed samples:    148096000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.660747E+00 | sop loss: 5.394381E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.28 | backward-compute: 79.82 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 17.61
 iteration  1158000/10000000 | consumed samples:    148224000 | elapsed time per iteration (ms): 249.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656293E+00 | sop loss: 5.515680E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.94 | backward-compute: 79.86 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 21.96
 iteration  1159000/10000000 | consumed samples:    148352000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656094E+00 | sop loss: 5.435727E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.98 | backward-compute: 79.88 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 16.19
 iteration  1160000/10000000 | consumed samples:    148480000 | elapsed time per iteration (ms): 250.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.662316E+00 | sop loss: 5.408186E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.09 | backward-compute: 79.83 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 19.26
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1160000 | lm loss value: 1.686071E+00 | lm loss PPL: 5.398230E+00 | sop loss value: 5.782866E-02 | sop loss PPL: 1.059533E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1161000/10000000 | consumed samples:    148608000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.658788E+00 | sop loss: 5.397724E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.92 | backward-compute: 79.81 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.33
 iteration  1162000/10000000 | consumed samples:    148736000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.660218E+00 | sop loss: 5.494339E-02 | loss scale: 8192.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.99 | backward-compute: 79.79 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 17.60
 iteration  1163000/10000000 | consumed samples:    148864000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.661692E+00 | sop loss: 5.367153E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.99 | backward-compute: 79.79 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 16.77
 iteration  1164000/10000000 | consumed samples:    148992000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.658104E+00 | sop loss: 5.345392E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.29 | backward-compute: 79.85 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 13.05
 iteration  1165000/10000000 | consumed samples:    149120000 | elapsed time per iteration (ms): 246.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.658102E+00 | sop loss: 5.313501E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.53 | backward-compute: 79.88 | backward-params-all-reduce: 14.35 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.59 | batch-generator: 14.67
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1165000 | lm loss value: 1.686511E+00 | lm loss PPL: 5.400607E+00 | sop loss value: 8.105677E-02 | sop loss PPL: 1.084432E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1166000/10000000 | consumed samples:    149248000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.661575E+00 | sop loss: 5.407189E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.89 | backward-compute: 79.82 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 14.27
 iteration  1167000/10000000 | consumed samples:    149376000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.660518E+00 | sop loss: 5.434602E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.24 | backward-compute: 79.88 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 20.56
 iteration  1168000/10000000 | consumed samples:    149504000 | elapsed time per iteration (ms): 250.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.658338E+00 | sop loss: 5.350462E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.04 | backward-compute: 79.82 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 19.33
 iteration  1169000/10000000 | consumed samples:    149632000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.661355E+00 | sop loss: 5.331611E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.82 | backward-compute: 79.77 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 18.11
 iteration  1170000/10000000 | consumed samples:    149760000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.661139E+00 | sop loss: 5.469175E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.58 | backward-compute: 79.78 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.56 | batch-generator: 18.02
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1170000 | lm loss value: 1.712605E+00 | lm loss PPL: 5.543381E+00 | sop loss value: 6.565082E-02 | sop loss PPL: 1.067854E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1171000/10000000 | consumed samples:    149888000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.660998E+00 | sop loss: 5.462895E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.09 | backward-compute: 79.76 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 15.03
 iteration  1172000/10000000 | consumed samples:    150016000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.658160E+00 | sop loss: 5.261886E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.02 | backward-compute: 79.75 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 17.00
 iteration  1173000/10000000 | consumed samples:    150144000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654603E+00 | sop loss: 5.344798E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.42 | backward-compute: 79.67 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.76 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 16.45
 iteration  1174000/10000000 | consumed samples:    150272000 | elapsed time per iteration (ms): 246.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.657533E+00 | sop loss: 5.415089E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.21 | backward-compute: 79.68 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.24 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 14.04
 iteration  1175000/10000000 | consumed samples:    150400000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.661628E+00 | sop loss: 5.496349E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.96 | backward-compute: 79.74 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 16.11
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1175000 | lm loss value: 1.744921E+00 | lm loss PPL: 5.725449E+00 | sop loss value: 7.375637E-02 | sop loss PPL: 1.076544E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1176000/10000000 | consumed samples:    150528000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.660125E+00 | sop loss: 5.471824E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.18 | backward-compute: 79.74 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 15.21
 iteration  1177000/10000000 | consumed samples:    150656000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656749E+00 | sop loss: 5.456601E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.85 | backward-compute: 79.77 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 26.52
 iteration  1178000/10000000 | consumed samples:    150784000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.661342E+00 | sop loss: 5.397316E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.85 | backward-compute: 79.77 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 21.00
 iteration  1179000/10000000 | consumed samples:    150912000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.661129E+00 | sop loss: 5.372116E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.27 | backward-compute: 79.80 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 27.83
 iteration  1180000/10000000 | consumed samples:    151040000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.659647E+00 | sop loss: 5.407504E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.60 | backward-compute: 79.81 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 31.00
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1180000 | lm loss value: 1.713261E+00 | lm loss PPL: 5.547019E+00 | sop loss value: 6.443286E-02 | sop loss PPL: 1.066554E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1181000/10000000 | consumed samples:    151168000 | elapsed time per iteration (ms): 250.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.660805E+00 | sop loss: 5.520948E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.18 | backward-compute: 79.82 | backward-params-all-reduce: 14.43 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.21 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.64 | batch-generator: 16.48
 iteration  1182000/10000000 | consumed samples:    151296000 | elapsed time per iteration (ms): 246.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.659176E+00 | sop loss: 5.241353E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.93 | backward-compute: 79.87 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 14.03
 iteration  1183000/10000000 | consumed samples:    151424000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.661092E+00 | sop loss: 5.443902E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.94 | backward-compute: 79.88 | backward-params-all-reduce: 14.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.24 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.67 | batch-generator: 14.83
 iteration  1184000/10000000 | consumed samples:    151552000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.658486E+00 | sop loss: 5.427593E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.42 | backward-compute: 79.78 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 14.06
 iteration  1185000/10000000 | consumed samples:    151680000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.659632E+00 | sop loss: 5.436270E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.76 | backward-compute: 79.78 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 17.53
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1185000 | lm loss value: 1.723987E+00 | lm loss PPL: 5.606841E+00 | sop loss value: 5.400068E-02 | sop loss PPL: 1.055485E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1186000/10000000 | consumed samples:    151808000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.659724E+00 | sop loss: 5.513057E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.40 | backward-compute: 79.80 | backward-params-all-reduce: 14.43 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.55 | batch-generator: 17.36
 iteration  1187000/10000000 | consumed samples:    151936000 | elapsed time per iteration (ms): 245.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.658658E+00 | sop loss: 5.506444E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 131.41 | backward-compute: 79.94 | backward-params-all-reduce: 14.79 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.89 | optimizer-unscale-and-check-inf: 2.31 | optimizer-clip-main-grad: 4.41 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.95 | batch-generator: 16.81
 iteration  1188000/10000000 | consumed samples:    152064000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.659171E+00 | sop loss: 5.295594E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.83 | backward-compute: 79.79 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.19 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.63 | batch-generator: 15.51
 iteration  1189000/10000000 | consumed samples:    152192000 | elapsed time per iteration (ms): 246.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.657081E+00 | sop loss: 5.424061E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.22 | backward-compute: 79.81 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 15.78
 iteration  1190000/10000000 | consumed samples:    152320000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.660790E+00 | sop loss: 5.469492E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.92 | backward-compute: 79.79 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 14.81
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1190000 | lm loss value: 1.701389E+00 | lm loss PPL: 5.481557E+00 | sop loss value: 6.746112E-02 | sop loss PPL: 1.069789E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1191000/10000000 | consumed samples:    152448000 | elapsed time per iteration (ms): 250.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.662358E+00 | sop loss: 5.352624E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.28 | backward-compute: 79.84 | backward-params-all-reduce: 13.92 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 14.75
 iteration  1192000/10000000 | consumed samples:    152576000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.659291E+00 | sop loss: 5.349191E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.62 | backward-compute: 79.83 | backward-params-all-reduce: 14.44 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.21 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.66 | batch-generator: 15.71
 iteration  1193000/10000000 | consumed samples:    152704000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.658261E+00 | sop loss: 5.454254E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.14 | backward-compute: 79.82 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 12.78
 iteration  1194000/10000000 | consumed samples:    152832000 | elapsed time per iteration (ms): 246.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656050E+00 | sop loss: 5.484968E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.66 | backward-compute: 79.82 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.42 | batch-generator: 15.83
 iteration  1195000/10000000 | consumed samples:    152960000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.658938E+00 | sop loss: 5.356971E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.59 | backward-compute: 79.83 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.03
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1195000 | lm loss value: 1.706747E+00 | lm loss PPL: 5.511007E+00 | sop loss value: 7.432622E-02 | sop loss PPL: 1.077158E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1196000/10000000 | consumed samples:    153088000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.660966E+00 | sop loss: 5.500877E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.22 | backward-compute: 79.80 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 15.16
 iteration  1197000/10000000 | consumed samples:    153216000 | elapsed time per iteration (ms): 246.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656487E+00 | sop loss: 5.471366E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.40 | backward-compute: 79.81 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.50 | batch-generator: 14.12
 iteration  1198000/10000000 | consumed samples:    153344000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.659378E+00 | sop loss: 5.476321E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.06 | backward-compute: 79.81 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 16.40
 iteration  1199000/10000000 | consumed samples:    153472000 | elapsed time per iteration (ms): 246.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.658545E+00 | sop loss: 5.456193E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.33 | backward-compute: 79.80 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 11.44
 iteration  1200000/10000000 | consumed samples:    153600000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656508E+00 | sop loss: 5.514296E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.30 | backward-compute: 79.80 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 14.21
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1200000 | lm loss value: 1.710439E+00 | lm loss PPL: 5.531388E+00 | sop loss value: 5.649232E-02 | sop loss PPL: 1.058118E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 1200000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 1200000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2334.95
 iteration  1201000/10000000 | consumed samples:    153728000 | elapsed time per iteration (ms): 250.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.658965E+00 | sop loss: 5.405500E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.01 | backward-compute: 79.84 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 17.10
 iteration  1202000/10000000 | consumed samples:    153856000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.660558E+00 | sop loss: 5.465371E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.15 | backward-compute: 79.86 | backward-params-all-reduce: 13.89 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 14.84
 iteration  1203000/10000000 | consumed samples:    153984000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.659251E+00 | sop loss: 5.353388E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.04 | backward-compute: 79.85 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 14.30
 iteration  1204000/10000000 | consumed samples:    154112000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656337E+00 | sop loss: 5.313495E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.83 | backward-compute: 79.79 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 14.53
 iteration  1205000/10000000 | consumed samples:    154240000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.657080E+00 | sop loss: 5.415953E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.18 | backward-compute: 79.86 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.60
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1205000 | lm loss value: 1.716974E+00 | lm loss PPL: 5.567656E+00 | sop loss value: 5.121893E-02 | sop loss PPL: 1.052553E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1206000/10000000 | consumed samples:    154368000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655870E+00 | sop loss: 5.360006E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.45 | backward-compute: 79.80 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 16.33
 iteration  1207000/10000000 | consumed samples:    154496000 | elapsed time per iteration (ms): 246.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654962E+00 | sop loss: 5.490770E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.37 | backward-compute: 79.83 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 16.10
 iteration  1208000/10000000 | consumed samples:    154624000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656461E+00 | sop loss: 5.434469E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.92 | backward-compute: 79.82 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 16.97
 iteration  1209000/10000000 | consumed samples:    154752000 | elapsed time per iteration (ms): 246.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.657495E+00 | sop loss: 5.417908E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.86 | backward-compute: 79.85 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.90
 iteration  1210000/10000000 | consumed samples:    154880000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.658378E+00 | sop loss: 5.220879E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.65 | backward-compute: 79.83 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 11.79
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1210000 | lm loss value: 1.686911E+00 | lm loss PPL: 5.402763E+00 | sop loss value: 6.297362E-02 | sop loss PPL: 1.064999E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1211000/10000000 | consumed samples:    155008000 | elapsed time per iteration (ms): 251.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.657153E+00 | sop loss: 5.424389E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.66 | backward-compute: 79.80 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 17.38
 iteration  1212000/10000000 | consumed samples:    155136000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.659594E+00 | sop loss: 5.412334E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.63 | backward-compute: 79.77 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 22.50
 iteration  1213000/10000000 | consumed samples:    155264000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.657397E+00 | sop loss: 5.405570E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.28 | backward-compute: 79.82 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 13.52
 iteration  1214000/10000000 | consumed samples:    155392000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.658610E+00 | sop loss: 5.427876E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.06 | backward-compute: 79.86 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 15.91
 iteration  1215000/10000000 | consumed samples:    155520000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.657770E+00 | sop loss: 5.372467E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.95 | backward-compute: 79.86 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.55 | batch-generator: 17.94
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1215000 | lm loss value: 1.673686E+00 | lm loss PPL: 5.331787E+00 | sop loss value: 5.505276E-02 | sop loss PPL: 1.056596E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1216000/10000000 | consumed samples:    155648000 | elapsed time per iteration (ms): 251.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.658499E+00 | sop loss: 5.403251E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.10 | backward-compute: 79.78 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 12.94
 iteration  1217000/10000000 | consumed samples:    155776000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.657217E+00 | sop loss: 5.413739E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.61 | backward-compute: 79.81 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 15.86
 iteration  1218000/10000000 | consumed samples:    155904000 | elapsed time per iteration (ms): 246.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.658530E+00 | sop loss: 5.440393E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.67 | backward-compute: 79.77 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 14.77
 iteration  1219000/10000000 | consumed samples:    156032000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656901E+00 | sop loss: 5.474638E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.61 | backward-compute: 79.92 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 16.75
 iteration  1220000/10000000 | consumed samples:    156160000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.658735E+00 | sop loss: 5.406491E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.81 | backward-compute: 79.87 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 15.97
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1220000 | lm loss value: 1.746195E+00 | lm loss PPL: 5.732746E+00 | sop loss value: 6.782066E-02 | sop loss PPL: 1.070173E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1221000/10000000 | consumed samples:    156288000 | elapsed time per iteration (ms): 249.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655349E+00 | sop loss: 5.294146E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.06 | backward-compute: 79.79 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 18.33
 iteration  1222000/10000000 | consumed samples:    156416000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656220E+00 | sop loss: 5.383082E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.87 | backward-compute: 79.77 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 17.86
 iteration  1223000/10000000 | consumed samples:    156544000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.659453E+00 | sop loss: 5.426242E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.47 | backward-compute: 79.74 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 16.58
 iteration  1224000/10000000 | consumed samples:    156672000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656581E+00 | sop loss: 5.332513E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.70 | backward-compute: 79.79 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.05
 iteration  1225000/10000000 | consumed samples:    156800000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.659710E+00 | sop loss: 5.493179E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.43 | backward-compute: 79.83 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 18.58
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1225000 | lm loss value: 1.712773E+00 | lm loss PPL: 5.544316E+00 | sop loss value: 5.920160E-02 | sop loss PPL: 1.060989E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1226000/10000000 | consumed samples:    156928000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.658050E+00 | sop loss: 5.469909E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.33 | backward-compute: 79.87 | backward-params-all-reduce: 14.37 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.24 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.68 | batch-generator: 18.42
 iteration  1227000/10000000 | consumed samples:    157056000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.659127E+00 | sop loss: 5.471822E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.25 | backward-compute: 79.85 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 14.53
 iteration  1228000/10000000 | consumed samples:    157184000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.658581E+00 | sop loss: 5.499571E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.96 | backward-compute: 79.80 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 16.47
 iteration  1229000/10000000 | consumed samples:    157312000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.657392E+00 | sop loss: 5.459675E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.38 | backward-compute: 79.82 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.54 | batch-generator: 15.49
 iteration  1230000/10000000 | consumed samples:    157440000 | elapsed time per iteration (ms): 249.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655251E+00 | sop loss: 5.355435E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.37 | backward-compute: 79.77 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 16.51
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1230000 | lm loss value: 1.669082E+00 | lm loss PPL: 5.307293E+00 | sop loss value: 8.178423E-02 | sop loss PPL: 1.085222E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1231000/10000000 | consumed samples:    157568000 | elapsed time per iteration (ms): 251.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.657644E+00 | sop loss: 5.421723E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.42 | backward-compute: 79.74 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 19.11
 iteration  1232000/10000000 | consumed samples:    157696000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.660338E+00 | sop loss: 5.380720E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.37 | backward-compute: 79.91 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 12.31
 iteration  1233000/10000000 | consumed samples:    157824000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.660661E+00 | sop loss: 5.437029E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.46 | backward-compute: 79.97 | backward-params-all-reduce: 13.91 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 14.64
 iteration  1234000/10000000 | consumed samples:    157952000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655882E+00 | sop loss: 5.501779E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.06 | backward-compute: 79.80 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 22.20
 iteration  1235000/10000000 | consumed samples:    158080000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.660545E+00 | sop loss: 5.455487E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.88 | backward-compute: 79.82 | backward-params-all-reduce: 14.34 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.55 | batch-generator: 14.93
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1235000 | lm loss value: 1.677745E+00 | lm loss PPL: 5.353468E+00 | sop loss value: 5.411705E-02 | sop loss PPL: 1.055608E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1236000/10000000 | consumed samples:    158208000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655953E+00 | sop loss: 5.350468E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.37 | backward-compute: 79.91 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 15.01
 iteration  1237000/10000000 | consumed samples:    158336000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655074E+00 | sop loss: 5.355610E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.19 | backward-compute: 79.82 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.36
 iteration  1238000/10000000 | consumed samples:    158464000 | elapsed time per iteration (ms): 246.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655274E+00 | sop loss: 5.358377E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.60 | backward-compute: 79.83 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 15.85
 iteration  1239000/10000000 | consumed samples:    158592000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656292E+00 | sop loss: 5.475226E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.66 | backward-compute: 79.82 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 17.90
 iteration  1240000/10000000 | consumed samples:    158720000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656565E+00 | sop loss: 5.375059E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.43 | backward-compute: 79.83 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.60
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1240000 | lm loss value: 1.724158E+00 | lm loss PPL: 5.607799E+00 | sop loss value: 7.582761E-02 | sop loss PPL: 1.078777E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1241000/10000000 | consumed samples:    158848000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.652492E+00 | sop loss: 5.464684E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.30 | backward-compute: 79.79 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 15.17
 iteration  1242000/10000000 | consumed samples:    158976000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.658646E+00 | sop loss: 5.329855E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.46 | backward-compute: 79.84 | backward-params-all-reduce: 14.64 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.31 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.79 | batch-generator: 17.20
 iteration  1243000/10000000 | consumed samples:    159104000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655907E+00 | sop loss: 5.275036E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.27 | backward-compute: 79.85 | backward-params-all-reduce: 14.29 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.19 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.61 | batch-generator: 17.02
 iteration  1244000/10000000 | consumed samples:    159232000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.653708E+00 | sop loss: 5.444040E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.24 | backward-compute: 79.81 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 16.18
 iteration  1245000/10000000 | consumed samples:    159360000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655333E+00 | sop loss: 5.377934E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.58 | backward-compute: 79.78 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 15.27
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1245000 | lm loss value: 1.702314E+00 | lm loss PPL: 5.486630E+00 | sop loss value: 7.091033E-02 | sop loss PPL: 1.073485E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1246000/10000000 | consumed samples:    159488000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656364E+00 | sop loss: 5.296263E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.64 | backward-compute: 79.85 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.56 | batch-generator: 16.77
 iteration  1247000/10000000 | consumed samples:    159616000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.658744E+00 | sop loss: 5.325874E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.88 | backward-compute: 79.84 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 13.71
 iteration  1248000/10000000 | consumed samples:    159744000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655544E+00 | sop loss: 5.356633E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.72 | backward-compute: 79.85 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 12.93
 iteration  1249000/10000000 | consumed samples:    159872000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655672E+00 | sop loss: 5.359493E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.24 | backward-compute: 79.79 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 13.63
 iteration  1250000/10000000 | consumed samples:    160000000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656974E+00 | sop loss: 5.372538E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.99 | backward-compute: 79.83 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 12.48
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1250000 | lm loss value: 1.704362E+00 | lm loss PPL: 5.497878E+00 | sop loss value: 6.389822E-02 | sop loss PPL: 1.065984E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 1250000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 1250000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2333.52
 iteration  1251000/10000000 | consumed samples:    160128000 | elapsed time per iteration (ms): 252.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656635E+00 | sop loss: 5.505691E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.20 | backward-compute: 79.83 | backward-params-all-reduce: 14.38 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.52 | batch-generator: 16.25
 iteration  1252000/10000000 | consumed samples:    160256000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656321E+00 | sop loss: 5.351433E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.53 | backward-compute: 79.83 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 16.42
 iteration  1253000/10000000 | consumed samples:    160384000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.653822E+00 | sop loss: 5.401556E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.37 | backward-compute: 79.84 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.01
 iteration  1254000/10000000 | consumed samples:    160512000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655334E+00 | sop loss: 5.368372E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.75 | backward-compute: 79.85 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 13.57
 iteration  1255000/10000000 | consumed samples:    160640000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654153E+00 | sop loss: 5.441308E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.96 | backward-compute: 79.82 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 14.92
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1255000 | lm loss value: 1.674446E+00 | lm loss PPL: 5.335837E+00 | sop loss value: 4.760809E-02 | sop loss PPL: 1.048760E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1256000/10000000 | consumed samples:    160768000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.659629E+00 | sop loss: 5.423496E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.11 | backward-compute: 79.82 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 18.35
 iteration  1257000/10000000 | consumed samples:    160896000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655736E+00 | sop loss: 5.523271E-02 | loss scale: 8192.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.22 | backward-compute: 79.87 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 15.68
 iteration  1258000/10000000 | consumed samples:    161024000 | elapsed time per iteration (ms): 246.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654712E+00 | sop loss: 5.379316E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.55 | backward-compute: 79.82 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 19.91
 iteration  1259000/10000000 | consumed samples:    161152000 | elapsed time per iteration (ms): 246.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656967E+00 | sop loss: 5.340536E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.40 | backward-compute: 79.81 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 16.01
 iteration  1260000/10000000 | consumed samples:    161280000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654031E+00 | sop loss: 5.460253E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.76 | backward-compute: 79.81 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 15.02
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1260000 | lm loss value: 1.756415E+00 | lm loss PPL: 5.791639E+00 | sop loss value: 5.585164E-02 | sop loss PPL: 1.057441E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1261000/10000000 | consumed samples:    161408000 | elapsed time per iteration (ms): 250.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656451E+00 | sop loss: 5.371301E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.81 | backward-compute: 79.85 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 20.87
 iteration  1262000/10000000 | consumed samples:    161536000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654964E+00 | sop loss: 5.420290E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.21 | backward-compute: 79.85 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 17.32
 iteration  1263000/10000000 | consumed samples:    161664000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.658768E+00 | sop loss: 5.553116E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.47 | backward-compute: 79.81 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 15.76
 iteration  1264000/10000000 | consumed samples:    161792000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.657571E+00 | sop loss: 5.415271E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.62 | backward-compute: 79.80 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 15.69
 iteration  1265000/10000000 | consumed samples:    161920000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656865E+00 | sop loss: 5.468192E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.05 | backward-compute: 79.80 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.43 | batch-generator: 17.80
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1265000 | lm loss value: 1.694677E+00 | lm loss PPL: 5.444888E+00 | sop loss value: 7.071090E-02 | sop loss PPL: 1.073271E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1266000/10000000 | consumed samples:    162048000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655011E+00 | sop loss: 5.517694E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.37 | backward-compute: 79.84 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 13.67
 iteration  1267000/10000000 | consumed samples:    162176000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654028E+00 | sop loss: 5.303423E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.70 | backward-compute: 79.83 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 16.68
 iteration  1268000/10000000 | consumed samples:    162304000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654209E+00 | sop loss: 5.260065E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.28 | backward-compute: 79.82 | backward-params-all-reduce: 14.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.57 | batch-generator: 18.90
 iteration  1269000/10000000 | consumed samples:    162432000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.657229E+00 | sop loss: 5.340880E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.58 | backward-compute: 79.80 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 13.68
 iteration  1270000/10000000 | consumed samples:    162560000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.652646E+00 | sop loss: 5.365466E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.64 | backward-compute: 79.88 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 13.21
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1270000 | lm loss value: 1.733259E+00 | lm loss PPL: 5.659068E+00 | sop loss value: 7.068656E-02 | sop loss PPL: 1.073245E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1271000/10000000 | consumed samples:    162688000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.653975E+00 | sop loss: 5.374690E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.71 | backward-compute: 79.89 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 16.13
 iteration  1272000/10000000 | consumed samples:    162816000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.657173E+00 | sop loss: 5.313037E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.91 | backward-compute: 79.83 | backward-params-all-reduce: 14.61 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.33 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.81 | batch-generator: 14.98
 iteration  1273000/10000000 | consumed samples:    162944000 | elapsed time per iteration (ms): 247.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.657385E+00 | sop loss: 5.468430E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.26 | backward-compute: 79.81 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 17.35
 iteration  1274000/10000000 | consumed samples:    163072000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656185E+00 | sop loss: 5.381771E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.82 | backward-compute: 79.82 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 12.67
 iteration  1275000/10000000 | consumed samples:    163200000 | elapsed time per iteration (ms): 246.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654642E+00 | sop loss: 5.352318E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.03 | backward-compute: 79.89 | backward-params-all-reduce: 14.48 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.20 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.62 | batch-generator: 14.60
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1275000 | lm loss value: 1.736457E+00 | lm loss PPL: 5.677196E+00 | sop loss value: 6.414032E-02 | sop loss PPL: 1.066242E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1276000/10000000 | consumed samples:    163328000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655279E+00 | sop loss: 5.484317E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.40 | backward-compute: 79.81 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 18.03
 iteration  1277000/10000000 | consumed samples:    163456000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654965E+00 | sop loss: 5.536423E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.19 | backward-compute: 79.70 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 14.12
 iteration  1278000/10000000 | consumed samples:    163584000 | elapsed time per iteration (ms): 245.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.653390E+00 | sop loss: 5.469987E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.18 | backward-compute: 79.77 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 16.54
 iteration  1279000/10000000 | consumed samples:    163712000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656440E+00 | sop loss: 5.478428E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.52 | backward-compute: 79.78 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 18.21
 iteration  1280000/10000000 | consumed samples:    163840000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.651450E+00 | sop loss: 5.423328E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.10 | backward-compute: 79.84 | backward-params-all-reduce: 14.38 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.56 | batch-generator: 15.02
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1280000 | lm loss value: 1.704416E+00 | lm loss PPL: 5.498172E+00 | sop loss value: 6.432743E-02 | sop loss PPL: 1.066442E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1281000/10000000 | consumed samples:    163968000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656628E+00 | sop loss: 5.337708E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.34 | backward-compute: 79.93 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 14.04
 iteration  1282000/10000000 | consumed samples:    164096000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656217E+00 | sop loss: 5.329341E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.61 | backward-compute: 79.78 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.26
 iteration  1283000/10000000 | consumed samples:    164224000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654577E+00 | sop loss: 5.337472E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.76 | backward-compute: 79.75 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.56 | batch-generator: 15.82
 iteration  1284000/10000000 | consumed samples:    164352000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655701E+00 | sop loss: 5.339731E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.77 | backward-compute: 79.80 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 13.35
 iteration  1285000/10000000 | consumed samples:    164480000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654774E+00 | sop loss: 5.373289E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.42 | backward-compute: 79.84 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 14.30
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1285000 | lm loss value: 1.688245E+00 | lm loss PPL: 5.409978E+00 | sop loss value: 5.175603E-02 | sop loss PPL: 1.053119E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1286000/10000000 | consumed samples:    164608000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654153E+00 | sop loss: 5.278115E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.28 | backward-compute: 79.79 | backward-params-all-reduce: 14.46 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.22 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.65 | batch-generator: 15.83
 iteration  1287000/10000000 | consumed samples:    164736000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.661760E+00 | sop loss: 5.353004E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.85 | backward-compute: 79.78 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 14.18
 iteration  1288000/10000000 | consumed samples:    164864000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.652645E+00 | sop loss: 5.438690E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.12 | backward-compute: 79.80 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 16.64
 iteration  1289000/10000000 | consumed samples:    164992000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.653964E+00 | sop loss: 5.253902E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.64 | backward-compute: 79.84 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.19 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.61 | batch-generator: 18.42
 iteration  1290000/10000000 | consumed samples:    165120000 | elapsed time per iteration (ms): 249.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655723E+00 | sop loss: 5.410787E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.24 | backward-compute: 79.85 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 21.72
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1290000 | lm loss value: 1.721234E+00 | lm loss PPL: 5.591422E+00 | sop loss value: 5.886048E-02 | sop loss PPL: 1.060627E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1291000/10000000 | consumed samples:    165248000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655277E+00 | sop loss: 5.339245E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.86 | backward-compute: 79.84 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.32
 iteration  1292000/10000000 | consumed samples:    165376000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.653327E+00 | sop loss: 5.354378E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.78 | backward-compute: 79.91 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 18.81
 iteration  1293000/10000000 | consumed samples:    165504000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.652290E+00 | sop loss: 5.505430E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.31 | backward-compute: 79.77 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.52
 iteration  1294000/10000000 | consumed samples:    165632000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.659114E+00 | sop loss: 5.409418E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.99 | backward-compute: 79.88 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 17.37
 iteration  1295000/10000000 | consumed samples:    165760000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654630E+00 | sop loss: 5.340259E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.54 | backward-compute: 79.85 | backward-params-all-reduce: 14.28 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.51 | batch-generator: 15.53
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1295000 | lm loss value: 1.696538E+00 | lm loss PPL: 5.455029E+00 | sop loss value: 6.172032E-02 | sop loss PPL: 1.063665E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1296000/10000000 | consumed samples:    165888000 | elapsed time per iteration (ms): 249.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654289E+00 | sop loss: 5.423335E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.85 | backward-compute: 79.84 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.56 | batch-generator: 24.29
 iteration  1297000/10000000 | consumed samples:    166016000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654817E+00 | sop loss: 5.293290E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.72 | backward-compute: 79.81 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 13.34
 iteration  1298000/10000000 | consumed samples:    166144000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654979E+00 | sop loss: 5.301691E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.92 | backward-compute: 79.89 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 14.03
 iteration  1299000/10000000 | consumed samples:    166272000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.653785E+00 | sop loss: 5.433028E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.02 | backward-compute: 79.81 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.53 | batch-generator: 16.32
 iteration  1300000/10000000 | consumed samples:    166400000 | elapsed time per iteration (ms): 250.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656374E+00 | sop loss: 5.424924E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.95 | backward-compute: 79.81 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.51 | batch-generator: 16.30
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1300000 | lm loss value: 1.661364E+00 | lm loss PPL: 5.266487E+00 | sop loss value: 7.158788E-02 | sop loss PPL: 1.074213E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 1300000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 1300000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2345.41
 iteration  1301000/10000000 | consumed samples:    166528000 | elapsed time per iteration (ms): 253.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654569E+00 | sop loss: 5.462129E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.59 | backward-compute: 79.80 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 25.29
 iteration  1302000/10000000 | consumed samples:    166656000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656881E+00 | sop loss: 5.315545E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.69 | backward-compute: 79.79 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.79
 iteration  1303000/10000000 | consumed samples:    166784000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655307E+00 | sop loss: 5.419926E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.84 | backward-compute: 79.82 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.78
 iteration  1304000/10000000 | consumed samples:    166912000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.651637E+00 | sop loss: 5.373323E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.98 | backward-compute: 79.82 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 16.22
 iteration  1305000/10000000 | consumed samples:    167040000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654741E+00 | sop loss: 5.195185E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.32 | backward-compute: 79.80 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 15.20
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1305000 | lm loss value: 1.709237E+00 | lm loss PPL: 5.524746E+00 | sop loss value: 6.388565E-02 | sop loss PPL: 1.065970E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1306000/10000000 | consumed samples:    167168000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656036E+00 | sop loss: 5.269465E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.69 | backward-compute: 79.84 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.41
 iteration  1307000/10000000 | consumed samples:    167296000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655066E+00 | sop loss: 5.350414E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.14 | backward-compute: 79.81 | backward-params-all-reduce: 14.39 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.20 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.63 | batch-generator: 17.65
 iteration  1308000/10000000 | consumed samples:    167424000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655645E+00 | sop loss: 5.575468E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.55 | backward-compute: 79.79 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 14.59
 iteration  1309000/10000000 | consumed samples:    167552000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.658281E+00 | sop loss: 5.446498E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.47 | backward-compute: 79.80 | backward-params-all-reduce: 14.33 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.57 | batch-generator: 15.23
 iteration  1310000/10000000 | consumed samples:    167680000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.653539E+00 | sop loss: 5.396717E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.63 | backward-compute: 79.86 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 20.39
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1310000 | lm loss value: 1.671421E+00 | lm loss PPL: 5.319721E+00 | sop loss value: 7.696199E-02 | sop loss PPL: 1.080001E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1311000/10000000 | consumed samples:    167808000 | elapsed time per iteration (ms): 251.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656162E+00 | sop loss: 5.378756E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.35 | backward-compute: 79.85 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 25.72
 iteration  1312000/10000000 | consumed samples:    167936000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.652591E+00 | sop loss: 5.330130E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.17 | backward-compute: 79.79 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 25.40
 iteration  1313000/10000000 | consumed samples:    168064000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654071E+00 | sop loss: 5.316270E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.54 | backward-compute: 79.79 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 22.06
 iteration  1314000/10000000 | consumed samples:    168192000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655566E+00 | sop loss: 5.354447E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.43 | backward-compute: 79.75 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 18.66
 iteration  1315000/10000000 | consumed samples:    168320000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654482E+00 | sop loss: 5.222079E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.92 | backward-compute: 79.81 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 16.99
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1315000 | lm loss value: 1.701854E+00 | lm loss PPL: 5.484103E+00 | sop loss value: 7.875790E-02 | sop loss PPL: 1.081942E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1316000/10000000 | consumed samples:    168448000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.651702E+00 | sop loss: 5.480392E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.91 | backward-compute: 79.82 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.68
 iteration  1317000/10000000 | consumed samples:    168576000 | elapsed time per iteration (ms): 251.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656105E+00 | sop loss: 5.313855E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.25 | backward-compute: 79.76 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 12.35
 iteration  1318000/10000000 | consumed samples:    168704000 | elapsed time per iteration (ms): 250.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649402E+00 | sop loss: 5.380164E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.75 | backward-compute: 79.79 | backward-params-all-reduce: 14.39 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.19 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.61 | batch-generator: 16.75
 iteration  1319000/10000000 | consumed samples:    168832000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654027E+00 | sop loss: 5.392522E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.15 | backward-compute: 79.84 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.54
 iteration  1320000/10000000 | consumed samples:    168960000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.652630E+00 | sop loss: 5.317615E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.44 | backward-compute: 79.82 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 17.10
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1320000 | lm loss value: 1.671482E+00 | lm loss PPL: 5.320048E+00 | sop loss value: 5.766977E-02 | sop loss PPL: 1.059365E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1321000/10000000 | consumed samples:    169088000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650364E+00 | sop loss: 5.403989E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.46 | backward-compute: 79.85 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 16.20
 iteration  1322000/10000000 | consumed samples:    169216000 | elapsed time per iteration (ms): 246.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655302E+00 | sop loss: 5.453748E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.94 | backward-compute: 79.81 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 17.30
 iteration  1323000/10000000 | consumed samples:    169344000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.653799E+00 | sop loss: 5.347143E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.82 | backward-compute: 79.83 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 15.40
 iteration  1324000/10000000 | consumed samples:    169472000 | elapsed time per iteration (ms): 246.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655594E+00 | sop loss: 5.419921E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.10 | backward-compute: 79.79 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.38
 iteration  1325000/10000000 | consumed samples:    169600000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.652663E+00 | sop loss: 5.407787E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.32 | backward-compute: 79.84 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 17.81
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1325000 | lm loss value: 1.732048E+00 | lm loss PPL: 5.652216E+00 | sop loss value: 5.362609E-02 | sop loss PPL: 1.055090E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1326000/10000000 | consumed samples:    169728000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.652589E+00 | sop loss: 5.442152E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.24 | backward-compute: 79.81 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.29
 iteration  1327000/10000000 | consumed samples:    169856000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655611E+00 | sop loss: 5.447963E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.79 | backward-compute: 79.83 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 18.44
 iteration  1328000/10000000 | consumed samples:    169984000 | elapsed time per iteration (ms): 246.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654269E+00 | sop loss: 5.396132E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.45 | backward-compute: 79.78 | backward-params-all-reduce: 14.29 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 11.81
 iteration  1329000/10000000 | consumed samples:    170112000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655363E+00 | sop loss: 5.356373E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.67 | backward-compute: 79.80 | backward-params-all-reduce: 14.65 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.32 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.78 | batch-generator: 15.39
 iteration  1330000/10000000 | consumed samples:    170240000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.653439E+00 | sop loss: 5.502953E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.42 | backward-compute: 79.82 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 17.51
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1330000 | lm loss value: 1.715679E+00 | lm loss PPL: 5.560450E+00 | sop loss value: 5.959224E-02 | sop loss PPL: 1.061404E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1331000/10000000 | consumed samples:    170368000 | elapsed time per iteration (ms): 250.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654925E+00 | sop loss: 5.455273E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.75 | backward-compute: 79.83 | backward-params-all-reduce: 14.47 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.21 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.63 | batch-generator: 13.88
 iteration  1332000/10000000 | consumed samples:    170496000 | elapsed time per iteration (ms): 246.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.653959E+00 | sop loss: 5.306123E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.95 | backward-compute: 79.82 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.06
 iteration  1333000/10000000 | consumed samples:    170624000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.656850E+00 | sop loss: 5.446936E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.09 | backward-compute: 79.82 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 14.99
 iteration  1334000/10000000 | consumed samples:    170752000 | elapsed time per iteration (ms): 250.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.653225E+00 | sop loss: 5.337023E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.71 | backward-compute: 79.83 | backward-params-all-reduce: 14.39 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.56 | batch-generator: 17.52
 iteration  1335000/10000000 | consumed samples:    170880000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.652500E+00 | sop loss: 5.299660E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.24 | backward-compute: 79.77 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 19.09
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1335000 | lm loss value: 1.705490E+00 | lm loss PPL: 5.504085E+00 | sop loss value: 7.278044E-02 | sop loss PPL: 1.075494E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1336000/10000000 | consumed samples:    171008000 | elapsed time per iteration (ms): 251.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.651227E+00 | sop loss: 5.315518E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.06 | backward-compute: 79.79 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 16.52
 iteration  1337000/10000000 | consumed samples:    171136000 | elapsed time per iteration (ms): 245.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.653591E+00 | sop loss: 5.459620E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.56 | backward-compute: 79.83 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 17.88
 iteration  1338000/10000000 | consumed samples:    171264000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.653325E+00 | sop loss: 5.393549E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.15 | backward-compute: 79.86 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 14.13
 iteration  1339000/10000000 | consumed samples:    171392000 | elapsed time per iteration (ms): 247.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.653079E+00 | sop loss: 5.513552E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.40 | backward-compute: 79.78 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.41 | batch-generator: 16.69
 iteration  1340000/10000000 | consumed samples:    171520000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654020E+00 | sop loss: 5.441059E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.89 | backward-compute: 79.81 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 18.34
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1340000 | lm loss value: 1.695981E+00 | lm loss PPL: 5.451992E+00 | sop loss value: 8.764156E-02 | sop loss PPL: 1.091597E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1341000/10000000 | consumed samples:    171648000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.652091E+00 | sop loss: 5.342467E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.08 | backward-compute: 79.78 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.30 | batch-generator: 18.53
 iteration  1342000/10000000 | consumed samples:    171776000 | elapsed time per iteration (ms): 246.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654673E+00 | sop loss: 5.495965E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.61 | backward-compute: 79.79 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 14.92
 iteration  1343000/10000000 | consumed samples:    171904000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650253E+00 | sop loss: 5.386041E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.73 | backward-compute: 79.76 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 13.89
 iteration  1344000/10000000 | consumed samples:    172032000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654463E+00 | sop loss: 5.445740E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.68 | backward-compute: 79.76 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 15.18
 iteration  1345000/10000000 | consumed samples:    172160000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654974E+00 | sop loss: 5.321151E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.45 | backward-compute: 79.82 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 12.65
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1345000 | lm loss value: 1.671738E+00 | lm loss PPL: 5.321410E+00 | sop loss value: 6.249498E-02 | sop loss PPL: 1.064489E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1346000/10000000 | consumed samples:    172288000 | elapsed time per iteration (ms): 249.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648644E+00 | sop loss: 5.422583E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.39 | backward-compute: 79.91 | backward-params-all-reduce: 13.91 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 16.72
 iteration  1347000/10000000 | consumed samples:    172416000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.651413E+00 | sop loss: 5.321843E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.92 | backward-compute: 79.81 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.53 | batch-generator: 14.24
 iteration  1348000/10000000 | consumed samples:    172544000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649860E+00 | sop loss: 5.323368E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.00 | backward-compute: 79.87 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.93
 iteration  1349000/10000000 | consumed samples:    172672000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650623E+00 | sop loss: 5.308489E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.98 | backward-compute: 79.83 | backward-params-all-reduce: 14.45 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.23 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.64 | batch-generator: 14.74
 iteration  1350000/10000000 | consumed samples:    172800000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650004E+00 | sop loss: 5.423127E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.86 | backward-compute: 79.82 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 11.12
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1350000 | lm loss value: 1.683537E+00 | lm loss PPL: 5.384568E+00 | sop loss value: 8.587184E-02 | sop loss PPL: 1.089667E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 1350000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 1350000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2299.02
 iteration  1351000/10000000 | consumed samples:    172928000 | elapsed time per iteration (ms): 252.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650555E+00 | sop loss: 5.393789E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.87 | backward-compute: 79.84 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 17.30
 iteration  1352000/10000000 | consumed samples:    173056000 | elapsed time per iteration (ms): 246.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654061E+00 | sop loss: 5.379163E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.85 | backward-compute: 79.85 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.50 | batch-generator: 16.68
 iteration  1353000/10000000 | consumed samples:    173184000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655639E+00 | sop loss: 5.254538E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.55 | backward-compute: 79.81 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 16.56
 iteration  1354000/10000000 | consumed samples:    173312000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.653064E+00 | sop loss: 5.363761E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.11 | backward-compute: 79.81 | backward-params-all-reduce: 14.60 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.27 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.73 | batch-generator: 15.79
 iteration  1355000/10000000 | consumed samples:    173440000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650095E+00 | sop loss: 5.457215E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.27 | backward-compute: 79.80 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.55 | batch-generator: 17.30
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1355000 | lm loss value: 1.687674E+00 | lm loss PPL: 5.406891E+00 | sop loss value: 6.971660E-02 | sop loss PPL: 1.072204E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1356000/10000000 | consumed samples:    173568000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654881E+00 | sop loss: 5.522184E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.68 | backward-compute: 79.85 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 19.09
 iteration  1357000/10000000 | consumed samples:    173696000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.651464E+00 | sop loss: 5.429839E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.52 | backward-compute: 79.80 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 18.26
 iteration  1358000/10000000 | consumed samples:    173824000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654634E+00 | sop loss: 5.225694E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.85 | backward-compute: 80.03 | backward-params-all-reduce: 14.57 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.87 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.34 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.82 | batch-generator: 15.80
 iteration  1359000/10000000 | consumed samples:    173952000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650266E+00 | sop loss: 5.349926E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.62 | backward-compute: 79.86 | backward-params-all-reduce: 14.38 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.53 | batch-generator: 16.78
 iteration  1360000/10000000 | consumed samples:    174080000 | elapsed time per iteration (ms): 246.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650155E+00 | sop loss: 5.287967E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.88 | backward-compute: 79.90 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 17.89
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1360000 | lm loss value: 1.687060E+00 | lm loss PPL: 5.403572E+00 | sop loss value: 6.701928E-02 | sop loss PPL: 1.069316E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1361000/10000000 | consumed samples:    174208000 | elapsed time per iteration (ms): 251.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649171E+00 | sop loss: 5.388572E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.43 | backward-compute: 79.82 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 17.73
 iteration  1362000/10000000 | consumed samples:    174336000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.653251E+00 | sop loss: 5.318546E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.24 | backward-compute: 79.77 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 13.35
 iteration  1363000/10000000 | consumed samples:    174464000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.651321E+00 | sop loss: 5.371088E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.89 | backward-compute: 79.84 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 14.63
 iteration  1364000/10000000 | consumed samples:    174592000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.652334E+00 | sop loss: 5.480351E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.87 | backward-compute: 79.79 | backward-params-all-reduce: 14.44 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.20 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.62 | batch-generator: 17.07
 iteration  1365000/10000000 | consumed samples:    174720000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.651885E+00 | sop loss: 5.456223E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.25 | backward-compute: 79.81 | backward-params-all-reduce: 14.50 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.22 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.69 | batch-generator: 17.78
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1365000 | lm loss value: 1.739553E+00 | lm loss PPL: 5.694796E+00 | sop loss value: 7.011068E-02 | sop loss PPL: 1.072627E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1366000/10000000 | consumed samples:    174848000 | elapsed time per iteration (ms): 251.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.652550E+00 | sop loss: 5.295769E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.59 | backward-compute: 79.84 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.29
 iteration  1367000/10000000 | consumed samples:    174976000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.652500E+00 | sop loss: 5.408713E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.27 | backward-compute: 79.87 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 14.55
 iteration  1368000/10000000 | consumed samples:    175104000 | elapsed time per iteration (ms): 250.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655731E+00 | sop loss: 5.331562E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.46 | backward-compute: 79.81 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 25.96
 iteration  1369000/10000000 | consumed samples:    175232000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.652289E+00 | sop loss: 5.324539E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.98 | backward-compute: 79.84 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.65
 iteration  1370000/10000000 | consumed samples:    175360000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.651332E+00 | sop loss: 5.296408E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.51 | backward-compute: 79.76 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.02
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1370000 | lm loss value: 1.685348E+00 | lm loss PPL: 5.394329E+00 | sop loss value: 6.308138E-02 | sop loss PPL: 1.065114E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1371000/10000000 | consumed samples:    175488000 | elapsed time per iteration (ms): 250.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648960E+00 | sop loss: 5.498684E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.11 | backward-compute: 79.84 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 17.36
 iteration  1372000/10000000 | consumed samples:    175616000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649469E+00 | sop loss: 5.342896E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.83 | backward-compute: 79.87 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 15.28
 iteration  1373000/10000000 | consumed samples:    175744000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.655839E+00 | sop loss: 5.439805E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.09 | backward-compute: 79.83 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 16.65
 iteration  1374000/10000000 | consumed samples:    175872000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650483E+00 | sop loss: 5.317132E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.34 | backward-compute: 79.85 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 13.34
 iteration  1375000/10000000 | consumed samples:    176000000 | elapsed time per iteration (ms): 246.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650257E+00 | sop loss: 5.408875E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.47 | backward-compute: 79.84 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.45
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1375000 | lm loss value: 1.683099E+00 | lm loss PPL: 5.382209E+00 | sop loss value: 6.447170E-02 | sop loss PPL: 1.066595E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1376000/10000000 | consumed samples:    176128000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.651727E+00 | sop loss: 5.512759E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.18 | backward-compute: 79.81 | backward-params-all-reduce: 14.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.57 | batch-generator: 17.45
 iteration  1377000/10000000 | consumed samples:    176256000 | elapsed time per iteration (ms): 250.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.651823E+00 | sop loss: 5.395144E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.95 | backward-compute: 79.75 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 22.00
 iteration  1378000/10000000 | consumed samples:    176384000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650146E+00 | sop loss: 5.343678E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.21 | backward-compute: 79.79 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 16.10
 iteration  1379000/10000000 | consumed samples:    176512000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649969E+00 | sop loss: 5.367850E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.17 | backward-compute: 79.83 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.53 | batch-generator: 16.62
 iteration  1380000/10000000 | consumed samples:    176640000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.651418E+00 | sop loss: 5.507161E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.05 | backward-compute: 79.80 | backward-params-all-reduce: 14.28 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.55 | batch-generator: 15.60
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1380000 | lm loss value: 1.657271E+00 | lm loss PPL: 5.244979E+00 | sop loss value: 7.227039E-02 | sop loss PPL: 1.074946E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1381000/10000000 | consumed samples:    176768000 | elapsed time per iteration (ms): 249.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650163E+00 | sop loss: 5.371419E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.24 | backward-compute: 79.81 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 12.82
 iteration  1382000/10000000 | consumed samples:    176896000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.651102E+00 | sop loss: 5.191021E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.18 | backward-compute: 79.78 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 13.55
 iteration  1383000/10000000 | consumed samples:    177024000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.653649E+00 | sop loss: 5.398391E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.76 | backward-compute: 79.77 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.41 | batch-generator: 14.56
 iteration  1384000/10000000 | consumed samples:    177152000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.651352E+00 | sop loss: 5.273385E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.13 | backward-compute: 79.79 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 13.58
 iteration  1385000/10000000 | consumed samples:    177280000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649183E+00 | sop loss: 5.410621E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.80 | backward-compute: 79.79 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 14.80
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1385000 | lm loss value: 1.698732E+00 | lm loss PPL: 5.467010E+00 | sop loss value: 6.209520E-02 | sop loss PPL: 1.064064E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1386000/10000000 | consumed samples:    177408000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.652536E+00 | sop loss: 5.279148E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.69 | backward-compute: 79.83 | backward-params-all-reduce: 14.76 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.88 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.34 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.85 | batch-generator: 15.42
 iteration  1387000/10000000 | consumed samples:    177536000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.652975E+00 | sop loss: 5.345169E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.06 | backward-compute: 79.83 | backward-params-all-reduce: 13.86 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 12.94
 iteration  1388000/10000000 | consumed samples:    177664000 | elapsed time per iteration (ms): 247.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.652768E+00 | sop loss: 5.410852E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.90 | backward-compute: 79.78 | backward-params-all-reduce: 14.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 17.11
 iteration  1389000/10000000 | consumed samples:    177792000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.652827E+00 | sop loss: 5.292120E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.73 | backward-compute: 79.76 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.44 | batch-generator: 15.26
 iteration  1390000/10000000 | consumed samples:    177920000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.652055E+00 | sop loss: 5.372909E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.33 | backward-compute: 79.76 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 13.07
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1390000 | lm loss value: 1.650285E+00 | lm loss PPL: 5.208462E+00 | sop loss value: 5.946690E-02 | sop loss PPL: 1.061271E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1391000/10000000 | consumed samples:    178048000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649486E+00 | sop loss: 5.375977E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.32 | backward-compute: 79.81 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 18.75
 iteration  1392000/10000000 | consumed samples:    178176000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650698E+00 | sop loss: 5.445550E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.08 | backward-compute: 79.81 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 12.78
 iteration  1393000/10000000 | consumed samples:    178304000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.651334E+00 | sop loss: 5.381401E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.77 | backward-compute: 79.81 | backward-params-all-reduce: 14.64 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.28 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.76 | batch-generator: 14.82
 iteration  1394000/10000000 | consumed samples:    178432000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650532E+00 | sop loss: 5.318235E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.82 | backward-compute: 79.97 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 18.84
 iteration  1395000/10000000 | consumed samples:    178560000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.651355E+00 | sop loss: 5.383403E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.86 | backward-compute: 79.82 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 16.61
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1395000 | lm loss value: 1.727932E+00 | lm loss PPL: 5.629002E+00 | sop loss value: 6.547312E-02 | sop loss PPL: 1.067664E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1396000/10000000 | consumed samples:    178688000 | elapsed time per iteration (ms): 251.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650161E+00 | sop loss: 5.458316E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.57 | backward-compute: 79.76 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 14.65
 iteration  1397000/10000000 | consumed samples:    178816000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650759E+00 | sop loss: 5.318434E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.73 | backward-compute: 79.80 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 16.42
 iteration  1398000/10000000 | consumed samples:    178944000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649919E+00 | sop loss: 5.401588E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.09 | backward-compute: 79.86 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 16.05
 iteration  1399000/10000000 | consumed samples:    179072000 | elapsed time per iteration (ms): 246.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.651154E+00 | sop loss: 5.342519E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.85 | backward-compute: 79.83 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 13.29
 iteration  1400000/10000000 | consumed samples:    179200000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654021E+00 | sop loss: 5.273576E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.86 | backward-compute: 79.82 | backward-params-all-reduce: 14.54 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.25 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.71 | batch-generator: 15.43
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1400000 | lm loss value: 1.672224E+00 | lm loss PPL: 5.323995E+00 | sop loss value: 7.358378E-02 | sop loss PPL: 1.076359E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 1400000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 1400000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2412.57
 iteration  1401000/10000000 | consumed samples:    179328000 | elapsed time per iteration (ms): 252.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648755E+00 | sop loss: 5.286325E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.74 | backward-compute: 79.83 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 19.88
 iteration  1402000/10000000 | consumed samples:    179456000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648293E+00 | sop loss: 5.239072E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.47 | backward-compute: 79.81 | backward-params-all-reduce: 14.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 14.37
 iteration  1403000/10000000 | consumed samples:    179584000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.651843E+00 | sop loss: 5.421200E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.77 | backward-compute: 79.82 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 15.08
 iteration  1404000/10000000 | consumed samples:    179712000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647487E+00 | sop loss: 5.390158E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.71 | backward-compute: 79.89 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 15.38
 iteration  1405000/10000000 | consumed samples:    179840000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.654101E+00 | sop loss: 5.343977E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.84 | backward-compute: 79.90 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.13
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1405000 | lm loss value: 1.684120E+00 | lm loss PPL: 5.387707E+00 | sop loss value: 6.839972E-02 | sop loss PPL: 1.070793E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1406000/10000000 | consumed samples:    179968000 | elapsed time per iteration (ms): 252.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.651152E+00 | sop loss: 5.308407E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.87 | backward-compute: 79.84 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 16.42
 iteration  1407000/10000000 | consumed samples:    180096000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649400E+00 | sop loss: 5.283205E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.00 | backward-compute: 79.83 | backward-params-all-reduce: 14.37 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.57 | batch-generator: 16.22
 iteration  1408000/10000000 | consumed samples:    180224000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649481E+00 | sop loss: 5.346721E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.90 | backward-compute: 79.76 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.51 | batch-generator: 13.94
 iteration  1409000/10000000 | consumed samples:    180352000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.651663E+00 | sop loss: 5.264471E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.76 | backward-compute: 79.90 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 14.95
 iteration  1410000/10000000 | consumed samples:    180480000 | elapsed time per iteration (ms): 246.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.653435E+00 | sop loss: 5.298232E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.62 | backward-compute: 79.89 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 13.18
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1410000 | lm loss value: 1.683963E+00 | lm loss PPL: 5.386862E+00 | sop loss value: 8.946862E-02 | sop loss PPL: 1.093593E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1411000/10000000 | consumed samples:    180608000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650744E+00 | sop loss: 5.533416E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.29 | backward-compute: 79.87 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 14.80
 iteration  1412000/10000000 | consumed samples:    180736000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649188E+00 | sop loss: 5.374569E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.24 | backward-compute: 79.78 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 14.18
 iteration  1413000/10000000 | consumed samples:    180864000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650085E+00 | sop loss: 5.298783E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.09 | backward-compute: 79.78 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.76 | optimizer-unscale-and-check-inf: 2.24 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.30 | batch-generator: 15.88
 iteration  1414000/10000000 | consumed samples:    180992000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650278E+00 | sop loss: 5.420557E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.68 | backward-compute: 79.78 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 16.45
 iteration  1415000/10000000 | consumed samples:    181120000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.651528E+00 | sop loss: 5.364025E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.85 | backward-compute: 79.87 | backward-params-all-reduce: 14.79 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.92 | optimizer-unscale-and-check-inf: 2.31 | optimizer-clip-main-grad: 4.32 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.90 | batch-generator: 18.25
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1415000 | lm loss value: 1.712282E+00 | lm loss PPL: 5.541595E+00 | sop loss value: 5.933752E-02 | sop loss PPL: 1.061133E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1416000/10000000 | consumed samples:    181248000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.653675E+00 | sop loss: 5.456813E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.06 | backward-compute: 79.90 | backward-params-all-reduce: 14.68 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.87 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.19 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.68 | batch-generator: 13.79
 iteration  1417000/10000000 | consumed samples:    181376000 | elapsed time per iteration (ms): 247.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650281E+00 | sop loss: 5.313720E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.06 | backward-compute: 79.89 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 15.17
 iteration  1418000/10000000 | consumed samples:    181504000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649038E+00 | sop loss: 5.406718E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.18 | backward-compute: 79.85 | backward-params-all-reduce: 14.28 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 15.04
 iteration  1419000/10000000 | consumed samples:    181632000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650025E+00 | sop loss: 5.379554E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.92 | backward-compute: 79.86 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 11.71
 iteration  1420000/10000000 | consumed samples:    181760000 | elapsed time per iteration (ms): 250.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.652461E+00 | sop loss: 5.235683E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.10 | backward-compute: 79.77 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 13.54
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1420000 | lm loss value: 1.691405E+00 | lm loss PPL: 5.427100E+00 | sop loss value: 6.963977E-02 | sop loss PPL: 1.072122E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1421000/10000000 | consumed samples:    181888000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650333E+00 | sop loss: 5.499531E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.50 | backward-compute: 79.81 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 13.82
 iteration  1422000/10000000 | consumed samples:    182016000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648836E+00 | sop loss: 5.441952E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.78 | backward-compute: 79.85 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 16.12
 iteration  1423000/10000000 | consumed samples:    182144000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649153E+00 | sop loss: 5.266993E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.44 | backward-compute: 79.88 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 13.16
 iteration  1424000/10000000 | consumed samples:    182272000 | elapsed time per iteration (ms): 250.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648536E+00 | sop loss: 5.366857E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.92 | backward-compute: 79.82 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 21.07
 iteration  1425000/10000000 | consumed samples:    182400000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650534E+00 | sop loss: 5.445668E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.29 | backward-compute: 79.82 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 18.82
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1425000 | lm loss value: 1.704603E+00 | lm loss PPL: 5.499201E+00 | sop loss value: 5.353111E-02 | sop loss PPL: 1.054990E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1426000/10000000 | consumed samples:    182528000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649100E+00 | sop loss: 5.249850E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.89 | backward-compute: 79.85 | backward-params-all-reduce: 14.38 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 14.88
 iteration  1427000/10000000 | consumed samples:    182656000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647207E+00 | sop loss: 5.322741E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.27 | backward-compute: 79.82 | backward-params-all-reduce: 14.48 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.20 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.63 | batch-generator: 14.27
 iteration  1428000/10000000 | consumed samples:    182784000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649433E+00 | sop loss: 5.241343E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.96 | backward-compute: 79.73 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 13.65
 iteration  1429000/10000000 | consumed samples:    182912000 | elapsed time per iteration (ms): 246.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.651715E+00 | sop loss: 5.340933E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.00 | backward-compute: 79.80 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.55 | batch-generator: 17.19
 iteration  1430000/10000000 | consumed samples:    183040000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649741E+00 | sop loss: 5.237060E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.67 | backward-compute: 79.78 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 15.32
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1430000 | lm loss value: 1.700859E+00 | lm loss PPL: 5.478652E+00 | sop loss value: 8.050574E-02 | sop loss PPL: 1.083835E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1431000/10000000 | consumed samples:    183168000 | elapsed time per iteration (ms): 250.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650266E+00 | sop loss: 5.272728E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.36 | backward-compute: 79.75 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 15.10
 iteration  1432000/10000000 | consumed samples:    183296000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650587E+00 | sop loss: 5.464494E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.76 | backward-compute: 79.76 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 16.42
 iteration  1433000/10000000 | consumed samples:    183424000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649413E+00 | sop loss: 5.503030E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.58 | backward-compute: 79.76 | backward-params-all-reduce: 14.28 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 15.94
 iteration  1434000/10000000 | consumed samples:    183552000 | elapsed time per iteration (ms): 245.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649094E+00 | sop loss: 5.297963E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.90 | backward-compute: 79.77 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.34
 iteration  1435000/10000000 | consumed samples:    183680000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650124E+00 | sop loss: 5.438300E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.95 | backward-compute: 79.77 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 18.73
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1435000 | lm loss value: 1.720881E+00 | lm loss PPL: 5.589449E+00 | sop loss value: 6.360799E-02 | sop loss PPL: 1.065675E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1436000/10000000 | consumed samples:    183808000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648042E+00 | sop loss: 5.452267E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.45 | backward-compute: 79.80 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 16.55
 iteration  1437000/10000000 | consumed samples:    183936000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.646688E+00 | sop loss: 5.398008E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.44 | backward-compute: 79.79 | backward-params-all-reduce: 14.52 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.23 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.66 | batch-generator: 13.35
 iteration  1438000/10000000 | consumed samples:    184064000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647963E+00 | sop loss: 5.237181E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.87 | backward-compute: 79.77 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.49
 iteration  1439000/10000000 | consumed samples:    184192000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648317E+00 | sop loss: 5.485503E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.92 | backward-compute: 79.77 | backward-params-all-reduce: 14.35 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.55 | batch-generator: 12.69
 iteration  1440000/10000000 | consumed samples:    184320000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647572E+00 | sop loss: 5.405137E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.18 | backward-compute: 79.79 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 18.66
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1440000 | lm loss value: 1.697927E+00 | lm loss PPL: 5.462614E+00 | sop loss value: 7.644457E-02 | sop loss PPL: 1.079442E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1441000/10000000 | consumed samples:    184448000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648483E+00 | sop loss: 5.185534E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.67 | backward-compute: 79.80 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 18.93
 iteration  1442000/10000000 | consumed samples:    184576000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.646462E+00 | sop loss: 5.291620E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.18 | backward-compute: 79.75 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.62
 iteration  1443000/10000000 | consumed samples:    184704000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647740E+00 | sop loss: 5.267183E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.26 | backward-compute: 79.81 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 15.87
 iteration  1444000/10000000 | consumed samples:    184832000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648118E+00 | sop loss: 5.266174E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.89 | backward-compute: 79.78 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 17.81
 iteration  1445000/10000000 | consumed samples:    184960000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648164E+00 | sop loss: 5.260874E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.24 | backward-compute: 79.76 | backward-params-all-reduce: 14.70 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.87 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.34 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.84 | batch-generator: 17.00
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1445000 | lm loss value: 1.673040E+00 | lm loss PPL: 5.328340E+00 | sop loss value: 6.662064E-02 | sop loss PPL: 1.068890E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1446000/10000000 | consumed samples:    185088000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650490E+00 | sop loss: 5.225084E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.56 | backward-compute: 79.81 | backward-params-all-reduce: 14.28 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 15.20
 iteration  1447000/10000000 | consumed samples:    185216000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649847E+00 | sop loss: 5.351510E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.56 | backward-compute: 79.88 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 15.85
 iteration  1448000/10000000 | consumed samples:    185344000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648873E+00 | sop loss: 5.340622E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.81 | backward-compute: 79.86 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 15.00
 iteration  1449000/10000000 | consumed samples:    185472000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648485E+00 | sop loss: 5.328432E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.43 | backward-compute: 79.85 | backward-params-all-reduce: 14.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 18.00
 iteration  1450000/10000000 | consumed samples:    185600000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.652597E+00 | sop loss: 5.324092E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.56 | backward-compute: 79.86 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.56 | batch-generator: 14.50
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1450000 | lm loss value: 1.671328E+00 | lm loss PPL: 5.319225E+00 | sop loss value: 5.281987E-02 | sop loss PPL: 1.054240E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 1450000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 1450000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2264.99
 iteration  1451000/10000000 | consumed samples:    185728000 | elapsed time per iteration (ms): 252.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.646056E+00 | sop loss: 5.379871E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.43 | backward-compute: 79.81 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.56
 iteration  1452000/10000000 | consumed samples:    185856000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647181E+00 | sop loss: 5.358207E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.76 | backward-compute: 79.72 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 16.43
 iteration  1453000/10000000 | consumed samples:    185984000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648344E+00 | sop loss: 5.326917E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.23 | backward-compute: 79.86 | backward-params-all-reduce: 13.88 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 18.51
 iteration  1454000/10000000 | consumed samples:    186112000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.646928E+00 | sop loss: 5.443752E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.06 | backward-compute: 79.74 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 13.12
 iteration  1455000/10000000 | consumed samples:    186240000 | elapsed time per iteration (ms): 246.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648512E+00 | sop loss: 5.467161E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.20 | backward-compute: 79.83 | backward-params-all-reduce: 14.39 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.19 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.65 | batch-generator: 14.75
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1455000 | lm loss value: 1.700849E+00 | lm loss PPL: 5.478599E+00 | sop loss value: 5.736838E-02 | sop loss PPL: 1.059046E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1456000/10000000 | consumed samples:    186368000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649832E+00 | sop loss: 5.284733E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.01 | backward-compute: 79.80 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 14.80
 iteration  1457000/10000000 | consumed samples:    186496000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.646855E+00 | sop loss: 5.267968E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.33 | backward-compute: 79.76 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 17.10
 iteration  1458000/10000000 | consumed samples:    186624000 | elapsed time per iteration (ms): 247.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649773E+00 | sop loss: 5.373227E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.24 | backward-compute: 79.78 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 13.14
 iteration  1459000/10000000 | consumed samples:    186752000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648820E+00 | sop loss: 5.212991E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.81 | backward-compute: 79.76 | backward-params-all-reduce: 13.92 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 16.41
 iteration  1460000/10000000 | consumed samples:    186880000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648442E+00 | sop loss: 5.311043E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.53 | backward-compute: 79.84 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 16.82
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1460000 | lm loss value: 1.752111E+00 | lm loss PPL: 5.766763E+00 | sop loss value: 6.105541E-02 | sop loss PPL: 1.062958E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1461000/10000000 | consumed samples:    187008000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647834E+00 | sop loss: 5.400112E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.04 | backward-compute: 79.82 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 14.70
 iteration  1462000/10000000 | consumed samples:    187136000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648074E+00 | sop loss: 5.466416E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.92 | backward-compute: 79.81 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 16.16
 iteration  1463000/10000000 | consumed samples:    187264000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647825E+00 | sop loss: 5.301824E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.79 | backward-compute: 79.97 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 14.14
 iteration  1464000/10000000 | consumed samples:    187392000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647223E+00 | sop loss: 5.396623E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.18 | backward-compute: 79.91 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 14.58
 iteration  1465000/10000000 | consumed samples:    187520000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648381E+00 | sop loss: 5.395882E-02 | loss scale: 8192.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.27 | backward-compute: 79.72 | backward-params-all-reduce: 14.34 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 13.48
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1465000 | lm loss value: 1.672469E+00 | lm loss PPL: 5.325300E+00 | sop loss value: 5.736960E-02 | sop loss PPL: 1.059047E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1466000/10000000 | consumed samples:    187648000 | elapsed time per iteration (ms): 253.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649373E+00 | sop loss: 5.400860E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.58 | backward-compute: 79.74 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 16.07
 iteration  1467000/10000000 | consumed samples:    187776000 | elapsed time per iteration (ms): 246.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648016E+00 | sop loss: 5.372465E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.14 | backward-compute: 79.76 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 14.67
 iteration  1468000/10000000 | consumed samples:    187904000 | elapsed time per iteration (ms): 246.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650874E+00 | sop loss: 5.307972E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.47 | backward-compute: 79.81 | backward-params-all-reduce: 14.41 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.60 | batch-generator: 17.90
 iteration  1469000/10000000 | consumed samples:    188032000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647933E+00 | sop loss: 5.235477E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.26 | backward-compute: 79.83 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 15.01
 iteration  1470000/10000000 | consumed samples:    188160000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647086E+00 | sop loss: 5.383840E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.02 | backward-compute: 79.89 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 15.68
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1470000 | lm loss value: 1.746140E+00 | lm loss PPL: 5.732432E+00 | sop loss value: 6.669848E-02 | sop loss PPL: 1.068973E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1471000/10000000 | consumed samples:    188288000 | elapsed time per iteration (ms): 252.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.646235E+00 | sop loss: 5.356323E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.80 | backward-compute: 79.78 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 13.06
 iteration  1472000/10000000 | consumed samples:    188416000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.646648E+00 | sop loss: 5.354933E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.19 | backward-compute: 79.78 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.03
 iteration  1473000/10000000 | consumed samples:    188544000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.646217E+00 | sop loss: 5.320358E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.20 | backward-compute: 79.80 | backward-params-all-reduce: 14.56 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.26 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.69 | batch-generator: 15.47
 iteration  1474000/10000000 | consumed samples:    188672000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.653022E+00 | sop loss: 5.272564E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.66 | backward-compute: 79.78 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 17.30
 iteration  1475000/10000000 | consumed samples:    188800000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648522E+00 | sop loss: 5.297060E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.92 | backward-compute: 79.86 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.41 | batch-generator: 16.31
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1475000 | lm loss value: 1.650259E+00 | lm loss PPL: 5.208329E+00 | sop loss value: 5.892396E-02 | sop loss PPL: 1.060695E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1476000/10000000 | consumed samples:    188928000 | elapsed time per iteration (ms): 250.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649826E+00 | sop loss: 5.397201E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.70 | backward-compute: 79.79 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 15.25
 iteration  1477000/10000000 | consumed samples:    189056000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.646415E+00 | sop loss: 5.345331E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.71 | backward-compute: 79.79 | backward-params-all-reduce: 14.44 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.53 | batch-generator: 18.70
 iteration  1478000/10000000 | consumed samples:    189184000 | elapsed time per iteration (ms): 249.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647418E+00 | sop loss: 5.319618E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.78 | backward-compute: 79.79 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 18.61
 iteration  1479000/10000000 | consumed samples:    189312000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647365E+00 | sop loss: 5.330307E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.27 | backward-compute: 79.80 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 14.07
 iteration  1480000/10000000 | consumed samples:    189440000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.646026E+00 | sop loss: 5.414382E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.35 | backward-compute: 79.79 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 17.43
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1480000 | lm loss value: 1.697904E+00 | lm loss PPL: 5.462483E+00 | sop loss value: 5.438212E-02 | sop loss PPL: 1.055888E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1481000/10000000 | consumed samples:    189568000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650652E+00 | sop loss: 5.401444E-02 | loss scale: 32768.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.09 | backward-compute: 79.82 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 18.02
 iteration  1482000/10000000 | consumed samples:    189696000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647142E+00 | sop loss: 5.229032E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.00 | backward-compute: 79.80 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 13.31
 iteration  1483000/10000000 | consumed samples:    189824000 | elapsed time per iteration (ms): 250.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643236E+00 | sop loss: 5.183662E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.28 | backward-compute: 79.83 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 18.17
 iteration  1484000/10000000 | consumed samples:    189952000 | elapsed time per iteration (ms): 251.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647428E+00 | sop loss: 5.380619E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.49 | backward-compute: 79.85 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 22.76
 iteration  1485000/10000000 | consumed samples:    190080000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.646254E+00 | sop loss: 5.456983E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.29 | backward-compute: 80.00 | backward-params-all-reduce: 13.90 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 16.65
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1485000 | lm loss value: 1.695574E+00 | lm loss PPL: 5.449774E+00 | sop loss value: 5.224191E-02 | sop loss PPL: 1.053631E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1486000/10000000 | consumed samples:    190208000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648342E+00 | sop loss: 5.441113E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.55 | backward-compute: 79.84 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 19.98
 iteration  1487000/10000000 | consumed samples:    190336000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650702E+00 | sop loss: 5.334091E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.97 | backward-compute: 79.77 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 16.52
 iteration  1488000/10000000 | consumed samples:    190464000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648094E+00 | sop loss: 5.190228E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.29 | backward-compute: 79.86 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 18.76
 iteration  1489000/10000000 | consumed samples:    190592000 | elapsed time per iteration (ms): 246.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644604E+00 | sop loss: 5.256196E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.42 | backward-compute: 79.86 | backward-params-all-reduce: 14.64 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.32 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.79 | batch-generator: 17.39
 iteration  1490000/10000000 | consumed samples:    190720000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645634E+00 | sop loss: 5.196885E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.28 | backward-compute: 79.81 | backward-params-all-reduce: 14.27 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.58 | batch-generator: 12.76
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1490000 | lm loss value: 1.690655E+00 | lm loss PPL: 5.423030E+00 | sop loss value: 7.404319E-02 | sop loss PPL: 1.076853E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1491000/10000000 | consumed samples:    190848000 | elapsed time per iteration (ms): 250.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647645E+00 | sop loss: 5.324448E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.60 | backward-compute: 79.78 | backward-params-all-reduce: 14.51 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.27 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.75 | batch-generator: 15.82
 iteration  1492000/10000000 | consumed samples:    190976000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648941E+00 | sop loss: 5.393242E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.79 | backward-compute: 79.83 | backward-params-all-reduce: 14.47 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.26 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.72 | batch-generator: 15.36
 iteration  1493000/10000000 | consumed samples:    191104000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645798E+00 | sop loss: 5.381663E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.65 | backward-compute: 79.78 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 14.24
 iteration  1494000/10000000 | consumed samples:    191232000 | elapsed time per iteration (ms): 246.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.646766E+00 | sop loss: 5.340818E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.73 | backward-compute: 79.79 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 13.67
 iteration  1495000/10000000 | consumed samples:    191360000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648269E+00 | sop loss: 5.329459E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.72 | backward-compute: 79.79 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 18.10
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1495000 | lm loss value: 1.684873E+00 | lm loss PPL: 5.391765E+00 | sop loss value: 5.087993E-02 | sop loss PPL: 1.052197E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1496000/10000000 | consumed samples:    191488000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648028E+00 | sop loss: 5.247464E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.09 | backward-compute: 79.79 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 18.94
 iteration  1497000/10000000 | consumed samples:    191616000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644548E+00 | sop loss: 5.358632E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.05 | backward-compute: 79.78 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 15.09
 iteration  1498000/10000000 | consumed samples:    191744000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.646490E+00 | sop loss: 5.411008E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.33 | backward-compute: 79.82 | backward-params-all-reduce: 14.62 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.87 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.33 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.83 | batch-generator: 14.68
 iteration  1499000/10000000 | consumed samples:    191872000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.650140E+00 | sop loss: 5.362513E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.29 | backward-compute: 79.83 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.50 | batch-generator: 15.43
 iteration  1500000/10000000 | consumed samples:    192000000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647004E+00 | sop loss: 5.467880E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.02 | backward-compute: 79.76 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 16.31
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1500000 | lm loss value: 1.685202E+00 | lm loss PPL: 5.393542E+00 | sop loss value: 6.081175E-02 | sop loss PPL: 1.062699E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 1500000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 1500000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2297.02
 iteration  1501000/10000000 | consumed samples:    192128000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647650E+00 | sop loss: 5.209308E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.15 | backward-compute: 79.76 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 19.33
 iteration  1502000/10000000 | consumed samples:    192256000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647758E+00 | sop loss: 5.320474E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.23 | backward-compute: 79.80 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.51 | batch-generator: 27.27
 iteration  1503000/10000000 | consumed samples:    192384000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648732E+00 | sop loss: 5.345541E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.79 | backward-compute: 79.75 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 15.01
 iteration  1504000/10000000 | consumed samples:    192512000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649110E+00 | sop loss: 5.381939E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.01 | backward-compute: 79.85 | backward-params-all-reduce: 14.53 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.28 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.73 | batch-generator: 16.59
 iteration  1505000/10000000 | consumed samples:    192640000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649122E+00 | sop loss: 5.180045E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.09 | backward-compute: 79.91 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 17.52
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1505000 | lm loss value: 1.669127E+00 | lm loss PPL: 5.307535E+00 | sop loss value: 7.603440E-02 | sop loss PPL: 1.079000E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1506000/10000000 | consumed samples:    192768000 | elapsed time per iteration (ms): 251.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647983E+00 | sop loss: 5.278413E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.70 | backward-compute: 79.83 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 16.99
 iteration  1507000/10000000 | consumed samples:    192896000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647552E+00 | sop loss: 5.339915E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.64 | backward-compute: 79.81 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 14.77
 iteration  1508000/10000000 | consumed samples:    193024000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.646471E+00 | sop loss: 5.343861E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.44 | backward-compute: 79.80 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 14.92
 iteration  1509000/10000000 | consumed samples:    193152000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649210E+00 | sop loss: 5.165993E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.90 | backward-compute: 79.77 | backward-params-all-reduce: 14.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.49 | batch-generator: 14.76
 iteration  1510000/10000000 | consumed samples:    193280000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648568E+00 | sop loss: 5.374225E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.48 | backward-compute: 79.77 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 16.75
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1510000 | lm loss value: 1.705525E+00 | lm loss PPL: 5.504274E+00 | sop loss value: 8.987679E-02 | sop loss PPL: 1.094039E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1511000/10000000 | consumed samples:    193408000 | elapsed time per iteration (ms): 250.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.646800E+00 | sop loss: 5.372546E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.58 | backward-compute: 79.80 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.52
 iteration  1512000/10000000 | consumed samples:    193536000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647456E+00 | sop loss: 5.349478E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.85 | backward-compute: 79.86 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 21.67
 iteration  1513000/10000000 | consumed samples:    193664000 | elapsed time per iteration (ms): 251.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647300E+00 | sop loss: 5.239933E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.26 | backward-compute: 79.86 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 28.92
 iteration  1514000/10000000 | consumed samples:    193792000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.651044E+00 | sop loss: 5.416474E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.51 | backward-compute: 79.88 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 17.54
 iteration  1515000/10000000 | consumed samples:    193920000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.646170E+00 | sop loss: 5.468613E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.24 | backward-compute: 79.73 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.76 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.22 | optimizer: 16.28 | batch-generator: 13.27
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1515000 | lm loss value: 1.677759E+00 | lm loss PPL: 5.353544E+00 | sop loss value: 6.843395E-02 | sop loss PPL: 1.070830E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1516000/10000000 | consumed samples:    194048000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647203E+00 | sop loss: 5.369047E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.06 | backward-compute: 79.78 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 16.95
 iteration  1517000/10000000 | consumed samples:    194176000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645422E+00 | sop loss: 5.332560E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.10 | backward-compute: 79.79 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 16.05
 iteration  1518000/10000000 | consumed samples:    194304000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645197E+00 | sop loss: 5.271138E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.56 | backward-compute: 79.80 | backward-params-all-reduce: 14.37 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.59 | batch-generator: 19.08
 iteration  1519000/10000000 | consumed samples:    194432000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.646526E+00 | sop loss: 5.287846E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.45 | backward-compute: 79.78 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 16.45
 iteration  1520000/10000000 | consumed samples:    194560000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644398E+00 | sop loss: 5.363947E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.61 | backward-compute: 79.76 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 13.28
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1520000 | lm loss value: 1.683684E+00 | lm loss PPL: 5.385361E+00 | sop loss value: 7.496090E-02 | sop loss PPL: 1.077842E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1521000/10000000 | consumed samples:    194688000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647481E+00 | sop loss: 5.294724E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.38 | backward-compute: 79.81 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 14.69
 iteration  1522000/10000000 | consumed samples:    194816000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647386E+00 | sop loss: 5.332667E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.41 | backward-compute: 79.85 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.51 | batch-generator: 15.27
 iteration  1523000/10000000 | consumed samples:    194944000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.646768E+00 | sop loss: 5.298196E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.45 | backward-compute: 79.81 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 14.64
 iteration  1524000/10000000 | consumed samples:    195072000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648191E+00 | sop loss: 5.211187E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.47 | backward-compute: 79.79 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 17.84
 iteration  1525000/10000000 | consumed samples:    195200000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643755E+00 | sop loss: 5.357858E-02 | loss scale: 8192.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.94 | backward-compute: 79.76 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 14.55
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1525000 | lm loss value: 1.721500E+00 | lm loss PPL: 5.592912E+00 | sop loss value: 6.695706E-02 | sop loss PPL: 1.069250E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1526000/10000000 | consumed samples:    195328000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644657E+00 | sop loss: 5.364163E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.51 | backward-compute: 79.79 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 17.05
 iteration  1527000/10000000 | consumed samples:    195456000 | elapsed time per iteration (ms): 246.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648111E+00 | sop loss: 5.391348E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.89 | backward-compute: 79.85 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 15.99
 iteration  1528000/10000000 | consumed samples:    195584000 | elapsed time per iteration (ms): 246.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645268E+00 | sop loss: 5.400323E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.72 | backward-compute: 79.84 | backward-params-all-reduce: 14.37 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.53 | batch-generator: 16.36
 iteration  1529000/10000000 | consumed samples:    195712000 | elapsed time per iteration (ms): 250.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644906E+00 | sop loss: 5.346325E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.84 | backward-compute: 79.84 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 14.89
 iteration  1530000/10000000 | consumed samples:    195840000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.648657E+00 | sop loss: 5.365144E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.82 | backward-compute: 79.86 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 19.21
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1530000 | lm loss value: 1.678053E+00 | lm loss PPL: 5.355118E+00 | sop loss value: 6.826343E-02 | sop loss PPL: 1.070647E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1531000/10000000 | consumed samples:    195968000 | elapsed time per iteration (ms): 251.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643349E+00 | sop loss: 5.261290E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.81 | backward-compute: 79.79 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.41 | batch-generator: 20.45
 iteration  1532000/10000000 | consumed samples:    196096000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647402E+00 | sop loss: 5.235158E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.64 | backward-compute: 79.77 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 15.57
 iteration  1533000/10000000 | consumed samples:    196224000 | elapsed time per iteration (ms): 246.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645280E+00 | sop loss: 5.340615E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.37 | backward-compute: 79.79 | backward-params-all-reduce: 14.34 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.56 | batch-generator: 15.80
 iteration  1534000/10000000 | consumed samples:    196352000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643980E+00 | sop loss: 5.298527E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.15 | backward-compute: 79.78 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 19.05
 iteration  1535000/10000000 | consumed samples:    196480000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645560E+00 | sop loss: 5.374309E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.80 | backward-compute: 79.80 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 19.48
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1535000 | lm loss value: 1.691701E+00 | lm loss PPL: 5.428707E+00 | sop loss value: 7.150187E-02 | sop loss PPL: 1.074120E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1536000/10000000 | consumed samples:    196608000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647545E+00 | sop loss: 5.336656E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.71 | backward-compute: 79.83 | backward-params-all-reduce: 13.89 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 21.83
 iteration  1537000/10000000 | consumed samples:    196736000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643410E+00 | sop loss: 5.355271E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.59 | backward-compute: 79.83 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.51 | batch-generator: 24.22
 iteration  1538000/10000000 | consumed samples:    196864000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645026E+00 | sop loss: 5.351699E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.42 | backward-compute: 79.90 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 19.55
 iteration  1539000/10000000 | consumed samples:    196992000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.646760E+00 | sop loss: 5.222314E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.05 | backward-compute: 79.83 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 17.69
 iteration  1540000/10000000 | consumed samples:    197120000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647998E+00 | sop loss: 5.272802E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.42 | backward-compute: 79.77 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.41 | batch-generator: 15.75
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1540000 | lm loss value: 1.669486E+00 | lm loss PPL: 5.309440E+00 | sop loss value: 8.131991E-02 | sop loss PPL: 1.084718E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1541000/10000000 | consumed samples:    197248000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644518E+00 | sop loss: 5.268582E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.14 | backward-compute: 79.88 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 18.15
 iteration  1542000/10000000 | consumed samples:    197376000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647492E+00 | sop loss: 5.226793E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.51 | backward-compute: 79.80 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 16.77
 iteration  1543000/10000000 | consumed samples:    197504000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643838E+00 | sop loss: 5.351869E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.30 | backward-compute: 79.81 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 13.59
 iteration  1544000/10000000 | consumed samples:    197632000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649073E+00 | sop loss: 5.307084E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.58 | backward-compute: 79.84 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 14.72
 iteration  1545000/10000000 | consumed samples:    197760000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644776E+00 | sop loss: 5.470741E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.54 | backward-compute: 79.84 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.55 | batch-generator: 18.56
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1545000 | lm loss value: 1.652627E+00 | lm loss PPL: 5.220678E+00 | sop loss value: 6.051218E-02 | sop loss PPL: 1.062381E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1546000/10000000 | consumed samples:    197888000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644789E+00 | sop loss: 5.255687E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.21 | backward-compute: 79.77 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.45 | batch-generator: 13.78
 iteration  1547000/10000000 | consumed samples:    198016000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643982E+00 | sop loss: 5.233738E-02 | loss scale: 8192.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.62 | backward-compute: 79.77 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 14.38
 iteration  1548000/10000000 | consumed samples:    198144000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647453E+00 | sop loss: 5.293933E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.47 | backward-compute: 79.83 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 18.13
 iteration  1549000/10000000 | consumed samples:    198272000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645877E+00 | sop loss: 5.318748E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.31 | backward-compute: 79.81 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 15.61
 iteration  1550000/10000000 | consumed samples:    198400000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642618E+00 | sop loss: 5.201515E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.13 | backward-compute: 79.81 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 18.84
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1550000 | lm loss value: 1.718378E+00 | lm loss PPL: 5.575480E+00 | sop loss value: 6.959607E-02 | sop loss PPL: 1.072075E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 1550000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 1550000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2276.10
 iteration  1551000/10000000 | consumed samples:    198528000 | elapsed time per iteration (ms): 252.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645195E+00 | sop loss: 5.337565E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.83 | backward-compute: 79.76 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 14.06
 iteration  1552000/10000000 | consumed samples:    198656000 | elapsed time per iteration (ms): 249.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644392E+00 | sop loss: 5.348759E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.56 | backward-compute: 79.78 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 17.38
 iteration  1553000/10000000 | consumed samples:    198784000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644737E+00 | sop loss: 5.306281E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.35 | backward-compute: 79.82 | backward-params-all-reduce: 14.38 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.57 | batch-generator: 12.31
 iteration  1554000/10000000 | consumed samples:    198912000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647253E+00 | sop loss: 5.366297E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.28 | backward-compute: 79.83 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.50 | batch-generator: 13.59
 iteration  1555000/10000000 | consumed samples:    199040000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644925E+00 | sop loss: 5.404708E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.34 | backward-compute: 79.88 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 13.91
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1555000 | lm loss value: 1.669319E+00 | lm loss PPL: 5.308552E+00 | sop loss value: 7.040936E-02 | sop loss PPL: 1.072947E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1556000/10000000 | consumed samples:    199168000 | elapsed time per iteration (ms): 250.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.646478E+00 | sop loss: 5.281737E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.20 | backward-compute: 79.78 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 17.57
 iteration  1557000/10000000 | consumed samples:    199296000 | elapsed time per iteration (ms): 246.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645741E+00 | sop loss: 5.448249E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.66 | backward-compute: 79.82 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 12.85
 iteration  1558000/10000000 | consumed samples:    199424000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643306E+00 | sop loss: 5.405582E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.78 | backward-compute: 79.79 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.50
 iteration  1559000/10000000 | consumed samples:    199552000 | elapsed time per iteration (ms): 246.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647003E+00 | sop loss: 5.167479E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.01 | backward-compute: 79.82 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 16.09
 iteration  1560000/10000000 | consumed samples:    199680000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641958E+00 | sop loss: 5.176648E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.53 | backward-compute: 79.89 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 16.10
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1560000 | lm loss value: 1.702991E+00 | lm loss PPL: 5.490346E+00 | sop loss value: 5.350375E-02 | sop loss PPL: 1.054961E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1561000/10000000 | consumed samples:    199808000 | elapsed time per iteration (ms): 250.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644130E+00 | sop loss: 5.411364E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.33 | backward-compute: 79.89 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 14.66
 iteration  1562000/10000000 | consumed samples:    199936000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645571E+00 | sop loss: 5.239837E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.13 | backward-compute: 79.82 | backward-params-all-reduce: 14.35 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 15.58
 iteration  1563000/10000000 | consumed samples:    200064000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644668E+00 | sop loss: 5.316971E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.43 | backward-compute: 79.78 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 15.26
 iteration  1564000/10000000 | consumed samples:    200192000 | elapsed time per iteration (ms): 247.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644016E+00 | sop loss: 5.391698E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.44 | backward-compute: 79.77 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 17.77
 iteration  1565000/10000000 | consumed samples:    200320000 | elapsed time per iteration (ms): 246.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.651247E+00 | sop loss: 5.374242E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.29 | backward-compute: 79.73 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.76 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 14.52
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1565000 | lm loss value: 1.685925E+00 | lm loss PPL: 5.397439E+00 | sop loss value: 5.373584E-02 | sop loss PPL: 1.055206E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1566000/10000000 | consumed samples:    200448000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644547E+00 | sop loss: 5.313211E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.29 | backward-compute: 79.74 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 15.96
 iteration  1567000/10000000 | consumed samples:    200576000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643686E+00 | sop loss: 5.367778E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.27 | backward-compute: 79.80 | backward-params-all-reduce: 14.47 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.19 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.60 | batch-generator: 14.95
 iteration  1568000/10000000 | consumed samples:    200704000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645135E+00 | sop loss: 5.366978E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.79 | backward-compute: 79.83 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 13.68
 iteration  1569000/10000000 | consumed samples:    200832000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644365E+00 | sop loss: 5.303005E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.32 | backward-compute: 79.80 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 12.47
 iteration  1570000/10000000 | consumed samples:    200960000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643694E+00 | sop loss: 5.307495E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.61 | backward-compute: 79.90 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 15.40
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1570000 | lm loss value: 1.661615E+00 | lm loss PPL: 5.267813E+00 | sop loss value: 6.685062E-02 | sop loss PPL: 1.069136E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1571000/10000000 | consumed samples:    201088000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645197E+00 | sop loss: 5.443033E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.33 | backward-compute: 79.77 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 14.58
 iteration  1572000/10000000 | consumed samples:    201216000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.646552E+00 | sop loss: 5.332972E-02 | loss scale: 8192.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.21 | backward-compute: 79.77 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.98
 iteration  1573000/10000000 | consumed samples:    201344000 | elapsed time per iteration (ms): 249.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642086E+00 | sop loss: 5.340243E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.08 | backward-compute: 79.78 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 25.23
 iteration  1574000/10000000 | consumed samples:    201472000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644458E+00 | sop loss: 5.346378E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.71 | backward-compute: 79.80 | backward-params-all-reduce: 14.40 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.20 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.60 | batch-generator: 14.80
 iteration  1575000/10000000 | consumed samples:    201600000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644603E+00 | sop loss: 5.290021E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.55 | backward-compute: 79.93 | backward-params-all-reduce: 14.58 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.30 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.78 | batch-generator: 17.77
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1575000 | lm loss value: 1.636073E+00 | lm loss PPL: 5.134965E+00 | sop loss value: 6.921314E-02 | sop loss PPL: 1.071665E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1576000/10000000 | consumed samples:    201728000 | elapsed time per iteration (ms): 251.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644081E+00 | sop loss: 5.277102E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.37 | backward-compute: 79.93 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.20 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.62 | batch-generator: 17.81
 iteration  1577000/10000000 | consumed samples:    201856000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644813E+00 | sop loss: 5.289571E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.31 | backward-compute: 79.83 | backward-params-all-reduce: 14.29 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 15.75
 iteration  1578000/10000000 | consumed samples:    201984000 | elapsed time per iteration (ms): 246.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649125E+00 | sop loss: 5.303836E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.64 | backward-compute: 79.80 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 20.93
 iteration  1579000/10000000 | consumed samples:    202112000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.649311E+00 | sop loss: 5.389288E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.31 | backward-compute: 79.78 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 18.37
 iteration  1580000/10000000 | consumed samples:    202240000 | elapsed time per iteration (ms): 247.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642213E+00 | sop loss: 5.141523E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.68 | backward-compute: 79.80 | backward-params-all-reduce: 14.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.90 | optimizer-unscale-and-check-inf: 2.31 | optimizer-clip-main-grad: 4.41 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.97 | batch-generator: 17.87
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1580000 | lm loss value: 1.684100E+00 | lm loss PPL: 5.387601E+00 | sop loss value: 5.630502E-02 | sop loss PPL: 1.057920E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1581000/10000000 | consumed samples:    202368000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645177E+00 | sop loss: 5.289432E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.95 | backward-compute: 79.84 | backward-params-all-reduce: 15.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.91 | optimizer-unscale-and-check-inf: 2.31 | optimizer-clip-main-grad: 4.44 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 17.02 | batch-generator: 15.54
 iteration  1582000/10000000 | consumed samples:    202496000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645582E+00 | sop loss: 5.416239E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.96 | backward-compute: 79.88 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 20.49
 iteration  1583000/10000000 | consumed samples:    202624000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645516E+00 | sop loss: 5.254004E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.16 | backward-compute: 79.80 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 12.87
 iteration  1584000/10000000 | consumed samples:    202752000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645627E+00 | sop loss: 5.255562E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.93 | backward-compute: 79.80 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 17.59
 iteration  1585000/10000000 | consumed samples:    202880000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643430E+00 | sop loss: 5.158234E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.48 | backward-compute: 79.82 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 17.04
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1585000 | lm loss value: 1.696209E+00 | lm loss PPL: 5.453233E+00 | sop loss value: 6.839285E-02 | sop loss PPL: 1.070786E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1586000/10000000 | consumed samples:    203008000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.646041E+00 | sop loss: 5.418028E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.11 | backward-compute: 79.82 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 15.81
 iteration  1587000/10000000 | consumed samples:    203136000 | elapsed time per iteration (ms): 247.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644596E+00 | sop loss: 5.317942E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.09 | backward-compute: 79.86 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 18.48
 iteration  1588000/10000000 | consumed samples:    203264000 | elapsed time per iteration (ms): 250.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645040E+00 | sop loss: 5.230942E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.84 | backward-compute: 79.83 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 13.89
 iteration  1589000/10000000 | consumed samples:    203392000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643553E+00 | sop loss: 5.293929E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.37 | backward-compute: 79.80 | backward-params-all-reduce: 14.74 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.31 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.79 | batch-generator: 15.23
 iteration  1590000/10000000 | consumed samples:    203520000 | elapsed time per iteration (ms): 249.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641607E+00 | sop loss: 5.369787E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.88 | backward-compute: 79.80 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 18.48
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1590000 | lm loss value: 1.647002E+00 | lm loss PPL: 5.191394E+00 | sop loss value: 5.439762E-02 | sop loss PPL: 1.055904E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1591000/10000000 | consumed samples:    203648000 | elapsed time per iteration (ms): 249.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643388E+00 | sop loss: 5.266231E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.37 | backward-compute: 79.80 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 17.47
 iteration  1592000/10000000 | consumed samples:    203776000 | elapsed time per iteration (ms): 251.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643165E+00 | sop loss: 5.395755E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.85 | backward-compute: 79.82 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 15.49
 iteration  1593000/10000000 | consumed samples:    203904000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645519E+00 | sop loss: 5.499088E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.82 | backward-compute: 79.82 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 13.79
 iteration  1594000/10000000 | consumed samples:    204032000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643568E+00 | sop loss: 5.218032E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.68 | backward-compute: 79.84 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 14.79
 iteration  1595000/10000000 | consumed samples:    204160000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641796E+00 | sop loss: 5.218585E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.47 | backward-compute: 79.79 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 14.47
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1595000 | lm loss value: 1.683054E+00 | lm loss PPL: 5.381965E+00 | sop loss value: 6.725083E-02 | sop loss PPL: 1.069564E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1596000/10000000 | consumed samples:    204288000 | elapsed time per iteration (ms): 251.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645317E+00 | sop loss: 5.351417E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.40 | backward-compute: 79.77 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 14.31
 iteration  1597000/10000000 | consumed samples:    204416000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644007E+00 | sop loss: 5.503176E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.02 | backward-compute: 79.82 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 18.11
 iteration  1598000/10000000 | consumed samples:    204544000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647303E+00 | sop loss: 5.349428E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.55 | backward-compute: 79.79 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 23.10
 iteration  1599000/10000000 | consumed samples:    204672000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642048E+00 | sop loss: 5.267921E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.58 | backward-compute: 79.82 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 17.45
 iteration  1600000/10000000 | consumed samples:    204800000 | elapsed time per iteration (ms): 250.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644122E+00 | sop loss: 5.308750E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.90 | backward-compute: 79.87 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 13.30
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1600000 | lm loss value: 1.700800E+00 | lm loss PPL: 5.478327E+00 | sop loss value: 9.304577E-02 | sop loss PPL: 1.097512E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 1600000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 1600000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2302.78
 iteration  1601000/10000000 | consumed samples:    204928000 | elapsed time per iteration (ms): 254.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.646147E+00 | sop loss: 5.211539E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.22 | backward-compute: 79.79 | backward-params-all-reduce: 14.33 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.19 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.62 | batch-generator: 15.20
 iteration  1602000/10000000 | consumed samples:    205056000 | elapsed time per iteration (ms): 246.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640594E+00 | sop loss: 5.298009E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.75 | backward-compute: 79.82 | backward-params-all-reduce: 14.67 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.30 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.76 | batch-generator: 12.26
 iteration  1603000/10000000 | consumed samples:    205184000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645017E+00 | sop loss: 5.312624E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.58 | backward-compute: 79.83 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.41 | batch-generator: 15.75
 iteration  1604000/10000000 | consumed samples:    205312000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647879E+00 | sop loss: 5.258817E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.34 | backward-compute: 79.80 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 12.83
 iteration  1605000/10000000 | consumed samples:    205440000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643920E+00 | sop loss: 5.178207E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.31 | backward-compute: 79.82 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 13.32
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1605000 | lm loss value: 1.708710E+00 | lm loss PPL: 5.521832E+00 | sop loss value: 6.398853E-02 | sop loss PPL: 1.066080E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1606000/10000000 | consumed samples:    205568000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643762E+00 | sop loss: 5.402625E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.72 | backward-compute: 79.80 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.10
 iteration  1607000/10000000 | consumed samples:    205696000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642696E+00 | sop loss: 5.350290E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.09 | backward-compute: 79.82 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 21.02
 iteration  1608000/10000000 | consumed samples:    205824000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640478E+00 | sop loss: 5.284449E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.12 | backward-compute: 79.86 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 21.50
 iteration  1609000/10000000 | consumed samples:    205952000 | elapsed time per iteration (ms): 250.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644525E+00 | sop loss: 5.226122E-02 | loss scale: 8192.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.52 | backward-compute: 79.77 | backward-params-all-reduce: 14.34 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 18.99
 iteration  1610000/10000000 | consumed samples:    206080000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644762E+00 | sop loss: 5.360398E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.77 | backward-compute: 79.77 | backward-params-all-reduce: 14.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 11.59
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1610000 | lm loss value: 1.677134E+00 | lm loss PPL: 5.350200E+00 | sop loss value: 6.881078E-02 | sop loss PPL: 1.071233E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1611000/10000000 | consumed samples:    206208000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643719E+00 | sop loss: 5.192104E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.48 | backward-compute: 79.85 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 17.39
 iteration  1612000/10000000 | consumed samples:    206336000 | elapsed time per iteration (ms): 246.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644970E+00 | sop loss: 5.423271E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.66 | backward-compute: 79.89 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 14.91
 iteration  1613000/10000000 | consumed samples:    206464000 | elapsed time per iteration (ms): 250.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644508E+00 | sop loss: 5.357919E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.40 | backward-compute: 79.82 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 13.24
 iteration  1614000/10000000 | consumed samples:    206592000 | elapsed time per iteration (ms): 246.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.647660E+00 | sop loss: 5.226020E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.74 | backward-compute: 79.83 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 16.17
 iteration  1615000/10000000 | consumed samples:    206720000 | elapsed time per iteration (ms): 247.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642229E+00 | sop loss: 5.440388E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.10 | backward-compute: 79.80 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.45 | batch-generator: 13.92
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1615000 | lm loss value: 1.709474E+00 | lm loss PPL: 5.526052E+00 | sop loss value: 6.602257E-02 | sop loss PPL: 1.068251E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1616000/10000000 | consumed samples:    206848000 | elapsed time per iteration (ms): 251.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644152E+00 | sop loss: 5.233912E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.22 | backward-compute: 79.81 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 14.12
 iteration  1617000/10000000 | consumed samples:    206976000 | elapsed time per iteration (ms): 246.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645070E+00 | sop loss: 5.366254E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.58 | backward-compute: 79.87 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 17.15
 iteration  1618000/10000000 | consumed samples:    207104000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643240E+00 | sop loss: 5.298366E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.75 | backward-compute: 79.84 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 16.30
 iteration  1619000/10000000 | consumed samples:    207232000 | elapsed time per iteration (ms): 245.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645463E+00 | sop loss: 5.265134E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.40 | backward-compute: 79.81 | backward-params-all-reduce: 14.27 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 15.85
 iteration  1620000/10000000 | consumed samples:    207360000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644274E+00 | sop loss: 5.366661E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.69 | backward-compute: 79.82 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 15.70
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1620000 | lm loss value: 1.664123E+00 | lm loss PPL: 5.281041E+00 | sop loss value: 6.564450E-02 | sop loss PPL: 1.067847E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1621000/10000000 | consumed samples:    207488000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643698E+00 | sop loss: 5.253497E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.54 | backward-compute: 79.84 | backward-params-all-reduce: 14.39 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.60 | batch-generator: 16.88
 iteration  1622000/10000000 | consumed samples:    207616000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644454E+00 | sop loss: 5.244770E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.56 | backward-compute: 79.83 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 15.36
 iteration  1623000/10000000 | consumed samples:    207744000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643148E+00 | sop loss: 5.212428E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.20 | backward-compute: 79.77 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.80
 iteration  1624000/10000000 | consumed samples:    207872000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639562E+00 | sop loss: 5.428286E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.79 | backward-compute: 79.78 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 13.33
 iteration  1625000/10000000 | consumed samples:    208000000 | elapsed time per iteration (ms): 250.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644002E+00 | sop loss: 5.338922E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.88 | backward-compute: 79.77 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.54
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1625000 | lm loss value: 1.628781E+00 | lm loss PPL: 5.097655E+00 | sop loss value: 5.051146E-02 | sop loss PPL: 1.051809E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1626000/10000000 | consumed samples:    208128000 | elapsed time per iteration (ms): 250.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.646428E+00 | sop loss: 5.279761E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.58 | backward-compute: 79.83 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 17.74
 iteration  1627000/10000000 | consumed samples:    208256000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644044E+00 | sop loss: 5.382908E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.25 | backward-compute: 79.82 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 16.60
 iteration  1628000/10000000 | consumed samples:    208384000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643460E+00 | sop loss: 5.255240E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.76 | backward-compute: 79.85 | backward-params-all-reduce: 14.64 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.29 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.75 | batch-generator: 14.65
 iteration  1629000/10000000 | consumed samples:    208512000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641391E+00 | sop loss: 5.249139E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.31 | backward-compute: 79.79 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.56 | batch-generator: 15.02
 iteration  1630000/10000000 | consumed samples:    208640000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645235E+00 | sop loss: 5.258632E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.16 | backward-compute: 79.80 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 15.75
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1630000 | lm loss value: 1.701743E+00 | lm loss PPL: 5.483499E+00 | sop loss value: 7.573943E-02 | sop loss PPL: 1.078681E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1631000/10000000 | consumed samples:    208768000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643580E+00 | sop loss: 5.262000E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.23 | backward-compute: 79.79 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 14.08
 iteration  1632000/10000000 | consumed samples:    208896000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644347E+00 | sop loss: 5.205972E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.12 | backward-compute: 79.76 | backward-params-all-reduce: 14.37 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.20 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.62 | batch-generator: 12.78
 iteration  1633000/10000000 | consumed samples:    209024000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642575E+00 | sop loss: 5.327202E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.78 | backward-compute: 79.75 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.55
 iteration  1634000/10000000 | consumed samples:    209152000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644417E+00 | sop loss: 5.306516E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.21 | backward-compute: 79.82 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 21.69
 iteration  1635000/10000000 | consumed samples:    209280000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643622E+00 | sop loss: 5.125351E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.68 | backward-compute: 79.96 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.55 | batch-generator: 14.16
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1635000 | lm loss value: 1.719205E+00 | lm loss PPL: 5.580093E+00 | sop loss value: 5.431067E-02 | sop loss PPL: 1.055813E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1636000/10000000 | consumed samples:    209408000 | elapsed time per iteration (ms): 251.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642396E+00 | sop loss: 5.402658E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.12 | backward-compute: 79.80 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 15.74
 iteration  1637000/10000000 | consumed samples:    209536000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644568E+00 | sop loss: 5.269732E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.09 | backward-compute: 79.80 | backward-params-all-reduce: 14.34 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.55 | batch-generator: 17.00
 iteration  1638000/10000000 | consumed samples:    209664000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644302E+00 | sop loss: 5.393584E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.94 | backward-compute: 79.87 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 16.53
 iteration  1639000/10000000 | consumed samples:    209792000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640565E+00 | sop loss: 5.382829E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.11 | backward-compute: 79.83 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 20.04
 iteration  1640000/10000000 | consumed samples:    209920000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642499E+00 | sop loss: 5.295330E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.70 | backward-compute: 79.86 | backward-params-all-reduce: 13.90 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 14.77
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1640000 | lm loss value: 1.671329E+00 | lm loss PPL: 5.319231E+00 | sop loss value: 6.550263E-02 | sop loss PPL: 1.067696E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1641000/10000000 | consumed samples:    210048000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642798E+00 | sop loss: 5.303148E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.40 | backward-compute: 79.83 | backward-params-all-reduce: 14.38 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.21 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.64 | batch-generator: 16.40
 iteration  1642000/10000000 | consumed samples:    210176000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644235E+00 | sop loss: 5.140763E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.67 | backward-compute: 79.82 | backward-params-all-reduce: 13.92 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 18.66
 iteration  1643000/10000000 | consumed samples:    210304000 | elapsed time per iteration (ms): 251.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639480E+00 | sop loss: 5.197508E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.37 | backward-compute: 79.85 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 14.34
 iteration  1644000/10000000 | consumed samples:    210432000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642916E+00 | sop loss: 5.308491E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.48 | backward-compute: 79.84 | backward-params-all-reduce: 14.37 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.19 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.61 | batch-generator: 15.97
 iteration  1645000/10000000 | consumed samples:    210560000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645160E+00 | sop loss: 5.247316E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.49 | backward-compute: 79.89 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 16.89
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1645000 | lm loss value: 1.694731E+00 | lm loss PPL: 5.445179E+00 | sop loss value: 8.162969E-02 | sop loss PPL: 1.085054E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1646000/10000000 | consumed samples:    210688000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643189E+00 | sop loss: 5.198399E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.11 | backward-compute: 79.76 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 16.54
 iteration  1647000/10000000 | consumed samples:    210816000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643597E+00 | sop loss: 5.271602E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.12 | backward-compute: 79.77 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 14.84
 iteration  1648000/10000000 | consumed samples:    210944000 | elapsed time per iteration (ms): 250.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640177E+00 | sop loss: 5.330624E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.37 | backward-compute: 79.83 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 13.15
 iteration  1649000/10000000 | consumed samples:    211072000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641082E+00 | sop loss: 5.253609E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.30 | backward-compute: 79.84 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 14.74
 iteration  1650000/10000000 | consumed samples:    211200000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643853E+00 | sop loss: 5.302081E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.02 | backward-compute: 79.92 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 14.27
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1650000 | lm loss value: 1.680878E+00 | lm loss PPL: 5.370271E+00 | sop loss value: 5.823142E-02 | sop loss PPL: 1.059960E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 1650000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 1650000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2310.04
 iteration  1651000/10000000 | consumed samples:    211328000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642120E+00 | sop loss: 5.240501E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.53 | backward-compute: 79.94 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 17.14
 iteration  1652000/10000000 | consumed samples:    211456000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641985E+00 | sop loss: 5.160375E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.42 | backward-compute: 79.90 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.53 | batch-generator: 14.44
 iteration  1653000/10000000 | consumed samples:    211584000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641539E+00 | sop loss: 5.359043E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.41 | backward-compute: 79.86 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 18.51
 iteration  1654000/10000000 | consumed samples:    211712000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641200E+00 | sop loss: 5.378431E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.26 | backward-compute: 79.85 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 18.64
 iteration  1655000/10000000 | consumed samples:    211840000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643595E+00 | sop loss: 5.387045E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.31 | backward-compute: 79.79 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 16.73
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1655000 | lm loss value: 1.671739E+00 | lm loss PPL: 5.321413E+00 | sop loss value: 6.605460E-02 | sop loss PPL: 1.068285E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1656000/10000000 | consumed samples:    211968000 | elapsed time per iteration (ms): 251.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641009E+00 | sop loss: 5.331609E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.23 | backward-compute: 79.82 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 21.86
 iteration  1657000/10000000 | consumed samples:    212096000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643361E+00 | sop loss: 5.341166E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.36 | backward-compute: 79.82 | backward-params-all-reduce: 14.47 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.22 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.65 | batch-generator: 12.08
 iteration  1658000/10000000 | consumed samples:    212224000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641794E+00 | sop loss: 5.296149E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.61 | backward-compute: 79.82 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 16.08
 iteration  1659000/10000000 | consumed samples:    212352000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642565E+00 | sop loss: 5.300303E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.13 | backward-compute: 79.77 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.85
 iteration  1660000/10000000 | consumed samples:    212480000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643032E+00 | sop loss: 5.302586E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.03 | backward-compute: 79.80 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 12.66
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1660000 | lm loss value: 1.646678E+00 | lm loss PPL: 5.189712E+00 | sop loss value: 6.511651E-02 | sop loss PPL: 1.067283E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1661000/10000000 | consumed samples:    212608000 | elapsed time per iteration (ms): 250.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642170E+00 | sop loss: 5.385336E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.65 | backward-compute: 79.83 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 20.41
 iteration  1662000/10000000 | consumed samples:    212736000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643662E+00 | sop loss: 5.370498E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.70 | backward-compute: 79.81 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 13.34
 iteration  1663000/10000000 | consumed samples:    212864000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638518E+00 | sop loss: 5.268979E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.69 | backward-compute: 79.85 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 11.19
 iteration  1664000/10000000 | consumed samples:    212992000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639094E+00 | sop loss: 5.470090E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.26 | backward-compute: 79.77 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 13.35
 iteration  1665000/10000000 | consumed samples:    213120000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644355E+00 | sop loss: 5.336578E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.35 | backward-compute: 79.87 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.54 | batch-generator: 19.02
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1665000 | lm loss value: 1.676583E+00 | lm loss PPL: 5.347252E+00 | sop loss value: 7.152294E-02 | sop loss PPL: 1.074143E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1666000/10000000 | consumed samples:    213248000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641402E+00 | sop loss: 5.043802E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.44 | backward-compute: 79.82 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 17.16
 iteration  1667000/10000000 | consumed samples:    213376000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643260E+00 | sop loss: 5.281730E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.67 | backward-compute: 79.82 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.47 | batch-generator: 17.92
 iteration  1668000/10000000 | consumed samples:    213504000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640598E+00 | sop loss: 5.301589E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.88 | backward-compute: 79.81 | backward-params-all-reduce: 13.87 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 19.40
 iteration  1669000/10000000 | consumed samples:    213632000 | elapsed time per iteration (ms): 251.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643720E+00 | sop loss: 5.266408E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.04 | backward-compute: 79.79 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 18.49
 iteration  1670000/10000000 | consumed samples:    213760000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643956E+00 | sop loss: 5.448104E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.43 | backward-compute: 79.80 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.20 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.62 | batch-generator: 17.62
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1670000 | lm loss value: 1.714676E+00 | lm loss PPL: 5.554875E+00 | sop loss value: 4.687237E-02 | sop loss PPL: 1.047988E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1671000/10000000 | consumed samples:    213888000 | elapsed time per iteration (ms): 250.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643915E+00 | sop loss: 5.243700E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.63 | backward-compute: 79.78 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 16.51
 iteration  1672000/10000000 | consumed samples:    214016000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642904E+00 | sop loss: 5.404397E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.29 | backward-compute: 79.79 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 17.10
 iteration  1673000/10000000 | consumed samples:    214144000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638429E+00 | sop loss: 5.313981E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.10 | backward-compute: 79.78 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 16.33
 iteration  1674000/10000000 | consumed samples:    214272000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639738E+00 | sop loss: 5.234609E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.71 | backward-compute: 79.82 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.63
 iteration  1675000/10000000 | consumed samples:    214400000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641776E+00 | sop loss: 5.467658E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.32 | backward-compute: 79.77 | backward-params-all-reduce: 14.62 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.20 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.63 | batch-generator: 14.22
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1675000 | lm loss value: 1.671789E+00 | lm loss PPL: 5.321678E+00 | sop loss value: 6.158615E-02 | sop loss PPL: 1.063522E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1676000/10000000 | consumed samples:    214528000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638292E+00 | sop loss: 5.309036E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.76 | backward-compute: 79.76 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 15.47
 iteration  1677000/10000000 | consumed samples:    214656000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639954E+00 | sop loss: 5.452734E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.69 | backward-compute: 79.89 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.43 | batch-generator: 13.53
 iteration  1678000/10000000 | consumed samples:    214784000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641151E+00 | sop loss: 5.375687E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.98 | backward-compute: 79.85 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 17.58
 iteration  1679000/10000000 | consumed samples:    214912000 | elapsed time per iteration (ms): 249.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640660E+00 | sop loss: 5.345827E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.33 | backward-compute: 79.80 | backward-params-all-reduce: 13.91 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.42 | batch-generator: 16.64
 iteration  1680000/10000000 | consumed samples:    215040000 | elapsed time per iteration (ms): 246.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640272E+00 | sop loss: 5.339620E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.13 | backward-compute: 79.76 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.69
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1680000 | lm loss value: 1.666439E+00 | lm loss PPL: 5.293284E+00 | sop loss value: 5.613428E-02 | sop loss PPL: 1.057740E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1681000/10000000 | consumed samples:    215168000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641975E+00 | sop loss: 5.290118E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.71 | backward-compute: 79.82 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 19.34
 iteration  1682000/10000000 | consumed samples:    215296000 | elapsed time per iteration (ms): 251.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640845E+00 | sop loss: 5.229501E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.84 | backward-compute: 79.78 | backward-params-all-reduce: 13.91 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 29.96
 iteration  1683000/10000000 | consumed samples:    215424000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640285E+00 | sop loss: 5.255670E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.30 | backward-compute: 79.79 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 16.65
 iteration  1684000/10000000 | consumed samples:    215552000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640033E+00 | sop loss: 5.351024E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.45 | backward-compute: 79.83 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 20.59
 iteration  1685000/10000000 | consumed samples:    215680000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638859E+00 | sop loss: 5.294279E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.16 | backward-compute: 79.84 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 15.80
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1685000 | lm loss value: 1.724769E+00 | lm loss PPL: 5.611223E+00 | sop loss value: 6.238854E-02 | sop loss PPL: 1.064376E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1686000/10000000 | consumed samples:    215808000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639078E+00 | sop loss: 5.462548E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.07 | backward-compute: 79.83 | backward-params-all-reduce: 14.29 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.56 | batch-generator: 17.12
 iteration  1687000/10000000 | consumed samples:    215936000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643562E+00 | sop loss: 5.409910E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.91 | backward-compute: 79.82 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 13.11
 iteration  1688000/10000000 | consumed samples:    216064000 | elapsed time per iteration (ms): 245.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639053E+00 | sop loss: 5.269118E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.29 | backward-compute: 79.81 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.51 | batch-generator: 13.49
 iteration  1689000/10000000 | consumed samples:    216192000 | elapsed time per iteration (ms): 250.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641269E+00 | sop loss: 5.215478E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.27 | backward-compute: 79.74 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 13.75
 iteration  1690000/10000000 | consumed samples:    216320000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642305E+00 | sop loss: 5.320657E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.11 | backward-compute: 79.75 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 13.86
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1690000 | lm loss value: 1.696363E+00 | lm loss PPL: 5.454074E+00 | sop loss value: 7.791594E-02 | sop loss PPL: 1.081032E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1691000/10000000 | consumed samples:    216448000 | elapsed time per iteration (ms): 250.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641063E+00 | sop loss: 5.391185E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.85 | backward-compute: 79.79 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 14.99
 iteration  1692000/10000000 | consumed samples:    216576000 | elapsed time per iteration (ms): 246.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640683E+00 | sop loss: 5.324036E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.13 | backward-compute: 79.86 | backward-params-all-reduce: 14.52 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.24 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.69 | batch-generator: 16.36
 iteration  1693000/10000000 | consumed samples:    216704000 | elapsed time per iteration (ms): 251.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639647E+00 | sop loss: 5.263519E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.67 | backward-compute: 79.82 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 16.78
 iteration  1694000/10000000 | consumed samples:    216832000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641854E+00 | sop loss: 5.067702E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.21 | backward-compute: 79.82 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 15.17
 iteration  1695000/10000000 | consumed samples:    216960000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.645699E+00 | sop loss: 5.196854E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.06 | backward-compute: 79.84 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 12.57
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1695000 | lm loss value: 1.681002E+00 | lm loss PPL: 5.370936E+00 | sop loss value: 6.284638E-02 | sop loss PPL: 1.064863E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1696000/10000000 | consumed samples:    217088000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642912E+00 | sop loss: 5.378057E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.39 | backward-compute: 79.83 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 18.57
 iteration  1697000/10000000 | consumed samples:    217216000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642536E+00 | sop loss: 5.362915E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.44 | backward-compute: 79.86 | backward-params-all-reduce: 14.34 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.20 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.64 | batch-generator: 26.41
 iteration  1698000/10000000 | consumed samples:    217344000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642254E+00 | sop loss: 5.202748E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.90 | backward-compute: 79.79 | backward-params-all-reduce: 14.31 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 17.11
 iteration  1699000/10000000 | consumed samples:    217472000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640018E+00 | sop loss: 5.157659E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.72 | backward-compute: 79.75 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 17.95
 iteration  1700000/10000000 | consumed samples:    217600000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640886E+00 | sop loss: 5.252513E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.57 | backward-compute: 79.80 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 14.94
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1700000 | lm loss value: 1.706812E+00 | lm loss PPL: 5.511362E+00 | sop loss value: 4.272885E-02 | sop loss PPL: 1.043655E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 1700000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 1700000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2280.01
 iteration  1701000/10000000 | consumed samples:    217728000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642810E+00 | sop loss: 5.196528E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.03 | backward-compute: 79.83 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 16.42
 iteration  1702000/10000000 | consumed samples:    217856000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642288E+00 | sop loss: 5.322670E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.69 | backward-compute: 79.82 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 13.63
 iteration  1703000/10000000 | consumed samples:    217984000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641519E+00 | sop loss: 5.112576E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.46 | backward-compute: 79.80 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.04
 iteration  1704000/10000000 | consumed samples:    218112000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643406E+00 | sop loss: 5.478188E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.44 | backward-compute: 79.77 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 20.07
 iteration  1705000/10000000 | consumed samples:    218240000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641732E+00 | sop loss: 5.328456E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.82 | backward-compute: 79.78 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 15.35
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1705000 | lm loss value: 1.712137E+00 | lm loss PPL: 5.540792E+00 | sop loss value: 7.644930E-02 | sop loss PPL: 1.079447E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1706000/10000000 | consumed samples:    218368000 | elapsed time per iteration (ms): 251.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640592E+00 | sop loss: 5.224244E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.23 | backward-compute: 79.82 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.76 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.29 | batch-generator: 17.59
 iteration  1707000/10000000 | consumed samples:    218496000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639312E+00 | sop loss: 5.261364E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.08 | backward-compute: 79.78 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.76
 iteration  1708000/10000000 | consumed samples:    218624000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642059E+00 | sop loss: 5.232592E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.52 | backward-compute: 79.91 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.48 | batch-generator: 14.61
 iteration  1709000/10000000 | consumed samples:    218752000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638289E+00 | sop loss: 5.388694E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.10 | backward-compute: 79.87 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 18.30
 iteration  1710000/10000000 | consumed samples:    218880000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639665E+00 | sop loss: 5.455238E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.58 | backward-compute: 79.82 | backward-params-all-reduce: 14.29 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 12.96
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1710000 | lm loss value: 1.663622E+00 | lm loss PPL: 5.278392E+00 | sop loss value: 6.767088E-02 | sop loss PPL: 1.070013E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1711000/10000000 | consumed samples:    219008000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640218E+00 | sop loss: 5.246517E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.70 | backward-compute: 79.93 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 15.84
 iteration  1712000/10000000 | consumed samples:    219136000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639197E+00 | sop loss: 5.411759E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.16 | backward-compute: 79.89 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 16.15
 iteration  1713000/10000000 | consumed samples:    219264000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637038E+00 | sop loss: 5.192764E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.21 | backward-compute: 79.82 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.54 | batch-generator: 17.31
 iteration  1714000/10000000 | consumed samples:    219392000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640132E+00 | sop loss: 5.320988E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.22 | backward-compute: 79.78 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.88
 iteration  1715000/10000000 | consumed samples:    219520000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641978E+00 | sop loss: 5.260664E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.51 | backward-compute: 79.78 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.41
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1715000 | lm loss value: 1.708866E+00 | lm loss PPL: 5.522696E+00 | sop loss value: 6.568170E-02 | sop loss PPL: 1.067887E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1716000/10000000 | consumed samples:    219648000 | elapsed time per iteration (ms): 250.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640182E+00 | sop loss: 5.314723E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.04 | backward-compute: 79.84 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 15.85
 iteration  1717000/10000000 | consumed samples:    219776000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637793E+00 | sop loss: 5.247678E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.91 | backward-compute: 79.92 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 14.98
 iteration  1718000/10000000 | consumed samples:    219904000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640263E+00 | sop loss: 5.311960E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.02 | backward-compute: 79.83 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 15.10
 iteration  1719000/10000000 | consumed samples:    220032000 | elapsed time per iteration (ms): 246.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639986E+00 | sop loss: 5.326706E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.93 | backward-compute: 79.81 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 17.27
 iteration  1720000/10000000 | consumed samples:    220160000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639601E+00 | sop loss: 5.290993E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.74 | backward-compute: 79.78 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 16.35
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1720000 | lm loss value: 1.700744E+00 | lm loss PPL: 5.478020E+00 | sop loss value: 5.534339E-02 | sop loss PPL: 1.056903E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1721000/10000000 | consumed samples:    220288000 | elapsed time per iteration (ms): 252.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642203E+00 | sop loss: 5.485090E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.16 | backward-compute: 79.76 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 15.58
 iteration  1722000/10000000 | consumed samples:    220416000 | elapsed time per iteration (ms): 245.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639767E+00 | sop loss: 5.221915E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.26 | backward-compute: 79.91 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 14.92
 iteration  1723000/10000000 | consumed samples:    220544000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638480E+00 | sop loss: 5.126512E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.14 | backward-compute: 79.84 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.54 | batch-generator: 15.84
 iteration  1724000/10000000 | consumed samples:    220672000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.644190E+00 | sop loss: 5.414926E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.05 | backward-compute: 79.82 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 12.16
 iteration  1725000/10000000 | consumed samples:    220800000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641480E+00 | sop loss: 5.216423E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.55 | backward-compute: 79.82 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 16.00
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1725000 | lm loss value: 1.705661E+00 | lm loss PPL: 5.505026E+00 | sop loss value: 5.245085E-02 | sop loss PPL: 1.053851E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1726000/10000000 | consumed samples:    220928000 | elapsed time per iteration (ms): 251.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639979E+00 | sop loss: 5.291903E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.65 | backward-compute: 79.83 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.49 | batch-generator: 23.78
 iteration  1727000/10000000 | consumed samples:    221056000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640073E+00 | sop loss: 5.228737E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.38 | backward-compute: 79.86 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.50
 iteration  1728000/10000000 | consumed samples:    221184000 | elapsed time per iteration (ms): 250.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641933E+00 | sop loss: 5.275612E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.86 | backward-compute: 79.79 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 17.03
 iteration  1729000/10000000 | consumed samples:    221312000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640448E+00 | sop loss: 5.309653E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.34 | backward-compute: 79.80 | backward-params-all-reduce: 14.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.56 | batch-generator: 14.49
 iteration  1730000/10000000 | consumed samples:    221440000 | elapsed time per iteration (ms): 250.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638935E+00 | sop loss: 5.470443E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.43 | backward-compute: 79.83 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 11.82
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1730000 | lm loss value: 1.661044E+00 | lm loss PPL: 5.264805E+00 | sop loss value: 9.407739E-02 | sop loss PPL: 1.098645E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1731000/10000000 | consumed samples:    221568000 | elapsed time per iteration (ms): 251.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641266E+00 | sop loss: 5.185377E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.32 | backward-compute: 79.87 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 15.80
 iteration  1732000/10000000 | consumed samples:    221696000 | elapsed time per iteration (ms): 245.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639130E+00 | sop loss: 5.174033E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.00 | backward-compute: 79.88 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.53 | batch-generator: 18.32
 iteration  1733000/10000000 | consumed samples:    221824000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.643792E+00 | sop loss: 5.273042E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.03 | backward-compute: 79.77 | backward-params-all-reduce: 14.76 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.87 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.30 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.78 | batch-generator: 17.10
 iteration  1734000/10000000 | consumed samples:    221952000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642271E+00 | sop loss: 5.186586E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.34 | backward-compute: 79.85 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.53 | batch-generator: 20.44
 iteration  1735000/10000000 | consumed samples:    222080000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640937E+00 | sop loss: 5.224474E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.22 | backward-compute: 79.78 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.42 | batch-generator: 19.22
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1735000 | lm loss value: 1.682731E+00 | lm loss PPL: 5.380230E+00 | sop loss value: 5.580884E-02 | sop loss PPL: 1.057396E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1736000/10000000 | consumed samples:    222208000 | elapsed time per iteration (ms): 250.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639395E+00 | sop loss: 5.229589E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.29 | backward-compute: 79.82 | backward-params-all-reduce: 14.58 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.27 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.74 | batch-generator: 16.67
 iteration  1737000/10000000 | consumed samples:    222336000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636881E+00 | sop loss: 5.349570E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.32 | backward-compute: 79.88 | backward-params-all-reduce: 14.49 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.22 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.64 | batch-generator: 19.35
 iteration  1738000/10000000 | consumed samples:    222464000 | elapsed time per iteration (ms): 246.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638601E+00 | sop loss: 5.279657E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.06 | backward-compute: 79.89 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.57 | batch-generator: 16.12
 iteration  1739000/10000000 | consumed samples:    222592000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640312E+00 | sop loss: 5.170223E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.31 | backward-compute: 79.81 | backward-params-all-reduce: 14.73 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.87 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.31 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.79 | batch-generator: 17.03
 iteration  1740000/10000000 | consumed samples:    222720000 | elapsed time per iteration (ms): 245.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638639E+00 | sop loss: 5.318335E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.50 | backward-compute: 79.84 | backward-params-all-reduce: 14.39 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.59 | batch-generator: 16.69
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1740000 | lm loss value: 1.675632E+00 | lm loss PPL: 5.342170E+00 | sop loss value: 5.717132E-02 | sop loss PPL: 1.058837E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1741000/10000000 | consumed samples:    222848000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640071E+00 | sop loss: 5.329113E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.46 | backward-compute: 79.84 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 18.72
 iteration  1742000/10000000 | consumed samples:    222976000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640224E+00 | sop loss: 5.249491E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.65 | backward-compute: 79.78 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 15.93
 iteration  1743000/10000000 | consumed samples:    223104000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640972E+00 | sop loss: 5.315457E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.80 | backward-compute: 79.81 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 14.72
 iteration  1744000/10000000 | consumed samples:    223232000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636915E+00 | sop loss: 5.247343E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.88 | backward-compute: 79.96 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 18.10
 iteration  1745000/10000000 | consumed samples:    223360000 | elapsed time per iteration (ms): 251.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639356E+00 | sop loss: 5.187218E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.92 | backward-compute: 79.82 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 15.77
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1745000 | lm loss value: 1.712812E+00 | lm loss PPL: 5.544532E+00 | sop loss value: 5.251022E-02 | sop loss PPL: 1.053913E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1746000/10000000 | consumed samples:    223488000 | elapsed time per iteration (ms): 252.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638502E+00 | sop loss: 5.305145E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.60 | backward-compute: 79.81 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 18.85
 iteration  1747000/10000000 | consumed samples:    223616000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640762E+00 | sop loss: 5.296879E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.79 | backward-compute: 79.81 | backward-params-all-reduce: 14.46 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.59 | batch-generator: 17.28
 iteration  1748000/10000000 | consumed samples:    223744000 | elapsed time per iteration (ms): 246.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639975E+00 | sop loss: 5.305648E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.74 | backward-compute: 79.80 | backward-params-all-reduce: 14.75 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.33 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.82 | batch-generator: 13.65
 iteration  1749000/10000000 | consumed samples:    223872000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635671E+00 | sop loss: 5.236107E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.94 | backward-compute: 79.87 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 17.19
 iteration  1750000/10000000 | consumed samples:    224000000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641790E+00 | sop loss: 5.197286E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.29 | backward-compute: 79.81 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 17.36
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1750000 | lm loss value: 1.672936E+00 | lm loss PPL: 5.327788E+00 | sop loss value: 8.128420E-02 | sop loss PPL: 1.084679E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 1750000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 1750000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2305.87
 iteration  1751000/10000000 | consumed samples:    224128000 | elapsed time per iteration (ms): 251.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640875E+00 | sop loss: 5.109964E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.76 | backward-compute: 79.81 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 17.61
 iteration  1752000/10000000 | consumed samples:    224256000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642890E+00 | sop loss: 5.303799E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.47 | backward-compute: 79.90 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 17.38
 iteration  1753000/10000000 | consumed samples:    224384000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640939E+00 | sop loss: 5.222322E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.22 | backward-compute: 79.89 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 16.48
 iteration  1754000/10000000 | consumed samples:    224512000 | elapsed time per iteration (ms): 246.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641050E+00 | sop loss: 5.243249E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.66 | backward-compute: 79.84 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 15.97
 iteration  1755000/10000000 | consumed samples:    224640000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639443E+00 | sop loss: 5.138429E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.26 | backward-compute: 79.85 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 22.66
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1755000 | lm loss value: 1.654001E+00 | lm loss PPL: 5.227856E+00 | sop loss value: 4.834109E-02 | sop loss PPL: 1.049529E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1756000/10000000 | consumed samples:    224768000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636388E+00 | sop loss: 5.150587E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.47 | backward-compute: 79.78 | backward-params-all-reduce: 14.35 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.59 | batch-generator: 19.23
 iteration  1757000/10000000 | consumed samples:    224896000 | elapsed time per iteration (ms): 246.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638982E+00 | sop loss: 5.333775E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.91 | backward-compute: 79.81 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 19.92
 iteration  1758000/10000000 | consumed samples:    225024000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637713E+00 | sop loss: 5.284141E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.27 | backward-compute: 79.84 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 14.88
 iteration  1759000/10000000 | consumed samples:    225152000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642919E+00 | sop loss: 5.089594E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.91 | backward-compute: 79.90 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 15.66
 iteration  1760000/10000000 | consumed samples:    225280000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640051E+00 | sop loss: 5.218513E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.70 | backward-compute: 79.80 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.48 | batch-generator: 17.39
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1760000 | lm loss value: 1.643809E+00 | lm loss PPL: 5.174842E+00 | sop loss value: 5.791833E-02 | sop loss PPL: 1.059628E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1761000/10000000 | consumed samples:    225408000 | elapsed time per iteration (ms): 250.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639331E+00 | sop loss: 5.095131E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.30 | backward-compute: 79.83 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 18.09
 iteration  1762000/10000000 | consumed samples:    225536000 | elapsed time per iteration (ms): 245.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637872E+00 | sop loss: 5.234743E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.16 | backward-compute: 79.81 | backward-params-all-reduce: 14.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 11.77
 iteration  1763000/10000000 | consumed samples:    225664000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642251E+00 | sop loss: 5.308631E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.60 | backward-compute: 79.81 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 14.02
 iteration  1764000/10000000 | consumed samples:    225792000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640011E+00 | sop loss: 5.173445E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.25 | backward-compute: 79.81 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 16.41
 iteration  1765000/10000000 | consumed samples:    225920000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640066E+00 | sop loss: 5.180242E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.83 | backward-compute: 79.84 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.27
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1765000 | lm loss value: 1.696042E+00 | lm loss PPL: 5.452327E+00 | sop loss value: 8.705778E-02 | sop loss PPL: 1.090960E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1766000/10000000 | consumed samples:    226048000 | elapsed time per iteration (ms): 250.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639088E+00 | sop loss: 5.237732E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.63 | backward-compute: 79.79 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 13.69
 iteration  1767000/10000000 | consumed samples:    226176000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640505E+00 | sop loss: 5.320221E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.23 | backward-compute: 79.76 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 15.19
 iteration  1768000/10000000 | consumed samples:    226304000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639010E+00 | sop loss: 5.279568E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.69 | backward-compute: 79.77 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 17.79
 iteration  1769000/10000000 | consumed samples:    226432000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639628E+00 | sop loss: 5.226879E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.35 | backward-compute: 79.78 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 13.09
 iteration  1770000/10000000 | consumed samples:    226560000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640560E+00 | sop loss: 5.297802E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.47 | backward-compute: 79.81 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 12.61
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1770000 | lm loss value: 1.692725E+00 | lm loss PPL: 5.434268E+00 | sop loss value: 5.294070E-02 | sop loss PPL: 1.054367E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1771000/10000000 | consumed samples:    226688000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639921E+00 | sop loss: 5.190392E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.04 | backward-compute: 79.95 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 16.18
 iteration  1772000/10000000 | consumed samples:    226816000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638250E+00 | sop loss: 5.242441E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.89 | backward-compute: 79.85 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 14.33
 iteration  1773000/10000000 | consumed samples:    226944000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639990E+00 | sop loss: 5.224667E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.16 | backward-compute: 79.83 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 13.21
 iteration  1774000/10000000 | consumed samples:    227072000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640906E+00 | sop loss: 5.345249E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.65 | backward-compute: 79.83 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.54
 iteration  1775000/10000000 | consumed samples:    227200000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638589E+00 | sop loss: 5.242946E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.02 | backward-compute: 79.83 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 14.86
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1775000 | lm loss value: 1.694586E+00 | lm loss PPL: 5.444390E+00 | sop loss value: 7.609364E-02 | sop loss PPL: 1.079064E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1776000/10000000 | consumed samples:    227328000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636032E+00 | sop loss: 5.204369E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.45 | backward-compute: 79.81 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 14.65
 iteration  1777000/10000000 | consumed samples:    227456000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634284E+00 | sop loss: 5.094533E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.54 | backward-compute: 79.81 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 19.36
 iteration  1778000/10000000 | consumed samples:    227584000 | elapsed time per iteration (ms): 246.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638432E+00 | sop loss: 5.219303E-02 | loss scale: 8192.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.31 | backward-compute: 79.83 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.58 | batch-generator: 18.71
 iteration  1779000/10000000 | consumed samples:    227712000 | elapsed time per iteration (ms): 246.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637701E+00 | sop loss: 5.368331E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.74 | backward-compute: 79.84 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 17.87
 iteration  1780000/10000000 | consumed samples:    227840000 | elapsed time per iteration (ms): 250.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638624E+00 | sop loss: 5.388882E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.93 | backward-compute: 79.88 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 18.70
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1780000 | lm loss value: 1.646602E+00 | lm loss PPL: 5.189318E+00 | sop loss value: 5.359824E-02 | sop loss PPL: 1.055061E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1781000/10000000 | consumed samples:    227968000 | elapsed time per iteration (ms): 250.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635337E+00 | sop loss: 5.117962E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.19 | backward-compute: 79.85 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 20.82
 iteration  1782000/10000000 | consumed samples:    228096000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639977E+00 | sop loss: 5.243252E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.98 | backward-compute: 79.80 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 12.99
 iteration  1783000/10000000 | consumed samples:    228224000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637431E+00 | sop loss: 5.445361E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.48 | backward-compute: 79.82 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 17.53
 iteration  1784000/10000000 | consumed samples:    228352000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639130E+00 | sop loss: 5.262798E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.61 | backward-compute: 79.78 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 20.37
 iteration  1785000/10000000 | consumed samples:    228480000 | elapsed time per iteration (ms): 247.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635189E+00 | sop loss: 5.232340E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.04 | backward-compute: 79.82 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 18.27
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1785000 | lm loss value: 1.683844E+00 | lm loss PPL: 5.386219E+00 | sop loss value: 5.451371E-02 | sop loss PPL: 1.056027E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1786000/10000000 | consumed samples:    228608000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639104E+00 | sop loss: 5.228783E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.66 | backward-compute: 79.82 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 13.86
 iteration  1787000/10000000 | consumed samples:    228736000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638071E+00 | sop loss: 5.209832E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.16 | backward-compute: 79.82 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.55 | batch-generator: 15.93
 iteration  1788000/10000000 | consumed samples:    228864000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640648E+00 | sop loss: 5.209984E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.80 | backward-compute: 79.78 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 13.53
 iteration  1789000/10000000 | consumed samples:    228992000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636636E+00 | sop loss: 5.256290E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.53 | backward-compute: 79.81 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.83
 iteration  1790000/10000000 | consumed samples:    229120000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640036E+00 | sop loss: 5.297873E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.77 | backward-compute: 79.83 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 23.46
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1790000 | lm loss value: 1.675838E+00 | lm loss PPL: 5.343273E+00 | sop loss value: 6.546905E-02 | sop loss PPL: 1.067660E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1791000/10000000 | consumed samples:    229248000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637143E+00 | sop loss: 5.133126E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.68 | backward-compute: 79.98 | backward-params-all-reduce: 14.70 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.87 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.37 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.86 | batch-generator: 16.51
 iteration  1792000/10000000 | consumed samples:    229376000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640531E+00 | sop loss: 5.284722E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.07 | backward-compute: 79.88 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 13.18
 iteration  1793000/10000000 | consumed samples:    229504000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639679E+00 | sop loss: 5.278198E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.27 | backward-compute: 79.82 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 15.81
 iteration  1794000/10000000 | consumed samples:    229632000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641005E+00 | sop loss: 5.197988E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.08 | backward-compute: 79.87 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.96
 iteration  1795000/10000000 | consumed samples:    229760000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637358E+00 | sop loss: 5.164446E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.73 | backward-compute: 79.76 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.53 | batch-generator: 17.67
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1795000 | lm loss value: 1.665808E+00 | lm loss PPL: 5.289946E+00 | sop loss value: 8.054601E-02 | sop loss PPL: 1.083879E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1796000/10000000 | consumed samples:    229888000 | elapsed time per iteration (ms): 250.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635503E+00 | sop loss: 5.333269E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.72 | backward-compute: 79.80 | backward-params-all-reduce: 14.50 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.26 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.72 | batch-generator: 23.53
 iteration  1797000/10000000 | consumed samples:    230016000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635248E+00 | sop loss: 5.345480E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.89 | backward-compute: 79.74 | backward-params-all-reduce: 14.38 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.60 | batch-generator: 13.24
 iteration  1798000/10000000 | consumed samples:    230144000 | elapsed time per iteration (ms): 246.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637036E+00 | sop loss: 5.205457E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.57 | backward-compute: 79.77 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.23
 iteration  1799000/10000000 | consumed samples:    230272000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639019E+00 | sop loss: 5.148125E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.61 | backward-compute: 79.89 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 15.47
 iteration  1800000/10000000 | consumed samples:    230400000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637360E+00 | sop loss: 5.173548E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.07 | backward-compute: 79.87 | backward-params-all-reduce: 14.87 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.89 | optimizer-unscale-and-check-inf: 2.31 | optimizer-clip-main-grad: 4.40 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.93 | batch-generator: 16.84
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1800000 | lm loss value: 1.681445E+00 | lm loss PPL: 5.373314E+00 | sop loss value: 6.659129E-02 | sop loss PPL: 1.068859E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 1800000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 1800000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2268.83
 iteration  1801000/10000000 | consumed samples:    230528000 | elapsed time per iteration (ms): 252.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641774E+00 | sop loss: 5.297806E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.78 | backward-compute: 79.77 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 15.26
 iteration  1802000/10000000 | consumed samples:    230656000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639146E+00 | sop loss: 5.337784E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.40 | backward-compute: 79.86 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.55 | batch-generator: 19.01
 iteration  1803000/10000000 | consumed samples:    230784000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640083E+00 | sop loss: 5.346528E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.02 | backward-compute: 79.84 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.23
 iteration  1804000/10000000 | consumed samples:    230912000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638376E+00 | sop loss: 5.199740E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.62 | backward-compute: 79.79 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 14.13
 iteration  1805000/10000000 | consumed samples:    231040000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.641617E+00 | sop loss: 5.286021E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.61 | backward-compute: 79.83 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 17.61
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1805000 | lm loss value: 1.648486E+00 | lm loss PPL: 5.199104E+00 | sop loss value: 5.682439E-02 | sop loss PPL: 1.058470E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1806000/10000000 | consumed samples:    231168000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635968E+00 | sop loss: 5.206532E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.14 | backward-compute: 79.83 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.14
 iteration  1807000/10000000 | consumed samples:    231296000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637277E+00 | sop loss: 5.299162E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.83 | backward-compute: 79.88 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 16.73
 iteration  1808000/10000000 | consumed samples:    231424000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631278E+00 | sop loss: 5.228191E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.71 | backward-compute: 79.86 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 19.74
 iteration  1809000/10000000 | consumed samples:    231552000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637660E+00 | sop loss: 5.327095E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.15 | backward-compute: 79.76 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 18.16
 iteration  1810000/10000000 | consumed samples:    231680000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638302E+00 | sop loss: 5.173016E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.02 | backward-compute: 79.89 | backward-params-all-reduce: 14.61 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.87 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.32 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.80 | batch-generator: 15.24
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1810000 | lm loss value: 1.693101E+00 | lm loss PPL: 5.436314E+00 | sop loss value: 7.160004E-02 | sop loss PPL: 1.074226E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1811000/10000000 | consumed samples:    231808000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636957E+00 | sop loss: 5.306636E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.06 | backward-compute: 79.79 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 14.49
 iteration  1812000/10000000 | consumed samples:    231936000 | elapsed time per iteration (ms): 245.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635950E+00 | sop loss: 5.104670E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.22 | backward-compute: 79.80 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 14.33
 iteration  1813000/10000000 | consumed samples:    232064000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639024E+00 | sop loss: 5.361401E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.73 | backward-compute: 79.80 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 16.83
 iteration  1814000/10000000 | consumed samples:    232192000 | elapsed time per iteration (ms): 246.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635887E+00 | sop loss: 5.302940E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.28 | backward-compute: 79.86 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.46
 iteration  1815000/10000000 | consumed samples:    232320000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.642165E+00 | sop loss: 5.213237E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.78 | backward-compute: 79.80 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.14
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1815000 | lm loss value: 1.678349E+00 | lm loss PPL: 5.356707E+00 | sop loss value: 5.941854E-02 | sop loss PPL: 1.061219E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1816000/10000000 | consumed samples:    232448000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639441E+00 | sop loss: 5.265519E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.21 | backward-compute: 79.80 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 12.73
 iteration  1817000/10000000 | consumed samples:    232576000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637374E+00 | sop loss: 5.207932E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.50 | backward-compute: 79.84 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 14.81
 iteration  1818000/10000000 | consumed samples:    232704000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636080E+00 | sop loss: 5.308486E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.17 | backward-compute: 79.81 | backward-params-all-reduce: 14.29 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.51 | batch-generator: 17.22
 iteration  1819000/10000000 | consumed samples:    232832000 | elapsed time per iteration (ms): 251.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637216E+00 | sop loss: 5.329263E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.40 | backward-compute: 79.79 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 16.78
 iteration  1820000/10000000 | consumed samples:    232960000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636817E+00 | sop loss: 5.286604E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.41 | backward-compute: 79.80 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 17.38
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1820000 | lm loss value: 1.669991E+00 | lm loss PPL: 5.312123E+00 | sop loss value: 5.903869E-02 | sop loss PPL: 1.060816E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1821000/10000000 | consumed samples:    233088000 | elapsed time per iteration (ms): 249.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638990E+00 | sop loss: 5.283855E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.47 | backward-compute: 79.82 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 16.09
 iteration  1822000/10000000 | consumed samples:    233216000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637873E+00 | sop loss: 5.210912E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.70 | backward-compute: 79.84 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.32
 iteration  1823000/10000000 | consumed samples:    233344000 | elapsed time per iteration (ms): 247.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637060E+00 | sop loss: 5.223992E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.17 | backward-compute: 79.87 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 17.42
 iteration  1824000/10000000 | consumed samples:    233472000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640426E+00 | sop loss: 5.166781E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.12 | backward-compute: 79.87 | backward-params-all-reduce: 13.90 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 18.83
 iteration  1825000/10000000 | consumed samples:    233600000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639377E+00 | sop loss: 5.258738E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.10 | backward-compute: 79.89 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 23.74
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1825000 | lm loss value: 1.701846E+00 | lm loss PPL: 5.484064E+00 | sop loss value: 6.512275E-02 | sop loss PPL: 1.067290E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1826000/10000000 | consumed samples:    233728000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635464E+00 | sop loss: 5.237374E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.51 | backward-compute: 79.83 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 13.70
 iteration  1827000/10000000 | consumed samples:    233856000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636514E+00 | sop loss: 5.159740E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.01 | backward-compute: 79.84 | backward-params-all-reduce: 14.34 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.58 | batch-generator: 17.75
 iteration  1828000/10000000 | consumed samples:    233984000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637976E+00 | sop loss: 5.271300E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.07 | backward-compute: 79.81 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 15.04
 iteration  1829000/10000000 | consumed samples:    234112000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636990E+00 | sop loss: 5.198541E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.22 | backward-compute: 79.74 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 14.68
 iteration  1830000/10000000 | consumed samples:    234240000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636464E+00 | sop loss: 5.149432E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.45 | backward-compute: 79.80 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 21.08
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1830000 | lm loss value: 1.714546E+00 | lm loss PPL: 5.554156E+00 | sop loss value: 5.739942E-02 | sop loss PPL: 1.059079E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1831000/10000000 | consumed samples:    234368000 | elapsed time per iteration (ms): 252.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637081E+00 | sop loss: 5.287834E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.44 | backward-compute: 79.78 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 19.40
 iteration  1832000/10000000 | consumed samples:    234496000 | elapsed time per iteration (ms): 246.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638904E+00 | sop loss: 5.260133E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.91 | backward-compute: 79.78 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 13.92
 iteration  1833000/10000000 | consumed samples:    234624000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635459E+00 | sop loss: 5.166259E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.33 | backward-compute: 79.77 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 16.13
 iteration  1834000/10000000 | consumed samples:    234752000 | elapsed time per iteration (ms): 246.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630935E+00 | sop loss: 5.137994E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.43 | backward-compute: 79.84 | backward-params-all-reduce: 14.64 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.27 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.72 | batch-generator: 17.14
 iteration  1835000/10000000 | consumed samples:    234880000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638902E+00 | sop loss: 5.248963E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.63 | backward-compute: 79.82 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 14.40
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1835000 | lm loss value: 1.694703E+00 | lm loss PPL: 5.445031E+00 | sop loss value: 6.827807E-02 | sop loss PPL: 1.070663E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1836000/10000000 | consumed samples:    235008000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639153E+00 | sop loss: 4.995686E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.78 | backward-compute: 79.85 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.24
 iteration  1837000/10000000 | consumed samples:    235136000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634762E+00 | sop loss: 5.249592E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.43 | backward-compute: 79.84 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 18.54
 iteration  1838000/10000000 | consumed samples:    235264000 | elapsed time per iteration (ms): 251.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634428E+00 | sop loss: 5.181201E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.18 | backward-compute: 79.77 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 15.50
 iteration  1839000/10000000 | consumed samples:    235392000 | elapsed time per iteration (ms): 246.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636550E+00 | sop loss: 5.134025E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.70 | backward-compute: 79.82 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 12.25
 iteration  1840000/10000000 | consumed samples:    235520000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638921E+00 | sop loss: 5.362292E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.66 | backward-compute: 79.78 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.55 | batch-generator: 15.22
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1840000 | lm loss value: 1.662111E+00 | lm loss PPL: 5.270423E+00 | sop loss value: 7.238870E-02 | sop loss PPL: 1.075073E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1841000/10000000 | consumed samples:    235648000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636541E+00 | sop loss: 5.384723E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.02 | backward-compute: 79.81 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.44 | batch-generator: 21.66
 iteration  1842000/10000000 | consumed samples:    235776000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638797E+00 | sop loss: 5.308569E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.86 | backward-compute: 79.85 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 21.04
 iteration  1843000/10000000 | consumed samples:    235904000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.640342E+00 | sop loss: 5.301456E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.81 | backward-compute: 79.85 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 12.73
 iteration  1844000/10000000 | consumed samples:    236032000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639314E+00 | sop loss: 5.228546E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.39 | backward-compute: 79.83 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 14.65
 iteration  1845000/10000000 | consumed samples:    236160000 | elapsed time per iteration (ms): 250.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634499E+00 | sop loss: 5.251906E-02 | loss scale: 8192.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.62 | backward-compute: 79.81 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 13.77
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1845000 | lm loss value: 1.693385E+00 | lm loss PPL: 5.437859E+00 | sop loss value: 7.554973E-02 | sop loss PPL: 1.078477E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1846000/10000000 | consumed samples:    236288000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639057E+00 | sop loss: 5.134887E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.29 | backward-compute: 79.94 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 13.81
 iteration  1847000/10000000 | consumed samples:    236416000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636680E+00 | sop loss: 5.293682E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.52 | backward-compute: 79.82 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 14.26
 iteration  1848000/10000000 | consumed samples:    236544000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638607E+00 | sop loss: 5.321718E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.97 | backward-compute: 79.79 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 16.92
 iteration  1849000/10000000 | consumed samples:    236672000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636655E+00 | sop loss: 5.250056E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.33 | backward-compute: 79.79 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 15.58
 iteration  1850000/10000000 | consumed samples:    236800000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637510E+00 | sop loss: 5.336936E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.58 | backward-compute: 79.80 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 17.20
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1850000 | lm loss value: 1.692601E+00 | lm loss PPL: 5.433598E+00 | sop loss value: 7.048827E-02 | sop loss PPL: 1.073032E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 1850000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 1850000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2344.07
 iteration  1851000/10000000 | consumed samples:    236928000 | elapsed time per iteration (ms): 252.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630518E+00 | sop loss: 5.241223E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.00 | backward-compute: 79.76 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.42 | batch-generator: 18.62
 iteration  1852000/10000000 | consumed samples:    237056000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636559E+00 | sop loss: 5.205743E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.98 | backward-compute: 79.85 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 16.38
 iteration  1853000/10000000 | consumed samples:    237184000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638485E+00 | sop loss: 5.269726E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.21 | backward-compute: 79.82 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 15.47
 iteration  1854000/10000000 | consumed samples:    237312000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636735E+00 | sop loss: 5.265700E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.83 | backward-compute: 79.73 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 14.30
 iteration  1855000/10000000 | consumed samples:    237440000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633971E+00 | sop loss: 5.193118E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.92 | backward-compute: 79.86 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 20.30
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1855000 | lm loss value: 1.683943E+00 | lm loss PPL: 5.386753E+00 | sop loss value: 4.470119E-02 | sop loss PPL: 1.045715E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1856000/10000000 | consumed samples:    237568000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638308E+00 | sop loss: 5.442482E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.85 | backward-compute: 79.92 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 17.20
 iteration  1857000/10000000 | consumed samples:    237696000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633787E+00 | sop loss: 5.107914E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.88 | backward-compute: 79.83 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 15.59
 iteration  1858000/10000000 | consumed samples:    237824000 | elapsed time per iteration (ms): 247.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639984E+00 | sop loss: 5.170565E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.35 | backward-compute: 79.77 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.81
 iteration  1859000/10000000 | consumed samples:    237952000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629492E+00 | sop loss: 5.260513E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.52 | backward-compute: 79.78 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 18.95
 iteration  1860000/10000000 | consumed samples:    238080000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635809E+00 | sop loss: 5.328701E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.44 | backward-compute: 79.80 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 16.91
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1860000 | lm loss value: 1.713750E+00 | lm loss PPL: 5.549737E+00 | sop loss value: 5.071033E-02 | sop loss PPL: 1.052018E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1861000/10000000 | consumed samples:    238208000 | elapsed time per iteration (ms): 251.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635543E+00 | sop loss: 5.203515E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.82 | backward-compute: 79.80 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 15.51
 iteration  1862000/10000000 | consumed samples:    238336000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635446E+00 | sop loss: 5.309111E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.89 | backward-compute: 79.81 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.53
 iteration  1863000/10000000 | consumed samples:    238464000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635306E+00 | sop loss: 5.223513E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.07 | backward-compute: 79.79 | backward-params-all-reduce: 14.28 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.56 | batch-generator: 15.22
 iteration  1864000/10000000 | consumed samples:    238592000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635760E+00 | sop loss: 5.158956E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.95 | backward-compute: 79.81 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 14.19
 iteration  1865000/10000000 | consumed samples:    238720000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637951E+00 | sop loss: 5.183055E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.43 | backward-compute: 79.84 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 16.41
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1865000 | lm loss value: 1.692986E+00 | lm loss PPL: 5.435685E+00 | sop loss value: 7.386304E-02 | sop loss PPL: 1.076659E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1866000/10000000 | consumed samples:    238848000 | elapsed time per iteration (ms): 249.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635841E+00 | sop loss: 5.237669E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.31 | backward-compute: 79.80 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 17.66
 iteration  1867000/10000000 | consumed samples:    238976000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636378E+00 | sop loss: 5.125446E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.20 | backward-compute: 79.75 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 17.98
 iteration  1868000/10000000 | consumed samples:    239104000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637185E+00 | sop loss: 5.188257E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.15 | backward-compute: 79.80 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 16.10
 iteration  1869000/10000000 | consumed samples:    239232000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633813E+00 | sop loss: 5.299384E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.41 | backward-compute: 79.76 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 13.35
 iteration  1870000/10000000 | consumed samples:    239360000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635954E+00 | sop loss: 5.271900E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.21 | backward-compute: 79.79 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.54 | batch-generator: 19.12
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1870000 | lm loss value: 1.694998E+00 | lm loss PPL: 5.446636E+00 | sop loss value: 5.126576E-02 | sop loss PPL: 1.052603E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1871000/10000000 | consumed samples:    239488000 | elapsed time per iteration (ms): 251.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.639673E+00 | sop loss: 5.131077E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.06 | backward-compute: 79.82 | backward-params-all-reduce: 14.62 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.23 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.68 | batch-generator: 18.58
 iteration  1872000/10000000 | consumed samples:    239616000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632885E+00 | sop loss: 5.201736E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.68 | backward-compute: 79.82 | backward-params-all-reduce: 14.42 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.23 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.68 | batch-generator: 15.31
 iteration  1873000/10000000 | consumed samples:    239744000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635592E+00 | sop loss: 5.226374E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.32 | backward-compute: 79.91 | backward-params-all-reduce: 14.28 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.51 | batch-generator: 14.59
 iteration  1874000/10000000 | consumed samples:    239872000 | elapsed time per iteration (ms): 249.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636463E+00 | sop loss: 5.287327E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.05 | backward-compute: 79.94 | backward-params-all-reduce: 13.82 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 20.24
 iteration  1875000/10000000 | consumed samples:    240000000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635953E+00 | sop loss: 5.163094E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.41 | backward-compute: 79.78 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.31
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1875000 | lm loss value: 1.670082E+00 | lm loss PPL: 5.312602E+00 | sop loss value: 7.154378E-02 | sop loss PPL: 1.074165E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1876000/10000000 | consumed samples:    240128000 | elapsed time per iteration (ms): 252.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635028E+00 | sop loss: 5.235633E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.36 | backward-compute: 79.82 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 13.88
 iteration  1877000/10000000 | consumed samples:    240256000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635073E+00 | sop loss: 5.145292E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.81 | backward-compute: 79.73 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.68
 iteration  1878000/10000000 | consumed samples:    240384000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634825E+00 | sop loss: 5.157218E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.52 | backward-compute: 79.85 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 16.28
 iteration  1879000/10000000 | consumed samples:    240512000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636675E+00 | sop loss: 5.139148E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.73 | backward-compute: 79.82 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 15.97
 iteration  1880000/10000000 | consumed samples:    240640000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636589E+00 | sop loss: 5.282882E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.79 | backward-compute: 79.80 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 17.70
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1880000 | lm loss value: 1.700782E+00 | lm loss PPL: 5.478228E+00 | sop loss value: 7.366698E-02 | sop loss PPL: 1.076448E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1881000/10000000 | consumed samples:    240768000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638073E+00 | sop loss: 5.408862E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.89 | backward-compute: 79.81 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.59 | batch-generator: 12.89
 iteration  1882000/10000000 | consumed samples:    240896000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636001E+00 | sop loss: 5.254327E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.53 | backward-compute: 79.77 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 15.93
 iteration  1883000/10000000 | consumed samples:    241024000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638313E+00 | sop loss: 5.264405E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.61 | backward-compute: 79.80 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.08
 iteration  1884000/10000000 | consumed samples:    241152000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635354E+00 | sop loss: 5.217696E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.17 | backward-compute: 79.84 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 15.25
 iteration  1885000/10000000 | consumed samples:    241280000 | elapsed time per iteration (ms): 250.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636802E+00 | sop loss: 5.288306E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.84 | backward-compute: 79.79 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 16.00
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1885000 | lm loss value: 1.675066E+00 | lm loss PPL: 5.339147E+00 | sop loss value: 5.149176E-02 | sop loss PPL: 1.052841E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1886000/10000000 | consumed samples:    241408000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633249E+00 | sop loss: 5.304526E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.13 | backward-compute: 79.80 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 16.17
 iteration  1887000/10000000 | consumed samples:    241536000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634435E+00 | sop loss: 5.146012E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.47 | backward-compute: 79.81 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 14.96
 iteration  1888000/10000000 | consumed samples:    241664000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638458E+00 | sop loss: 5.228391E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.55 | backward-compute: 79.81 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.41 | batch-generator: 15.51
 iteration  1889000/10000000 | consumed samples:    241792000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636498E+00 | sop loss: 5.185244E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.61 | backward-compute: 79.82 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.41 | batch-generator: 15.19
 iteration  1890000/10000000 | consumed samples:    241920000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636815E+00 | sop loss: 5.154680E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.41 | backward-compute: 79.79 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.71
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1890000 | lm loss value: 1.659381E+00 | lm loss PPL: 5.256054E+00 | sop loss value: 6.622482E-02 | sop loss PPL: 1.068467E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1891000/10000000 | consumed samples:    242048000 | elapsed time per iteration (ms): 250.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637381E+00 | sop loss: 5.219461E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.47 | backward-compute: 79.91 | backward-params-all-reduce: 13.87 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 23.43
 iteration  1892000/10000000 | consumed samples:    242176000 | elapsed time per iteration (ms): 250.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635553E+00 | sop loss: 5.283368E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.39 | backward-compute: 79.88 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 15.64
 iteration  1893000/10000000 | consumed samples:    242304000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.638285E+00 | sop loss: 5.177564E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.74 | backward-compute: 79.80 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 18.95
 iteration  1894000/10000000 | consumed samples:    242432000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636908E+00 | sop loss: 5.326880E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.32 | backward-compute: 79.78 | backward-params-all-reduce: 14.34 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.60 | batch-generator: 16.65
 iteration  1895000/10000000 | consumed samples:    242560000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632585E+00 | sop loss: 5.175203E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.52 | backward-compute: 79.75 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 13.78
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1895000 | lm loss value: 1.670387E+00 | lm loss PPL: 5.314224E+00 | sop loss value: 7.013750E-02 | sop loss PPL: 1.072656E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1896000/10000000 | consumed samples:    242688000 | elapsed time per iteration (ms): 250.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635194E+00 | sop loss: 5.295558E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.68 | backward-compute: 79.80 | backward-params-all-reduce: 14.39 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.60 | batch-generator: 15.02
 iteration  1897000/10000000 | consumed samples:    242816000 | elapsed time per iteration (ms): 246.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636518E+00 | sop loss: 5.175378E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.71 | backward-compute: 79.86 | backward-params-all-reduce: 14.27 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.48 | batch-generator: 15.62
 iteration  1898000/10000000 | consumed samples:    242944000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636047E+00 | sop loss: 5.160385E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.01 | backward-compute: 79.80 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 12.30
 iteration  1899000/10000000 | consumed samples:    243072000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632919E+00 | sop loss: 5.178200E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.78 | backward-compute: 79.80 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 14.47
 iteration  1900000/10000000 | consumed samples:    243200000 | elapsed time per iteration (ms): 251.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635605E+00 | sop loss: 5.327495E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.76 | backward-compute: 79.78 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 12.06
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1900000 | lm loss value: 1.683550E+00 | lm loss PPL: 5.384639E+00 | sop loss value: 8.037417E-02 | sop loss PPL: 1.083692E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 1900000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 1900000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2311.40
 iteration  1901000/10000000 | consumed samples:    243328000 | elapsed time per iteration (ms): 251.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635281E+00 | sop loss: 5.171531E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.95 | backward-compute: 79.78 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 12.88
 iteration  1902000/10000000 | consumed samples:    243456000 | elapsed time per iteration (ms): 246.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637607E+00 | sop loss: 5.349550E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.29 | backward-compute: 79.73 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 13.96
 iteration  1903000/10000000 | consumed samples:    243584000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634146E+00 | sop loss: 5.209420E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.21 | backward-compute: 79.77 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 14.40
 iteration  1904000/10000000 | consumed samples:    243712000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631667E+00 | sop loss: 5.262363E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.52 | backward-compute: 79.78 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 19.08
 iteration  1905000/10000000 | consumed samples:    243840000 | elapsed time per iteration (ms): 247.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633840E+00 | sop loss: 5.260767E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.24 | backward-compute: 79.77 | backward-params-all-reduce: 14.62 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.28 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.77 | batch-generator: 15.52
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1905000 | lm loss value: 1.718747E+00 | lm loss PPL: 5.577533E+00 | sop loss value: 5.186055E-02 | sop loss PPL: 1.053229E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1906000/10000000 | consumed samples:    243968000 | elapsed time per iteration (ms): 252.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636067E+00 | sop loss: 5.224301E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.90 | backward-compute: 79.80 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.52
 iteration  1907000/10000000 | consumed samples:    244096000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635539E+00 | sop loss: 5.220194E-02 | loss scale: 8192.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.68 | backward-compute: 79.82 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 14.36
 iteration  1908000/10000000 | consumed samples:    244224000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634381E+00 | sop loss: 5.195118E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.39 | backward-compute: 79.76 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.96
 iteration  1909000/10000000 | consumed samples:    244352000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635835E+00 | sop loss: 5.283983E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.12 | backward-compute: 79.80 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.20
 iteration  1910000/10000000 | consumed samples:    244480000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632605E+00 | sop loss: 5.214955E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.64 | backward-compute: 79.84 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 21.69
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1910000 | lm loss value: 1.679105E+00 | lm loss PPL: 5.360757E+00 | sop loss value: 6.475504E-02 | sop loss PPL: 1.066898E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1911000/10000000 | consumed samples:    244608000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635445E+00 | sop loss: 5.096953E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.60 | backward-compute: 79.78 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 13.59
 iteration  1912000/10000000 | consumed samples:    244736000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631983E+00 | sop loss: 5.320303E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.01 | backward-compute: 79.81 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 17.77
 iteration  1913000/10000000 | consumed samples:    244864000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634238E+00 | sop loss: 5.271115E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.80 | backward-compute: 79.83 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 15.16
 iteration  1914000/10000000 | consumed samples:    244992000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636001E+00 | sop loss: 5.241396E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.68 | backward-compute: 79.79 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.53 | batch-generator: 16.78
 iteration  1915000/10000000 | consumed samples:    245120000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631527E+00 | sop loss: 5.374530E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.87 | backward-compute: 79.81 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 17.46
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1915000 | lm loss value: 1.710203E+00 | lm loss PPL: 5.530084E+00 | sop loss value: 5.657721E-02 | sop loss PPL: 1.058208E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1916000/10000000 | consumed samples:    245248000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635730E+00 | sop loss: 5.361816E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.40 | backward-compute: 79.86 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.52 | batch-generator: 14.89
 iteration  1917000/10000000 | consumed samples:    245376000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634086E+00 | sop loss: 5.278120E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.54 | backward-compute: 79.81 | backward-params-all-reduce: 14.39 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.20 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.61 | batch-generator: 14.92
 iteration  1918000/10000000 | consumed samples:    245504000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635148E+00 | sop loss: 5.450378E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.50 | backward-compute: 79.81 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.38
 iteration  1919000/10000000 | consumed samples:    245632000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636375E+00 | sop loss: 5.281656E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.15 | backward-compute: 79.95 | backward-params-all-reduce: 14.37 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.20 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.66 | batch-generator: 15.72
 iteration  1920000/10000000 | consumed samples:    245760000 | elapsed time per iteration (ms): 250.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634043E+00 | sop loss: 5.191267E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.92 | backward-compute: 79.83 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 21.14
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1920000 | lm loss value: 1.670656E+00 | lm loss PPL: 5.315654E+00 | sop loss value: 5.922665E-02 | sop loss PPL: 1.061016E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1921000/10000000 | consumed samples:    245888000 | elapsed time per iteration (ms): 251.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632547E+00 | sop loss: 5.272740E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.10 | backward-compute: 79.80 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 15.09
 iteration  1922000/10000000 | consumed samples:    246016000 | elapsed time per iteration (ms): 246.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632108E+00 | sop loss: 5.146962E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.27 | backward-compute: 79.91 | backward-params-all-reduce: 13.80 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 14.68
 iteration  1923000/10000000 | consumed samples:    246144000 | elapsed time per iteration (ms): 249.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634014E+00 | sop loss: 5.126585E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.96 | backward-compute: 79.79 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 21.14
 iteration  1924000/10000000 | consumed samples:    246272000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636797E+00 | sop loss: 5.211088E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.98 | backward-compute: 79.85 | backward-params-all-reduce: 14.37 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.59 | batch-generator: 17.00
 iteration  1925000/10000000 | consumed samples:    246400000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631836E+00 | sop loss: 5.249973E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.35 | backward-compute: 79.80 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.12
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1925000 | lm loss value: 1.683937E+00 | lm loss PPL: 5.386724E+00 | sop loss value: 5.317031E-02 | sop loss PPL: 1.054609E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1926000/10000000 | consumed samples:    246528000 | elapsed time per iteration (ms): 249.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635615E+00 | sop loss: 5.316707E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.44 | backward-compute: 79.82 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 16.17
 iteration  1927000/10000000 | consumed samples:    246656000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636476E+00 | sop loss: 5.206607E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.73 | backward-compute: 79.81 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.52 | batch-generator: 16.27
 iteration  1928000/10000000 | consumed samples:    246784000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635768E+00 | sop loss: 5.241287E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.06 | backward-compute: 79.83 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 14.76
 iteration  1929000/10000000 | consumed samples:    246912000 | elapsed time per iteration (ms): 246.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634608E+00 | sop loss: 5.180702E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.93 | backward-compute: 79.81 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 13.73
 iteration  1930000/10000000 | consumed samples:    247040000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631950E+00 | sop loss: 5.152682E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.56 | backward-compute: 79.82 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 15.57
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1930000 | lm loss value: 1.672173E+00 | lm loss PPL: 5.323724E+00 | sop loss value: 5.912584E-02 | sop loss PPL: 1.060909E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1931000/10000000 | consumed samples:    247168000 | elapsed time per iteration (ms): 250.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634886E+00 | sop loss: 5.174578E-02 | loss scale: 8192.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.16 | backward-compute: 79.82 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.54 | batch-generator: 17.04
 iteration  1932000/10000000 | consumed samples:    247296000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631994E+00 | sop loss: 5.114246E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.26 | backward-compute: 79.77 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.44 | batch-generator: 24.28
 iteration  1933000/10000000 | consumed samples:    247424000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631414E+00 | sop loss: 5.418042E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.23 | backward-compute: 79.86 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 15.35
 iteration  1934000/10000000 | consumed samples:    247552000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634390E+00 | sop loss: 5.400401E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.81 | backward-compute: 79.88 | backward-params-all-reduce: 14.28 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.59 | batch-generator: 13.86
 iteration  1935000/10000000 | consumed samples:    247680000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633364E+00 | sop loss: 5.144190E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.77 | backward-compute: 79.84 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.53 | batch-generator: 14.53
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1935000 | lm loss value: 1.681938E+00 | lm loss PPL: 5.375963E+00 | sop loss value: 6.269579E-02 | sop loss PPL: 1.064703E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1936000/10000000 | consumed samples:    247808000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632446E+00 | sop loss: 5.345329E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.52 | backward-compute: 79.85 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.76
 iteration  1937000/10000000 | consumed samples:    247936000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631719E+00 | sop loss: 5.297777E-02 | loss scale: 8192.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.68 | backward-compute: 79.83 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.38
 iteration  1938000/10000000 | consumed samples:    248064000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634300E+00 | sop loss: 5.247367E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.03 | backward-compute: 79.74 | backward-params-all-reduce: 14.36 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.56 | batch-generator: 15.22
 iteration  1939000/10000000 | consumed samples:    248192000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637002E+00 | sop loss: 5.271002E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.90 | backward-compute: 79.86 | backward-params-all-reduce: 14.80 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.88 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.38 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.89 | batch-generator: 18.13
 iteration  1940000/10000000 | consumed samples:    248320000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634109E+00 | sop loss: 5.131566E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.81 | backward-compute: 79.86 | backward-params-all-reduce: 14.42 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.58 | batch-generator: 16.75
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1940000 | lm loss value: 1.681396E+00 | lm loss PPL: 5.373049E+00 | sop loss value: 6.349338E-02 | sop loss PPL: 1.065552E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1941000/10000000 | consumed samples:    248448000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634371E+00 | sop loss: 5.141855E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.00 | backward-compute: 79.87 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 24.58
 iteration  1942000/10000000 | consumed samples:    248576000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634908E+00 | sop loss: 5.281577E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.75 | backward-compute: 79.87 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 19.89
 iteration  1943000/10000000 | consumed samples:    248704000 | elapsed time per iteration (ms): 246.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635592E+00 | sop loss: 5.272767E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.95 | backward-compute: 79.79 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.81
 iteration  1944000/10000000 | consumed samples:    248832000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633548E+00 | sop loss: 5.198082E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.79 | backward-compute: 79.78 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 13.47
 iteration  1945000/10000000 | consumed samples:    248960000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634693E+00 | sop loss: 5.289499E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.88 | backward-compute: 79.92 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 17.74
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1945000 | lm loss value: 1.709556E+00 | lm loss PPL: 5.526510E+00 | sop loss value: 6.123467E-02 | sop loss PPL: 1.063148E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1946000/10000000 | consumed samples:    249088000 | elapsed time per iteration (ms): 251.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636506E+00 | sop loss: 5.331798E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.30 | backward-compute: 79.70 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 25.99
 iteration  1947000/10000000 | consumed samples:    249216000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635329E+00 | sop loss: 5.369093E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.47 | backward-compute: 79.75 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 13.41
 iteration  1948000/10000000 | consumed samples:    249344000 | elapsed time per iteration (ms): 246.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635201E+00 | sop loss: 5.163639E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.21 | backward-compute: 79.83 | backward-params-all-reduce: 14.37 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.56 | batch-generator: 15.11
 iteration  1949000/10000000 | consumed samples:    249472000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633868E+00 | sop loss: 5.107540E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.06 | backward-compute: 79.85 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.51
 iteration  1950000/10000000 | consumed samples:    249600000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631839E+00 | sop loss: 5.223984E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.05 | backward-compute: 79.94 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.85
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1950000 | lm loss value: 1.696553E+00 | lm loss PPL: 5.455112E+00 | sop loss value: 7.095056E-02 | sop loss PPL: 1.073528E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 1950000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 1950000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2312.38
 iteration  1951000/10000000 | consumed samples:    249728000 | elapsed time per iteration (ms): 252.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631862E+00 | sop loss: 5.179069E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.26 | backward-compute: 79.84 | backward-params-all-reduce: 13.90 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 17.74
 iteration  1952000/10000000 | consumed samples:    249856000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630853E+00 | sop loss: 5.169253E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.76 | backward-compute: 79.80 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 16.62
 iteration  1953000/10000000 | consumed samples:    249984000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630779E+00 | sop loss: 5.175136E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.92 | backward-compute: 79.82 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 14.12
 iteration  1954000/10000000 | consumed samples:    250112000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634636E+00 | sop loss: 5.240726E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.81 | backward-compute: 79.82 | backward-params-all-reduce: 13.88 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 18.79
 iteration  1955000/10000000 | consumed samples:    250240000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632625E+00 | sop loss: 5.320263E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.12 | backward-compute: 79.83 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.53
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1955000 | lm loss value: 1.665484E+00 | lm loss PPL: 5.288231E+00 | sop loss value: 5.792467E-02 | sop loss PPL: 1.059635E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1956000/10000000 | consumed samples:    250368000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631889E+00 | sop loss: 5.205300E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.79 | backward-compute: 79.80 | backward-params-all-reduce: 14.29 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 16.84
 iteration  1957000/10000000 | consumed samples:    250496000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632751E+00 | sop loss: 5.157331E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.40 | backward-compute: 79.87 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.85
 iteration  1958000/10000000 | consumed samples:    250624000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632364E+00 | sop loss: 5.238381E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.31 | backward-compute: 79.80 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 17.89
 iteration  1959000/10000000 | consumed samples:    250752000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630851E+00 | sop loss: 5.233556E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.51 | backward-compute: 79.83 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 17.01
 iteration  1960000/10000000 | consumed samples:    250880000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632589E+00 | sop loss: 5.202051E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.88 | backward-compute: 79.78 | backward-params-all-reduce: 14.49 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.22 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.67 | batch-generator: 17.25
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1960000 | lm loss value: 1.705644E+00 | lm loss PPL: 5.504932E+00 | sop loss value: 5.790670E-02 | sop loss PPL: 1.059616E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1961000/10000000 | consumed samples:    251008000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632300E+00 | sop loss: 5.247167E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.11 | backward-compute: 79.89 | backward-params-all-reduce: 14.33 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.58 | batch-generator: 16.07
 iteration  1962000/10000000 | consumed samples:    251136000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632523E+00 | sop loss: 5.160920E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.53 | backward-compute: 79.91 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 23.30
 iteration  1963000/10000000 | consumed samples:    251264000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630297E+00 | sop loss: 5.321898E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.11 | backward-compute: 79.81 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 13.73
 iteration  1964000/10000000 | consumed samples:    251392000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633627E+00 | sop loss: 5.332424E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.80 | backward-compute: 79.78 | backward-params-all-reduce: 14.27 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.48 | batch-generator: 13.29
 iteration  1965000/10000000 | consumed samples:    251520000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637084E+00 | sop loss: 5.247333E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.44 | backward-compute: 79.79 | backward-params-all-reduce: 14.43 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.23 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.66 | batch-generator: 13.83
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1965000 | lm loss value: 1.647112E+00 | lm loss PPL: 5.191966E+00 | sop loss value: 6.658088E-02 | sop loss PPL: 1.068847E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1966000/10000000 | consumed samples:    251648000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632846E+00 | sop loss: 5.205937E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.09 | backward-compute: 79.78 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 16.31
 iteration  1967000/10000000 | consumed samples:    251776000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637358E+00 | sop loss: 5.253083E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.57 | backward-compute: 79.78 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 12.95
 iteration  1968000/10000000 | consumed samples:    251904000 | elapsed time per iteration (ms): 246.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634570E+00 | sop loss: 5.130771E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.24 | backward-compute: 79.81 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 19.71
 iteration  1969000/10000000 | consumed samples:    252032000 | elapsed time per iteration (ms): 249.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633872E+00 | sop loss: 5.088132E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.88 | backward-compute: 79.78 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.46 | batch-generator: 20.61
 iteration  1970000/10000000 | consumed samples:    252160000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631866E+00 | sop loss: 5.223977E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.26 | backward-compute: 79.80 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 16.00
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1970000 | lm loss value: 1.672374E+00 | lm loss PPL: 5.324793E+00 | sop loss value: 5.738832E-02 | sop loss PPL: 1.059067E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1971000/10000000 | consumed samples:    252288000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634779E+00 | sop loss: 5.286830E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.88 | backward-compute: 79.84 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 13.49
 iteration  1972000/10000000 | consumed samples:    252416000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632760E+00 | sop loss: 5.284612E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.47 | backward-compute: 79.85 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 16.96
 iteration  1973000/10000000 | consumed samples:    252544000 | elapsed time per iteration (ms): 247.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632992E+00 | sop loss: 5.356408E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.22 | backward-compute: 79.84 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 17.41
 iteration  1974000/10000000 | consumed samples:    252672000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634889E+00 | sop loss: 5.283570E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.78 | backward-compute: 79.81 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.56 | batch-generator: 14.80
 iteration  1975000/10000000 | consumed samples:    252800000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635422E+00 | sop loss: 5.295571E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.60 | backward-compute: 79.84 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 14.30
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1975000 | lm loss value: 1.667465E+00 | lm loss PPL: 5.298721E+00 | sop loss value: 4.869641E-02 | sop loss PPL: 1.049902E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1976000/10000000 | consumed samples:    252928000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629714E+00 | sop loss: 5.092938E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.04 | backward-compute: 79.82 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 14.48
 iteration  1977000/10000000 | consumed samples:    253056000 | elapsed time per iteration (ms): 250.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634214E+00 | sop loss: 5.284687E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.21 | backward-compute: 79.92 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.19 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.61 | batch-generator: 16.47
 iteration  1978000/10000000 | consumed samples:    253184000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631833E+00 | sop loss: 5.271306E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.56 | backward-compute: 79.84 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.45 | batch-generator: 14.97
 iteration  1979000/10000000 | consumed samples:    253312000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632385E+00 | sop loss: 5.346735E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.39 | backward-compute: 79.80 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 14.89
 iteration  1980000/10000000 | consumed samples:    253440000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629820E+00 | sop loss: 5.303403E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.36 | backward-compute: 79.79 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 12.19
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1980000 | lm loss value: 1.642094E+00 | lm loss PPL: 5.165978E+00 | sop loss value: 6.902026E-02 | sop loss PPL: 1.071458E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1981000/10000000 | consumed samples:    253568000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637691E+00 | sop loss: 5.194832E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.67 | backward-compute: 79.82 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 18.01
 iteration  1982000/10000000 | consumed samples:    253696000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633427E+00 | sop loss: 5.140727E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.07 | backward-compute: 79.81 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.15
 iteration  1983000/10000000 | consumed samples:    253824000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633031E+00 | sop loss: 5.238089E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.09 | backward-compute: 79.80 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 17.90
 iteration  1984000/10000000 | consumed samples:    253952000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631255E+00 | sop loss: 5.120239E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.52 | backward-compute: 79.81 | backward-params-all-reduce: 14.58 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.27 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.72 | batch-generator: 17.04
 iteration  1985000/10000000 | consumed samples:    254080000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632306E+00 | sop loss: 5.404998E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.73 | backward-compute: 79.79 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 21.70
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1985000 | lm loss value: 1.686314E+00 | lm loss PPL: 5.399541E+00 | sop loss value: 6.192887E-02 | sop loss PPL: 1.063887E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1986000/10000000 | consumed samples:    254208000 | elapsed time per iteration (ms): 250.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630492E+00 | sop loss: 5.155366E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.30 | backward-compute: 79.80 | backward-params-all-reduce: 14.63 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.87 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.31 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.81 | batch-generator: 17.57
 iteration  1987000/10000000 | consumed samples:    254336000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630888E+00 | sop loss: 5.322855E-02 | loss scale: 8192.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.56 | backward-compute: 79.81 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 20.30
 iteration  1988000/10000000 | consumed samples:    254464000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633914E+00 | sop loss: 5.277411E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.27 | backward-compute: 79.75 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 14.53
 iteration  1989000/10000000 | consumed samples:    254592000 | elapsed time per iteration (ms): 246.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633317E+00 | sop loss: 5.137094E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.66 | backward-compute: 79.82 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 16.35
 iteration  1990000/10000000 | consumed samples:    254720000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633564E+00 | sop loss: 5.163646E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.66 | backward-compute: 79.82 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 19.53
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1990000 | lm loss value: 1.625254E+00 | lm loss PPL: 5.079707E+00 | sop loss value: 5.087505E-02 | sop loss PPL: 1.052191E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1991000/10000000 | consumed samples:    254848000 | elapsed time per iteration (ms): 249.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.636324E+00 | sop loss: 5.128447E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.30 | backward-compute: 79.75 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 18.03
 iteration  1992000/10000000 | consumed samples:    254976000 | elapsed time per iteration (ms): 246.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631136E+00 | sop loss: 5.200105E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.96 | backward-compute: 79.80 | backward-params-all-reduce: 14.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 15.07
 iteration  1993000/10000000 | consumed samples:    255104000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635757E+00 | sop loss: 5.305497E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.03 | backward-compute: 79.84 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 15.77
 iteration  1994000/10000000 | consumed samples:    255232000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632069E+00 | sop loss: 5.251636E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.48 | backward-compute: 79.84 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 18.13
 iteration  1995000/10000000 | consumed samples:    255360000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631982E+00 | sop loss: 5.404303E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.29 | backward-compute: 79.85 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 17.51
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1995000 | lm loss value: 1.672252E+00 | lm loss PPL: 5.324146E+00 | sop loss value: 4.721519E-02 | sop loss PPL: 1.048348E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  1996000/10000000 | consumed samples:    255488000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634118E+00 | sop loss: 5.248621E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.43 | backward-compute: 79.77 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.54 | batch-generator: 14.55
 iteration  1997000/10000000 | consumed samples:    255616000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631838E+00 | sop loss: 5.326562E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.74 | backward-compute: 79.82 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.57 | batch-generator: 12.16
 iteration  1998000/10000000 | consumed samples:    255744000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632401E+00 | sop loss: 5.350679E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.73 | backward-compute: 79.76 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 16.97
 iteration  1999000/10000000 | consumed samples:    255872000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630166E+00 | sop loss: 5.234562E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.41 | backward-compute: 79.78 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 14.29
 iteration  2000000/10000000 | consumed samples:    256000000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635194E+00 | sop loss: 5.165412E-02 | loss scale: 65536.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.74 | backward-compute: 79.85 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 15.54
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2000000 | lm loss value: 1.669408E+00 | lm loss PPL: 5.309023E+00 | sop loss value: 5.572493E-02 | sop loss PPL: 1.057307E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 2000000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 2000000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2266.87
 iteration  2001000/10000000 | consumed samples:    256128000 | elapsed time per iteration (ms): 252.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632259E+00 | sop loss: 5.185817E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.07 | backward-compute: 79.84 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 17.70
 iteration  2002000/10000000 | consumed samples:    256256000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633688E+00 | sop loss: 5.222068E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.07 | backward-compute: 79.82 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 17.17
 iteration  2003000/10000000 | consumed samples:    256384000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632748E+00 | sop loss: 5.195071E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.73 | backward-compute: 79.79 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.16
 iteration  2004000/10000000 | consumed samples:    256512000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633230E+00 | sop loss: 5.204672E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.80 | backward-compute: 79.74 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 12.63
 iteration  2005000/10000000 | consumed samples:    256640000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631832E+00 | sop loss: 5.322570E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.24 | backward-compute: 79.82 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 16.66
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2005000 | lm loss value: 1.683435E+00 | lm loss PPL: 5.384017E+00 | sop loss value: 5.907228E-02 | sop loss PPL: 1.060852E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2006000/10000000 | consumed samples:    256768000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631121E+00 | sop loss: 5.082254E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.66 | backward-compute: 79.82 | backward-params-all-reduce: 14.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 12.93
 iteration  2007000/10000000 | consumed samples:    256896000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633184E+00 | sop loss: 5.186481E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.25 | backward-compute: 79.78 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 17.76
 iteration  2008000/10000000 | consumed samples:    257024000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633221E+00 | sop loss: 5.070384E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.01 | backward-compute: 79.85 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 17.71
 iteration  2009000/10000000 | consumed samples:    257152000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631424E+00 | sop loss: 5.150906E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.52 | backward-compute: 79.82 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.42 | batch-generator: 17.31
 iteration  2010000/10000000 | consumed samples:    257280000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633635E+00 | sop loss: 5.213265E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.73 | backward-compute: 79.87 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 18.07
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2010000 | lm loss value: 1.666072E+00 | lm loss PPL: 5.291340E+00 | sop loss value: 5.285902E-02 | sop loss PPL: 1.054281E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2011000/10000000 | consumed samples:    257408000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633234E+00 | sop loss: 5.278278E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.40 | backward-compute: 79.82 | backward-params-all-reduce: 14.39 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.59 | batch-generator: 16.48
 iteration  2012000/10000000 | consumed samples:    257536000 | elapsed time per iteration (ms): 246.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632195E+00 | sop loss: 5.148594E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.53 | backward-compute: 79.86 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 14.24
 iteration  2013000/10000000 | consumed samples:    257664000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629793E+00 | sop loss: 5.260169E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.46 | backward-compute: 79.78 | backward-params-all-reduce: 14.67 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.87 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.29 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.78 | batch-generator: 14.47
 iteration  2014000/10000000 | consumed samples:    257792000 | elapsed time per iteration (ms): 251.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630960E+00 | sop loss: 5.092473E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.81 | backward-compute: 79.77 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 18.89
 iteration  2015000/10000000 | consumed samples:    257920000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632540E+00 | sop loss: 5.219093E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.35 | backward-compute: 79.77 | backward-params-all-reduce: 14.27 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.59 | batch-generator: 15.23
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2015000 | lm loss value: 1.681298E+00 | lm loss PPL: 5.372523E+00 | sop loss value: 7.200725E-02 | sop loss PPL: 1.074663E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2016000/10000000 | consumed samples:    258048000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631159E+00 | sop loss: 5.113006E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.76 | backward-compute: 79.80 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 14.29
 iteration  2017000/10000000 | consumed samples:    258176000 | elapsed time per iteration (ms): 250.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629279E+00 | sop loss: 5.220135E-02 | loss scale: 8192.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.24 | backward-compute: 79.86 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 24.66
 iteration  2018000/10000000 | consumed samples:    258304000 | elapsed time per iteration (ms): 247.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634382E+00 | sop loss: 5.287575E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.30 | backward-compute: 79.83 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 20.74
 iteration  2019000/10000000 | consumed samples:    258432000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632438E+00 | sop loss: 5.188382E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.44 | backward-compute: 79.83 | backward-params-all-reduce: 14.63 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.25 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.71 | batch-generator: 18.65
 iteration  2020000/10000000 | consumed samples:    258560000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634665E+00 | sop loss: 5.138608E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.91 | backward-compute: 79.83 | backward-params-all-reduce: 14.27 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.60 | batch-generator: 17.77
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2020000 | lm loss value: 1.701388E+00 | lm loss PPL: 5.481552E+00 | sop loss value: 7.562988E-02 | sop loss PPL: 1.078563E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2021000/10000000 | consumed samples:    258688000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630485E+00 | sop loss: 5.293468E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.07 | backward-compute: 79.79 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.55 | batch-generator: 14.89
 iteration  2022000/10000000 | consumed samples:    258816000 | elapsed time per iteration (ms): 246.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633384E+00 | sop loss: 5.239154E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.72 | backward-compute: 79.76 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 15.88
 iteration  2023000/10000000 | consumed samples:    258944000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634340E+00 | sop loss: 5.295090E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.00 | backward-compute: 79.79 | backward-params-all-reduce: 14.28 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 14.65
 iteration  2024000/10000000 | consumed samples:    259072000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632320E+00 | sop loss: 5.263098E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.33 | backward-compute: 79.90 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 16.39
 iteration  2025000/10000000 | consumed samples:    259200000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633632E+00 | sop loss: 5.339346E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.17 | backward-compute: 79.81 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.10
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2025000 | lm loss value: 1.682176E+00 | lm loss PPL: 5.377244E+00 | sop loss value: 6.503028E-02 | sop loss PPL: 1.067191E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2026000/10000000 | consumed samples:    259328000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630110E+00 | sop loss: 5.095982E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.23 | backward-compute: 79.78 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 16.80
 iteration  2027000/10000000 | consumed samples:    259456000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633769E+00 | sop loss: 5.214364E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.09 | backward-compute: 79.80 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 13.65
 iteration  2028000/10000000 | consumed samples:    259584000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630406E+00 | sop loss: 5.152865E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.89 | backward-compute: 79.79 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.43 | batch-generator: 17.01
 iteration  2029000/10000000 | consumed samples:    259712000 | elapsed time per iteration (ms): 247.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.637415E+00 | sop loss: 5.287682E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.21 | backward-compute: 79.81 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 18.19
 iteration  2030000/10000000 | consumed samples:    259840000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630331E+00 | sop loss: 5.275792E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.59 | backward-compute: 79.85 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 15.51
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2030000 | lm loss value: 1.668143E+00 | lm loss PPL: 5.302311E+00 | sop loss value: 6.042487E-02 | sop loss PPL: 1.062288E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2031000/10000000 | consumed samples:    259968000 | elapsed time per iteration (ms): 253.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629330E+00 | sop loss: 5.236640E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.12 | backward-compute: 79.72 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 13.10
 iteration  2032000/10000000 | consumed samples:    260096000 | elapsed time per iteration (ms): 252.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633350E+00 | sop loss: 5.130599E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.73 | backward-compute: 79.80 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 12.70
 iteration  2033000/10000000 | consumed samples:    260224000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634710E+00 | sop loss: 5.376471E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.28 | backward-compute: 79.85 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 15.39
 iteration  2034000/10000000 | consumed samples:    260352000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630961E+00 | sop loss: 5.226537E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.74 | backward-compute: 79.89 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.44
 iteration  2035000/10000000 | consumed samples:    260480000 | elapsed time per iteration (ms): 246.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628921E+00 | sop loss: 5.253766E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.56 | backward-compute: 79.82 | backward-params-all-reduce: 14.34 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.55 | batch-generator: 15.68
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2035000 | lm loss value: 1.687857E+00 | lm loss PPL: 5.407877E+00 | sop loss value: 7.194820E-02 | sop loss PPL: 1.074600E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2036000/10000000 | consumed samples:    260608000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.635322E+00 | sop loss: 5.282682E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.59 | backward-compute: 79.79 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 15.49
 iteration  2037000/10000000 | consumed samples:    260736000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632768E+00 | sop loss: 5.291324E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.28 | backward-compute: 79.81 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 18.64
 iteration  2038000/10000000 | consumed samples:    260864000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631212E+00 | sop loss: 5.369836E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.58 | backward-compute: 79.85 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 15.64
 iteration  2039000/10000000 | consumed samples:    260992000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632468E+00 | sop loss: 5.215012E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.33 | backward-compute: 79.88 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 18.10
 iteration  2040000/10000000 | consumed samples:    261120000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632496E+00 | sop loss: 5.201746E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.54 | backward-compute: 79.82 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 19.36
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2040000 | lm loss value: 1.667709E+00 | lm loss PPL: 5.300010E+00 | sop loss value: 5.924649E-02 | sop loss PPL: 1.061037E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2041000/10000000 | consumed samples:    261248000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633552E+00 | sop loss: 5.337352E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.08 | backward-compute: 79.86 | backward-params-all-reduce: 13.90 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.23
 iteration  2042000/10000000 | consumed samples:    261376000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630964E+00 | sop loss: 5.296919E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.93 | backward-compute: 79.78 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 24.13
 iteration  2043000/10000000 | consumed samples:    261504000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632338E+00 | sop loss: 5.272521E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.01 | backward-compute: 79.78 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.50 | batch-generator: 15.05
 iteration  2044000/10000000 | consumed samples:    261632000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629629E+00 | sop loss: 5.303209E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.36 | backward-compute: 79.81 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 17.16
 iteration  2045000/10000000 | consumed samples:    261760000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629628E+00 | sop loss: 5.224967E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.12 | backward-compute: 79.99 | backward-params-all-reduce: 13.83 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 13.78
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2045000 | lm loss value: 1.690490E+00 | lm loss PPL: 5.422139E+00 | sop loss value: 6.054372E-02 | sop loss PPL: 1.062414E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2046000/10000000 | consumed samples:    261888000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630460E+00 | sop loss: 5.224983E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.63 | backward-compute: 80.04 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 17.28
 iteration  2047000/10000000 | consumed samples:    262016000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629772E+00 | sop loss: 5.286790E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.75 | backward-compute: 79.77 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.43 | batch-generator: 17.22
 iteration  2048000/10000000 | consumed samples:    262144000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633710E+00 | sop loss: 5.163595E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.81 | backward-compute: 79.78 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 20.12
 iteration  2049000/10000000 | consumed samples:    262272000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630003E+00 | sop loss: 5.176393E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.34 | backward-compute: 79.74 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.47 | batch-generator: 15.39
 iteration  2050000/10000000 | consumed samples:    262400000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632144E+00 | sop loss: 5.236408E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.36 | backward-compute: 79.77 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 14.67
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2050000 | lm loss value: 1.642701E+00 | lm loss PPL: 5.169114E+00 | sop loss value: 7.879219E-02 | sop loss PPL: 1.081979E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 2050000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 2050000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2328.70
 iteration  2051000/10000000 | consumed samples:    262528000 | elapsed time per iteration (ms): 251.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633583E+00 | sop loss: 5.155783E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.18 | backward-compute: 79.81 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 17.61
 iteration  2052000/10000000 | consumed samples:    262656000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629370E+00 | sop loss: 5.257682E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.37 | backward-compute: 79.82 | backward-params-all-reduce: 14.85 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.89 | optimizer-unscale-and-check-inf: 2.31 | optimizer-clip-main-grad: 4.36 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.90 | batch-generator: 16.44
 iteration  2053000/10000000 | consumed samples:    262784000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633015E+00 | sop loss: 5.265018E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.67 | backward-compute: 79.85 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 20.66
 iteration  2054000/10000000 | consumed samples:    262912000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629843E+00 | sop loss: 5.159812E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.27 | backward-compute: 79.87 | backward-params-all-reduce: 14.63 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.26 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.72 | batch-generator: 16.19
 iteration  2055000/10000000 | consumed samples:    263040000 | elapsed time per iteration (ms): 251.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629078E+00 | sop loss: 5.190450E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.69 | backward-compute: 79.85 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 25.10
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2055000 | lm loss value: 1.647524E+00 | lm loss PPL: 5.194105E+00 | sop loss value: 7.539865E-02 | sop loss PPL: 1.078314E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2056000/10000000 | consumed samples:    263168000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634433E+00 | sop loss: 5.267037E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.96 | backward-compute: 79.83 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 16.74
 iteration  2057000/10000000 | consumed samples:    263296000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630924E+00 | sop loss: 5.246841E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.72 | backward-compute: 79.81 | backward-params-all-reduce: 13.87 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.62
 iteration  2058000/10000000 | consumed samples:    263424000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629160E+00 | sop loss: 5.161435E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.75 | backward-compute: 79.79 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 17.84
 iteration  2059000/10000000 | consumed samples:    263552000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628995E+00 | sop loss: 5.251028E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.82 | backward-compute: 79.85 | backward-params-all-reduce: 14.46 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.24 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.68 | batch-generator: 13.70
 iteration  2060000/10000000 | consumed samples:    263680000 | elapsed time per iteration (ms): 245.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630767E+00 | sop loss: 5.349700E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.97 | backward-compute: 79.91 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 17.29
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2060000 | lm loss value: 1.645115E+00 | lm loss PPL: 5.181605E+00 | sop loss value: 8.176658E-02 | sop loss PPL: 1.085202E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2061000/10000000 | consumed samples:    263808000 | elapsed time per iteration (ms): 250.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629895E+00 | sop loss: 5.262409E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.90 | backward-compute: 79.83 | backward-params-all-reduce: 14.28 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 19.22
 iteration  2062000/10000000 | consumed samples:    263936000 | elapsed time per iteration (ms): 246.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632252E+00 | sop loss: 5.099111E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.30 | backward-compute: 79.88 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 17.38
 iteration  2063000/10000000 | consumed samples:    264064000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632218E+00 | sop loss: 5.169914E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.49 | backward-compute: 79.81 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 16.09
 iteration  2064000/10000000 | consumed samples:    264192000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630855E+00 | sop loss: 5.257680E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.63 | backward-compute: 79.78 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 17.26
 iteration  2065000/10000000 | consumed samples:    264320000 | elapsed time per iteration (ms): 249.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633574E+00 | sop loss: 5.200327E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.23 | backward-compute: 79.72 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 15.62
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2065000 | lm loss value: 1.670190E+00 | lm loss PPL: 5.313176E+00 | sop loss value: 6.862415E-02 | sop loss PPL: 1.071034E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2066000/10000000 | consumed samples:    264448000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632031E+00 | sop loss: 5.167435E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.97 | backward-compute: 79.81 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.21
 iteration  2067000/10000000 | consumed samples:    264576000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628513E+00 | sop loss: 5.191540E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.52 | backward-compute: 79.82 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 20.76
 iteration  2068000/10000000 | consumed samples:    264704000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631092E+00 | sop loss: 5.202651E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.04 | backward-compute: 79.87 | backward-params-all-reduce: 14.39 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.53 | batch-generator: 18.08
 iteration  2069000/10000000 | consumed samples:    264832000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630459E+00 | sop loss: 5.145060E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.80 | backward-compute: 79.88 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.55 | batch-generator: 14.25
 iteration  2070000/10000000 | consumed samples:    264960000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628869E+00 | sop loss: 5.137526E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.07 | backward-compute: 79.78 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 15.17
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2070000 | lm loss value: 1.699086E+00 | lm loss PPL: 5.468947E+00 | sop loss value: 6.766819E-02 | sop loss PPL: 1.070010E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2071000/10000000 | consumed samples:    265088000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629348E+00 | sop loss: 5.298505E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.71 | backward-compute: 79.75 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.76 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 15.94
 iteration  2072000/10000000 | consumed samples:    265216000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631359E+00 | sop loss: 5.225289E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.54 | backward-compute: 79.82 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 17.34
 iteration  2073000/10000000 | consumed samples:    265344000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630910E+00 | sop loss: 5.015782E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.59 | backward-compute: 79.80 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 17.85
 iteration  2074000/10000000 | consumed samples:    265472000 | elapsed time per iteration (ms): 246.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631940E+00 | sop loss: 5.222293E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.70 | backward-compute: 79.84 | backward-params-all-reduce: 14.28 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.53 | batch-generator: 15.35
 iteration  2075000/10000000 | consumed samples:    265600000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632887E+00 | sop loss: 5.341563E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.91 | backward-compute: 79.90 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 14.57
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2075000 | lm loss value: 1.708604E+00 | lm loss PPL: 5.521251E+00 | sop loss value: 5.994076E-02 | sop loss PPL: 1.061774E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2076000/10000000 | consumed samples:    265728000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633315E+00 | sop loss: 5.272883E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.50 | backward-compute: 79.80 | backward-params-all-reduce: 14.27 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 15.57
 iteration  2077000/10000000 | consumed samples:    265856000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630516E+00 | sop loss: 5.240455E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.44 | backward-compute: 79.82 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.50 | batch-generator: 13.78
 iteration  2078000/10000000 | consumed samples:    265984000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627476E+00 | sop loss: 5.187984E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.19 | backward-compute: 79.79 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.77
 iteration  2079000/10000000 | consumed samples:    266112000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629052E+00 | sop loss: 5.353156E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.22 | backward-compute: 79.79 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 16.85
 iteration  2080000/10000000 | consumed samples:    266240000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631125E+00 | sop loss: 5.227470E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.66 | backward-compute: 79.80 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 16.13
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2080000 | lm loss value: 1.690404E+00 | lm loss PPL: 5.421670E+00 | sop loss value: 6.441687E-02 | sop loss PPL: 1.066537E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2081000/10000000 | consumed samples:    266368000 | elapsed time per iteration (ms): 251.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628074E+00 | sop loss: 5.147958E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.01 | backward-compute: 79.82 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 13.92
 iteration  2082000/10000000 | consumed samples:    266496000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631503E+00 | sop loss: 5.228736E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.33 | backward-compute: 79.82 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.95
 iteration  2083000/10000000 | consumed samples:    266624000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630693E+00 | sop loss: 5.160053E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.13 | backward-compute: 79.78 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 15.06
 iteration  2084000/10000000 | consumed samples:    266752000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.634422E+00 | sop loss: 5.253207E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.62 | backward-compute: 79.82 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 17.49
 iteration  2085000/10000000 | consumed samples:    266880000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630632E+00 | sop loss: 5.207856E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.66 | backward-compute: 79.85 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 14.67
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2085000 | lm loss value: 1.668152E+00 | lm loss PPL: 5.302360E+00 | sop loss value: 6.335192E-02 | sop loss PPL: 1.065402E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2086000/10000000 | consumed samples:    267008000 | elapsed time per iteration (ms): 250.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630111E+00 | sop loss: 5.168385E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.05 | backward-compute: 79.89 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.46 | batch-generator: 24.39
 iteration  2087000/10000000 | consumed samples:    267136000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627903E+00 | sop loss: 5.149786E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.47 | backward-compute: 79.86 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.50 | batch-generator: 14.95
 iteration  2088000/10000000 | consumed samples:    267264000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626571E+00 | sop loss: 5.269983E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.95 | backward-compute: 79.80 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.69
 iteration  2089000/10000000 | consumed samples:    267392000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631603E+00 | sop loss: 5.221688E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.78 | backward-compute: 79.79 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 15.54
 iteration  2090000/10000000 | consumed samples:    267520000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632985E+00 | sop loss: 5.267672E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.62 | backward-compute: 79.87 | backward-params-all-reduce: 13.92 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 18.86
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2090000 | lm loss value: 1.656247E+00 | lm loss PPL: 5.239610E+00 | sop loss value: 4.983083E-02 | sop loss PPL: 1.051093E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2091000/10000000 | consumed samples:    267648000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629588E+00 | sop loss: 5.174785E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.12 | backward-compute: 79.85 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 16.30
 iteration  2092000/10000000 | consumed samples:    267776000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629378E+00 | sop loss: 5.196877E-02 | loss scale: 8192.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.42 | backward-compute: 79.85 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 16.62
 iteration  2093000/10000000 | consumed samples:    267904000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628442E+00 | sop loss: 5.195876E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.51 | backward-compute: 79.76 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 25.80
 iteration  2094000/10000000 | consumed samples:    268032000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631676E+00 | sop loss: 5.120259E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.02 | backward-compute: 79.86 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 16.35
 iteration  2095000/10000000 | consumed samples:    268160000 | elapsed time per iteration (ms): 246.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629785E+00 | sop loss: 5.231438E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.30 | backward-compute: 79.81 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.50
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2095000 | lm loss value: 1.669976E+00 | lm loss PPL: 5.312043E+00 | sop loss value: 6.691596E-02 | sop loss PPL: 1.069206E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2096000/10000000 | consumed samples:    268288000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629481E+00 | sop loss: 5.268219E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.28 | backward-compute: 79.83 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 16.15
 iteration  2097000/10000000 | consumed samples:    268416000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630805E+00 | sop loss: 5.252694E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.10 | backward-compute: 79.82 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 16.83
 iteration  2098000/10000000 | consumed samples:    268544000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631275E+00 | sop loss: 5.181970E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.96 | backward-compute: 79.83 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 13.75
 iteration  2099000/10000000 | consumed samples:    268672000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627762E+00 | sop loss: 5.275373E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.16 | backward-compute: 79.94 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 17.71
 iteration  2100000/10000000 | consumed samples:    268800000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628771E+00 | sop loss: 5.166848E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.59 | backward-compute: 79.82 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.45 | batch-generator: 14.12
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2100000 | lm loss value: 1.702927E+00 | lm loss PPL: 5.489993E+00 | sop loss value: 5.761256E-02 | sop loss PPL: 1.059304E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 2100000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 2100000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2294.12
 iteration  2101000/10000000 | consumed samples:    268928000 | elapsed time per iteration (ms): 252.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630608E+00 | sop loss: 5.332312E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.46 | backward-compute: 79.89 | backward-params-all-reduce: 14.74 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.88 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.34 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.86 | batch-generator: 17.70
 iteration  2102000/10000000 | consumed samples:    269056000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632077E+00 | sop loss: 5.162310E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.71 | backward-compute: 79.78 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 12.14
 iteration  2103000/10000000 | consumed samples:    269184000 | elapsed time per iteration (ms): 249.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628538E+00 | sop loss: 5.171546E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.13 | backward-compute: 79.76 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 13.74
 iteration  2104000/10000000 | consumed samples:    269312000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628686E+00 | sop loss: 5.206545E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.16 | backward-compute: 79.84 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 16.51
 iteration  2105000/10000000 | consumed samples:    269440000 | elapsed time per iteration (ms): 249.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629861E+00 | sop loss: 5.287140E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.13 | backward-compute: 79.87 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 26.29
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2105000 | lm loss value: 1.661037E+00 | lm loss PPL: 5.264769E+00 | sop loss value: 6.832261E-02 | sop loss PPL: 1.070711E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2106000/10000000 | consumed samples:    269568000 | elapsed time per iteration (ms): 250.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629896E+00 | sop loss: 5.181003E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.05 | backward-compute: 79.84 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 17.65
 iteration  2107000/10000000 | consumed samples:    269696000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629648E+00 | sop loss: 5.207939E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.41 | backward-compute: 79.83 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 26.93
 iteration  2108000/10000000 | consumed samples:    269824000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628334E+00 | sop loss: 5.120638E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.14 | backward-compute: 79.83 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 17.79
 iteration  2109000/10000000 | consumed samples:    269952000 | elapsed time per iteration (ms): 246.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631770E+00 | sop loss: 5.259749E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.14 | backward-compute: 79.81 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 17.26
 iteration  2110000/10000000 | consumed samples:    270080000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630131E+00 | sop loss: 5.290638E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.92 | backward-compute: 79.79 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 14.26
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2110000 | lm loss value: 1.688424E+00 | lm loss PPL: 5.410948E+00 | sop loss value: 8.374963E-02 | sop loss PPL: 1.087357E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2111000/10000000 | consumed samples:    270208000 | elapsed time per iteration (ms): 253.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629181E+00 | sop loss: 5.277328E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.32 | backward-compute: 79.78 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 12.93
 iteration  2112000/10000000 | consumed samples:    270336000 | elapsed time per iteration (ms): 253.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631508E+00 | sop loss: 5.278095E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 140.83 | backward-compute: 79.78 | backward-params-all-reduce: 14.41 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 13.02
 iteration  2113000/10000000 | consumed samples:    270464000 | elapsed time per iteration (ms): 252.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630184E+00 | sop loss: 5.299270E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.46 | backward-compute: 79.86 | backward-params-all-reduce: 14.41 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 23.75
 iteration  2114000/10000000 | consumed samples:    270592000 | elapsed time per iteration (ms): 255.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631731E+00 | sop loss: 5.167873E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 142.19 | backward-compute: 79.78 | backward-params-all-reduce: 14.51 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 19.72
 iteration  2115000/10000000 | consumed samples:    270720000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628939E+00 | sop loss: 5.154176E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.59 | backward-compute: 79.93 | backward-params-all-reduce: 14.38 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.52 | batch-generator: 16.87
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2115000 | lm loss value: 1.656015E+00 | lm loss PPL: 5.238394E+00 | sop loss value: 8.457066E-02 | sop loss PPL: 1.088250E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2116000/10000000 | consumed samples:    270848000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625664E+00 | sop loss: 5.255421E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.99 | backward-compute: 79.86 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 16.13
 iteration  2117000/10000000 | consumed samples:    270976000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629133E+00 | sop loss: 5.265463E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.10 | backward-compute: 79.81 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 13.16
 iteration  2118000/10000000 | consumed samples:    271104000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630537E+00 | sop loss: 5.207440E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.09 | backward-compute: 79.77 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 15.74
 iteration  2119000/10000000 | consumed samples:    271232000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627605E+00 | sop loss: 5.306089E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.84 | backward-compute: 79.86 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.73
 iteration  2120000/10000000 | consumed samples:    271360000 | elapsed time per iteration (ms): 249.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627387E+00 | sop loss: 5.185842E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.04 | backward-compute: 79.87 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 25.88
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2120000 | lm loss value: 1.630487E+00 | lm loss PPL: 5.106363E+00 | sop loss value: 6.647431E-02 | sop loss PPL: 1.068734E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2121000/10000000 | consumed samples:    271488000 | elapsed time per iteration (ms): 251.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629436E+00 | sop loss: 5.244757E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.89 | backward-compute: 79.86 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 18.96
 iteration  2122000/10000000 | consumed samples:    271616000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629714E+00 | sop loss: 5.245041E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.54 | backward-compute: 79.85 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 16.42
 iteration  2123000/10000000 | consumed samples:    271744000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633234E+00 | sop loss: 5.133906E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.04 | backward-compute: 79.81 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.46 | batch-generator: 21.65
 iteration  2124000/10000000 | consumed samples:    271872000 | elapsed time per iteration (ms): 250.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628541E+00 | sop loss: 5.237938E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.94 | backward-compute: 79.82 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 31.12
 iteration  2125000/10000000 | consumed samples:    272000000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626255E+00 | sop loss: 5.233398E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.78 | backward-compute: 79.78 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 21.88
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2125000 | lm loss value: 1.697805E+00 | lm loss PPL: 5.461947E+00 | sop loss value: 5.929425E-02 | sop loss PPL: 1.061087E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2126000/10000000 | consumed samples:    272128000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627650E+00 | sop loss: 5.151575E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.59 | backward-compute: 79.80 | backward-params-all-reduce: 14.37 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 15.39
 iteration  2127000/10000000 | consumed samples:    272256000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628250E+00 | sop loss: 5.271999E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.62 | backward-compute: 79.87 | backward-params-all-reduce: 14.29 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.59 | batch-generator: 15.73
 iteration  2128000/10000000 | consumed samples:    272384000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631217E+00 | sop loss: 5.297327E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.51 | backward-compute: 79.87 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 16.39
 iteration  2129000/10000000 | consumed samples:    272512000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629173E+00 | sop loss: 5.251761E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.88 | backward-compute: 79.85 | backward-params-all-reduce: 14.74 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.88 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.36 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.87 | batch-generator: 15.41
 iteration  2130000/10000000 | consumed samples:    272640000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625136E+00 | sop loss: 5.179107E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.44 | backward-compute: 79.81 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.44 | batch-generator: 16.62
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2130000 | lm loss value: 1.661236E+00 | lm loss PPL: 5.265814E+00 | sop loss value: 5.775730E-02 | sop loss PPL: 1.059458E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2131000/10000000 | consumed samples:    272768000 | elapsed time per iteration (ms): 251.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627383E+00 | sop loss: 5.136718E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.80 | backward-compute: 79.78 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 15.68
 iteration  2132000/10000000 | consumed samples:    272896000 | elapsed time per iteration (ms): 250.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627860E+00 | sop loss: 5.235258E-02 | loss scale: 8192.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.27 | backward-compute: 79.76 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 17.62
 iteration  2133000/10000000 | consumed samples:    273024000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627753E+00 | sop loss: 5.289517E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.49 | backward-compute: 79.80 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.19
 iteration  2134000/10000000 | consumed samples:    273152000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625666E+00 | sop loss: 5.298009E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.31 | backward-compute: 79.89 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 14.27
 iteration  2135000/10000000 | consumed samples:    273280000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629717E+00 | sop loss: 5.284565E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.85 | backward-compute: 79.82 | backward-params-all-reduce: 14.81 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.87 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.32 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.81 | batch-generator: 13.40
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2135000 | lm loss value: 1.661471E+00 | lm loss PPL: 5.267053E+00 | sop loss value: 6.895586E-02 | sop loss PPL: 1.071389E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2136000/10000000 | consumed samples:    273408000 | elapsed time per iteration (ms): 250.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630951E+00 | sop loss: 5.205341E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.89 | backward-compute: 79.84 | backward-params-all-reduce: 14.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.60 | batch-generator: 13.41
 iteration  2137000/10000000 | consumed samples:    273536000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628907E+00 | sop loss: 5.143398E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.47 | backward-compute: 79.82 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 13.56
 iteration  2138000/10000000 | consumed samples:    273664000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633168E+00 | sop loss: 5.221414E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.12 | backward-compute: 79.91 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.30
 iteration  2139000/10000000 | consumed samples:    273792000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627583E+00 | sop loss: 5.132218E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.25 | backward-compute: 79.85 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.96
 iteration  2140000/10000000 | consumed samples:    273920000 | elapsed time per iteration (ms): 250.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629347E+00 | sop loss: 5.145898E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.41 | backward-compute: 79.81 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 14.39
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2140000 | lm loss value: 1.667593E+00 | lm loss PPL: 5.299398E+00 | sop loss value: 7.432122E-02 | sop loss PPL: 1.077153E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2141000/10000000 | consumed samples:    274048000 | elapsed time per iteration (ms): 251.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625810E+00 | sop loss: 5.142432E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.36 | backward-compute: 79.79 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.46 | batch-generator: 19.52
 iteration  2142000/10000000 | consumed samples:    274176000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628842E+00 | sop loss: 5.154753E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.43 | backward-compute: 79.76 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 13.28
 iteration  2143000/10000000 | consumed samples:    274304000 | elapsed time per iteration (ms): 246.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626978E+00 | sop loss: 5.190280E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.84 | backward-compute: 79.84 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.57 | batch-generator: 17.15
 iteration  2144000/10000000 | consumed samples:    274432000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628455E+00 | sop loss: 5.224806E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.73 | backward-compute: 79.85 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 17.76
 iteration  2145000/10000000 | consumed samples:    274560000 | elapsed time per iteration (ms): 249.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628507E+00 | sop loss: 5.303084E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.80 | backward-compute: 79.82 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.45 | batch-generator: 14.42
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2145000 | lm loss value: 1.665130E+00 | lm loss PPL: 5.286361E+00 | sop loss value: 6.853449E-02 | sop loss PPL: 1.070938E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2146000/10000000 | consumed samples:    274688000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629408E+00 | sop loss: 5.135994E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.83 | backward-compute: 79.80 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 16.28
 iteration  2147000/10000000 | consumed samples:    274816000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629359E+00 | sop loss: 5.380213E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.40 | backward-compute: 79.83 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 18.07
 iteration  2148000/10000000 | consumed samples:    274944000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631350E+00 | sop loss: 5.098105E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.40 | backward-compute: 79.75 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 15.91
 iteration  2149000/10000000 | consumed samples:    275072000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626591E+00 | sop loss: 5.195098E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.67 | backward-compute: 79.79 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 20.32
 iteration  2150000/10000000 | consumed samples:    275200000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629712E+00 | sop loss: 5.239437E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.87 | backward-compute: 79.86 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 14.82
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2150000 | lm loss value: 1.685153E+00 | lm loss PPL: 5.393274E+00 | sop loss value: 6.275165E-02 | sop loss PPL: 1.064762E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 2150000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 2150000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2311.95
 iteration  2151000/10000000 | consumed samples:    275328000 | elapsed time per iteration (ms): 252.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628472E+00 | sop loss: 5.254151E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.77 | backward-compute: 79.87 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 16.22
 iteration  2152000/10000000 | consumed samples:    275456000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625861E+00 | sop loss: 5.275165E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.96 | backward-compute: 79.92 | backward-params-all-reduce: 14.27 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.21 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.63 | batch-generator: 15.98
 iteration  2153000/10000000 | consumed samples:    275584000 | elapsed time per iteration (ms): 250.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629913E+00 | sop loss: 5.098075E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.66 | backward-compute: 79.87 | backward-params-all-reduce: 14.41 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.57 | batch-generator: 17.50
 iteration  2154000/10000000 | consumed samples:    275712000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628715E+00 | sop loss: 5.160433E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.48 | backward-compute: 79.76 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 15.28
 iteration  2155000/10000000 | consumed samples:    275840000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628726E+00 | sop loss: 5.233004E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.39 | backward-compute: 79.81 | backward-params-all-reduce: 14.63 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.28 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.74 | batch-generator: 17.50
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2155000 | lm loss value: 1.681026E+00 | lm loss PPL: 5.371066E+00 | sop loss value: 5.419991E-02 | sop loss PPL: 1.055696E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2156000/10000000 | consumed samples:    275968000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629064E+00 | sop loss: 5.150703E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.93 | backward-compute: 79.80 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 17.99
 iteration  2157000/10000000 | consumed samples:    276096000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626082E+00 | sop loss: 5.097107E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.62 | backward-compute: 79.83 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.27
 iteration  2158000/10000000 | consumed samples:    276224000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629225E+00 | sop loss: 5.193319E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.47 | backward-compute: 79.85 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 15.42
 iteration  2159000/10000000 | consumed samples:    276352000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626165E+00 | sop loss: 5.212582E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.38 | backward-compute: 79.80 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 14.41
 iteration  2160000/10000000 | consumed samples:    276480000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.633101E+00 | sop loss: 5.125525E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.56 | backward-compute: 79.90 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 17.63
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2160000 | lm loss value: 1.715703E+00 | lm loss PPL: 5.560583E+00 | sop loss value: 6.231660E-02 | sop loss PPL: 1.064299E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2161000/10000000 | consumed samples:    276608000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629564E+00 | sop loss: 5.324166E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.74 | backward-compute: 79.84 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.54 | batch-generator: 18.50
 iteration  2162000/10000000 | consumed samples:    276736000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628107E+00 | sop loss: 5.109106E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.79 | backward-compute: 79.83 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 13.36
 iteration  2163000/10000000 | consumed samples:    276864000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625695E+00 | sop loss: 5.199265E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.10 | backward-compute: 79.79 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 14.11
 iteration  2164000/10000000 | consumed samples:    276992000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626600E+00 | sop loss: 5.170383E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.13 | backward-compute: 79.76 | backward-params-all-reduce: 14.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 14.12
 iteration  2165000/10000000 | consumed samples:    277120000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629109E+00 | sop loss: 5.077468E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.36 | backward-compute: 79.75 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 14.56
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2165000 | lm loss value: 1.666862E+00 | lm loss PPL: 5.295523E+00 | sop loss value: 6.907953E-02 | sop loss PPL: 1.071521E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2166000/10000000 | consumed samples:    277248000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629893E+00 | sop loss: 5.201289E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.29 | backward-compute: 79.83 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 16.52
 iteration  2167000/10000000 | consumed samples:    277376000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626062E+00 | sop loss: 5.310493E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.43 | backward-compute: 79.82 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 13.42
 iteration  2168000/10000000 | consumed samples:    277504000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631304E+00 | sop loss: 5.142425E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.86 | backward-compute: 79.85 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.53 | batch-generator: 13.57
 iteration  2169000/10000000 | consumed samples:    277632000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628324E+00 | sop loss: 5.215128E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.31 | backward-compute: 79.84 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.57
 iteration  2170000/10000000 | consumed samples:    277760000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629472E+00 | sop loss: 5.208002E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.91 | backward-compute: 79.84 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.47 | batch-generator: 20.93
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2170000 | lm loss value: 1.677043E+00 | lm loss PPL: 5.349713E+00 | sop loss value: 8.314376E-02 | sop loss PPL: 1.086698E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2171000/10000000 | consumed samples:    277888000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624671E+00 | sop loss: 5.195676E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.27 | backward-compute: 79.84 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 13.63
 iteration  2172000/10000000 | consumed samples:    278016000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632567E+00 | sop loss: 5.163626E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.88 | backward-compute: 79.78 | backward-params-all-reduce: 14.31 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.60 | batch-generator: 13.33
 iteration  2173000/10000000 | consumed samples:    278144000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629645E+00 | sop loss: 5.114929E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.85 | backward-compute: 79.75 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 13.21
 iteration  2174000/10000000 | consumed samples:    278272000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627947E+00 | sop loss: 5.162559E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.48 | backward-compute: 79.80 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 13.36
 iteration  2175000/10000000 | consumed samples:    278400000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631621E+00 | sop loss: 5.327015E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.47 | backward-compute: 79.77 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 16.29
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2175000 | lm loss value: 1.669964E+00 | lm loss PPL: 5.311975E+00 | sop loss value: 6.042350E-02 | sop loss PPL: 1.062286E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2176000/10000000 | consumed samples:    278528000 | elapsed time per iteration (ms): 251.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627029E+00 | sop loss: 5.204810E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.73 | backward-compute: 79.81 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 19.03
 iteration  2177000/10000000 | consumed samples:    278656000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628117E+00 | sop loss: 5.141555E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.63 | backward-compute: 79.79 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 14.08
 iteration  2178000/10000000 | consumed samples:    278784000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629058E+00 | sop loss: 5.154398E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.96 | backward-compute: 79.93 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.44 | batch-generator: 15.46
 iteration  2179000/10000000 | consumed samples:    278912000 | elapsed time per iteration (ms): 250.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629512E+00 | sop loss: 5.181102E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.06 | backward-compute: 79.80 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.69
 iteration  2180000/10000000 | consumed samples:    279040000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629185E+00 | sop loss: 5.174333E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.95 | backward-compute: 79.85 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.53 | batch-generator: 19.05
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2180000 | lm loss value: 1.668431E+00 | lm loss PPL: 5.303837E+00 | sop loss value: 6.306594E-02 | sop loss PPL: 1.065097E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2181000/10000000 | consumed samples:    279168000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628307E+00 | sop loss: 5.215356E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.89 | backward-compute: 79.80 | backward-params-all-reduce: 14.36 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.60 | batch-generator: 18.74
 iteration  2182000/10000000 | consumed samples:    279296000 | elapsed time per iteration (ms): 246.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627014E+00 | sop loss: 5.264116E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.51 | backward-compute: 79.79 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.48 | batch-generator: 15.12
 iteration  2183000/10000000 | consumed samples:    279424000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628029E+00 | sop loss: 5.111160E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.95 | backward-compute: 79.76 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.91
 iteration  2184000/10000000 | consumed samples:    279552000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625994E+00 | sop loss: 5.157080E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.36 | backward-compute: 79.76 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 16.21
 iteration  2185000/10000000 | consumed samples:    279680000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627787E+00 | sop loss: 5.203135E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.07 | backward-compute: 79.78 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 14.95
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2185000 | lm loss value: 1.667708E+00 | lm loss PPL: 5.300005E+00 | sop loss value: 6.473408E-02 | sop loss PPL: 1.066875E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2186000/10000000 | consumed samples:    279808000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630732E+00 | sop loss: 5.248794E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.28 | backward-compute: 79.93 | backward-params-all-reduce: 14.46 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.87 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.30 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.79 | batch-generator: 18.80
 iteration  2187000/10000000 | consumed samples:    279936000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627719E+00 | sop loss: 5.209532E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.47 | backward-compute: 79.79 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 22.46
 iteration  2188000/10000000 | consumed samples:    280064000 | elapsed time per iteration (ms): 246.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.631108E+00 | sop loss: 5.111263E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.57 | backward-compute: 79.81 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 18.85
 iteration  2189000/10000000 | consumed samples:    280192000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627818E+00 | sop loss: 5.185435E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.45 | backward-compute: 79.82 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.51 | batch-generator: 17.38
 iteration  2190000/10000000 | consumed samples:    280320000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627743E+00 | sop loss: 5.189106E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.98 | backward-compute: 79.84 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 25.30
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2190000 | lm loss value: 1.659950E+00 | lm loss PPL: 5.259049E+00 | sop loss value: 6.590484E-02 | sop loss PPL: 1.068125E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2191000/10000000 | consumed samples:    280448000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627080E+00 | sop loss: 5.316335E-02 | loss scale: 8192.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.35 | backward-compute: 79.79 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 15.68
 iteration  2192000/10000000 | consumed samples:    280576000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628243E+00 | sop loss: 5.243455E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.35 | backward-compute: 79.77 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.35
 iteration  2193000/10000000 | consumed samples:    280704000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627229E+00 | sop loss: 5.093718E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.23 | backward-compute: 79.82 | backward-params-all-reduce: 14.29 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 16.29
 iteration  2194000/10000000 | consumed samples:    280832000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627986E+00 | sop loss: 5.194011E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.15 | backward-compute: 79.81 | backward-params-all-reduce: 14.39 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.21 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.62 | batch-generator: 14.06
 iteration  2195000/10000000 | consumed samples:    280960000 | elapsed time per iteration (ms): 250.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626375E+00 | sop loss: 5.157702E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.06 | backward-compute: 79.77 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 14.60
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2195000 | lm loss value: 1.684804E+00 | lm loss PPL: 5.391396E+00 | sop loss value: 5.731652E-02 | sop loss PPL: 1.058991E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2196000/10000000 | consumed samples:    281088000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627849E+00 | sop loss: 5.316208E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.14 | backward-compute: 79.82 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 16.71
 iteration  2197000/10000000 | consumed samples:    281216000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627154E+00 | sop loss: 5.201043E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.03 | backward-compute: 79.91 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 16.41
 iteration  2198000/10000000 | consumed samples:    281344000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624173E+00 | sop loss: 5.162541E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.39 | backward-compute: 79.97 | backward-params-all-reduce: 13.90 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 18.07
 iteration  2199000/10000000 | consumed samples:    281472000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.630480E+00 | sop loss: 5.213320E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.99 | backward-compute: 79.86 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 19.88
 iteration  2200000/10000000 | consumed samples:    281600000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626746E+00 | sop loss: 5.233088E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.83 | backward-compute: 79.79 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.24 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 17.31
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2200000 | lm loss value: 1.681205E+00 | lm loss PPL: 5.372026E+00 | sop loss value: 6.486028E-02 | sop loss PPL: 1.067010E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 2200000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 2200000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2305.94
 iteration  2201000/10000000 | consumed samples:    281728000 | elapsed time per iteration (ms): 251.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627083E+00 | sop loss: 5.214118E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.30 | backward-compute: 79.88 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 15.02
 iteration  2202000/10000000 | consumed samples:    281856000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627905E+00 | sop loss: 5.187039E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.74 | backward-compute: 79.84 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.92
 iteration  2203000/10000000 | consumed samples:    281984000 | elapsed time per iteration (ms): 250.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626050E+00 | sop loss: 5.071105E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.90 | backward-compute: 79.84 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 12.25
 iteration  2204000/10000000 | consumed samples:    282112000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624613E+00 | sop loss: 5.364006E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.37 | backward-compute: 79.90 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 13.06
 iteration  2205000/10000000 | consumed samples:    282240000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627213E+00 | sop loss: 5.091769E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.41 | backward-compute: 79.85 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 18.93
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2205000 | lm loss value: 1.642021E+00 | lm loss PPL: 5.165599E+00 | sop loss value: 5.386815E-02 | sop loss PPL: 1.055345E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2206000/10000000 | consumed samples:    282368000 | elapsed time per iteration (ms): 253.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623707E+00 | sop loss: 5.123367E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.78 | backward-compute: 79.79 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 15.46
 iteration  2207000/10000000 | consumed samples:    282496000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629929E+00 | sop loss: 5.233122E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.73 | backward-compute: 79.89 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 18.23
 iteration  2208000/10000000 | consumed samples:    282624000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625008E+00 | sop loss: 5.285412E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.59 | backward-compute: 79.93 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.26
 iteration  2209000/10000000 | consumed samples:    282752000 | elapsed time per iteration (ms): 249.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627558E+00 | sop loss: 5.238727E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.35 | backward-compute: 79.89 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 22.96
 iteration  2210000/10000000 | consumed samples:    282880000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626646E+00 | sop loss: 5.245221E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.66 | backward-compute: 79.75 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 15.17
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2210000 | lm loss value: 1.685500E+00 | lm loss PPL: 5.395145E+00 | sop loss value: 4.777687E-02 | sop loss PPL: 1.048937E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2211000/10000000 | consumed samples:    283008000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623962E+00 | sop loss: 5.177364E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.53 | backward-compute: 79.85 | backward-params-all-reduce: 13.88 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 14.84
 iteration  2212000/10000000 | consumed samples:    283136000 | elapsed time per iteration (ms): 251.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626532E+00 | sop loss: 5.140561E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.51 | backward-compute: 79.73 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 12.41
 iteration  2213000/10000000 | consumed samples:    283264000 | elapsed time per iteration (ms): 251.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628245E+00 | sop loss: 5.176604E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.72 | backward-compute: 79.78 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 14.03
 iteration  2214000/10000000 | consumed samples:    283392000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626895E+00 | sop loss: 5.119531E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.47 | backward-compute: 79.83 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 13.30
 iteration  2215000/10000000 | consumed samples:    283520000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626512E+00 | sop loss: 5.222000E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.33 | backward-compute: 79.86 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 14.51
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2215000 | lm loss value: 1.675766E+00 | lm loss PPL: 5.342886E+00 | sop loss value: 5.589951E-02 | sop loss PPL: 1.057491E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2216000/10000000 | consumed samples:    283648000 | elapsed time per iteration (ms): 251.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625977E+00 | sop loss: 5.227029E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.25 | backward-compute: 79.79 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 18.32
 iteration  2217000/10000000 | consumed samples:    283776000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626786E+00 | sop loss: 5.395880E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.69 | backward-compute: 79.81 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 14.96
 iteration  2218000/10000000 | consumed samples:    283904000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624028E+00 | sop loss: 5.211977E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.56 | backward-compute: 79.82 | backward-params-all-reduce: 13.90 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 24.25
 iteration  2219000/10000000 | consumed samples:    284032000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625568E+00 | sop loss: 5.134985E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.34 | backward-compute: 79.81 | backward-params-all-reduce: 13.91 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 16.21
 iteration  2220000/10000000 | consumed samples:    284160000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626437E+00 | sop loss: 5.339526E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.14 | backward-compute: 79.81 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 17.40
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2220000 | lm loss value: 1.669497E+00 | lm loss PPL: 5.309494E+00 | sop loss value: 7.602867E-02 | sop loss PPL: 1.078994E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2221000/10000000 | consumed samples:    284288000 | elapsed time per iteration (ms): 250.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628507E+00 | sop loss: 5.057484E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.24 | backward-compute: 79.85 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 16.25
 iteration  2222000/10000000 | consumed samples:    284416000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627247E+00 | sop loss: 5.192896E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.28 | backward-compute: 79.87 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 16.71
 iteration  2223000/10000000 | consumed samples:    284544000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.632535E+00 | sop loss: 5.153432E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.81 | backward-compute: 79.81 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 16.01
 iteration  2224000/10000000 | consumed samples:    284672000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625995E+00 | sop loss: 5.114661E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.80 | backward-compute: 79.85 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 13.71
 iteration  2225000/10000000 | consumed samples:    284800000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625600E+00 | sop loss: 5.229492E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.87 | backward-compute: 79.80 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 17.70
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2225000 | lm loss value: 1.655446E+00 | lm loss PPL: 5.235415E+00 | sop loss value: 5.783860E-02 | sop loss PPL: 1.059544E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2226000/10000000 | consumed samples:    284928000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626041E+00 | sop loss: 5.231543E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.08 | backward-compute: 79.79 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 20.78
 iteration  2227000/10000000 | consumed samples:    285056000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628828E+00 | sop loss: 5.238461E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.42 | backward-compute: 79.81 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 13.51
 iteration  2228000/10000000 | consumed samples:    285184000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625492E+00 | sop loss: 5.318146E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.85 | backward-compute: 79.91 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 14.61
 iteration  2229000/10000000 | consumed samples:    285312000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624833E+00 | sop loss: 5.198775E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.59 | backward-compute: 79.79 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 18.95
 iteration  2230000/10000000 | consumed samples:    285440000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623417E+00 | sop loss: 5.148670E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.77 | backward-compute: 79.82 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 11.97
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2230000 | lm loss value: 1.699193E+00 | lm loss PPL: 5.469530E+00 | sop loss value: 6.782430E-02 | sop loss PPL: 1.070177E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2231000/10000000 | consumed samples:    285568000 | elapsed time per iteration (ms): 250.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626827E+00 | sop loss: 5.111798E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.78 | backward-compute: 79.80 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 14.32
 iteration  2232000/10000000 | consumed samples:    285696000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625396E+00 | sop loss: 5.178451E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.56 | backward-compute: 79.81 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.42
 iteration  2233000/10000000 | consumed samples:    285824000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627509E+00 | sop loss: 5.187445E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.12 | backward-compute: 79.82 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.50
 iteration  2234000/10000000 | consumed samples:    285952000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625101E+00 | sop loss: 5.154853E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.67 | backward-compute: 79.82 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 14.82
 iteration  2235000/10000000 | consumed samples:    286080000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627687E+00 | sop loss: 5.114544E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.18 | backward-compute: 79.82 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 15.56
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2235000 | lm loss value: 1.650513E+00 | lm loss PPL: 5.209652E+00 | sop loss value: 5.555486E-02 | sop loss PPL: 1.057127E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2236000/10000000 | consumed samples:    286208000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622686E+00 | sop loss: 5.067007E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.96 | backward-compute: 79.89 | backward-params-all-reduce: 14.34 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.59 | batch-generator: 19.07
 iteration  2237000/10000000 | consumed samples:    286336000 | elapsed time per iteration (ms): 246.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627365E+00 | sop loss: 5.306179E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.71 | backward-compute: 79.85 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 13.83
 iteration  2238000/10000000 | consumed samples:    286464000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625550E+00 | sop loss: 5.138754E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.43 | backward-compute: 79.83 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 13.41
 iteration  2239000/10000000 | consumed samples:    286592000 | elapsed time per iteration (ms): 251.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627287E+00 | sop loss: 5.219179E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.26 | backward-compute: 79.69 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 14.69
 iteration  2240000/10000000 | consumed samples:    286720000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625485E+00 | sop loss: 5.235684E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.19 | backward-compute: 79.82 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 14.73
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2240000 | lm loss value: 1.668459E+00 | lm loss PPL: 5.303990E+00 | sop loss value: 6.622493E-02 | sop loss PPL: 1.068467E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2241000/10000000 | consumed samples:    286848000 | elapsed time per iteration (ms): 251.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626257E+00 | sop loss: 5.109209E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.55 | backward-compute: 79.86 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.77
 iteration  2242000/10000000 | consumed samples:    286976000 | elapsed time per iteration (ms): 245.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625189E+00 | sop loss: 5.316160E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.13 | backward-compute: 79.88 | backward-params-all-reduce: 14.60 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.25 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.69 | batch-generator: 16.41
 iteration  2243000/10000000 | consumed samples:    287104000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626571E+00 | sop loss: 5.081711E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.56 | backward-compute: 79.84 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 16.26
 iteration  2244000/10000000 | consumed samples:    287232000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625373E+00 | sop loss: 5.224625E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.22 | backward-compute: 79.79 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.86
 iteration  2245000/10000000 | consumed samples:    287360000 | elapsed time per iteration (ms): 246.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626664E+00 | sop loss: 5.068846E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.66 | backward-compute: 79.80 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 18.30
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2245000 | lm loss value: 1.701208E+00 | lm loss PPL: 5.480564E+00 | sop loss value: 6.529732E-02 | sop loss PPL: 1.067476E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2246000/10000000 | consumed samples:    287488000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623743E+00 | sop loss: 5.221623E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.63 | backward-compute: 79.84 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.51
 iteration  2247000/10000000 | consumed samples:    287616000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628446E+00 | sop loss: 5.165798E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.85 | backward-compute: 79.86 | backward-params-all-reduce: 14.80 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.87 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.31 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.79 | batch-generator: 13.54
 iteration  2248000/10000000 | consumed samples:    287744000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625041E+00 | sop loss: 5.104462E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.43 | backward-compute: 79.76 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.58
 iteration  2249000/10000000 | consumed samples:    287872000 | elapsed time per iteration (ms): 250.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627920E+00 | sop loss: 5.195783E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.15 | backward-compute: 79.79 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 14.74
 iteration  2250000/10000000 | consumed samples:    288000000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623639E+00 | sop loss: 5.195607E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.20 | backward-compute: 79.78 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 14.27
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2250000 | lm loss value: 1.657439E+00 | lm loss PPL: 5.245856E+00 | sop loss value: 6.038721E-02 | sop loss PPL: 1.062248E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 2250000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 2250000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2283.03
 iteration  2251000/10000000 | consumed samples:    288128000 | elapsed time per iteration (ms): 250.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627281E+00 | sop loss: 5.181852E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.17 | backward-compute: 79.81 | backward-params-all-reduce: 14.67 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.30 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.79 | batch-generator: 14.94
 iteration  2252000/10000000 | consumed samples:    288256000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628224E+00 | sop loss: 5.148888E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.17 | backward-compute: 79.82 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 14.47
 iteration  2253000/10000000 | consumed samples:    288384000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627969E+00 | sop loss: 5.254637E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.80 | backward-compute: 79.84 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.43 | batch-generator: 13.56
 iteration  2254000/10000000 | consumed samples:    288512000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623686E+00 | sop loss: 5.185412E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.37 | backward-compute: 79.90 | backward-params-all-reduce: 14.58 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.27 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.74 | batch-generator: 15.97
 iteration  2255000/10000000 | consumed samples:    288640000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627567E+00 | sop loss: 5.214262E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.23 | backward-compute: 79.84 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 12.44
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2255000 | lm loss value: 1.664654E+00 | lm loss PPL: 5.283845E+00 | sop loss value: 5.913514E-02 | sop loss PPL: 1.060919E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2256000/10000000 | consumed samples:    288768000 | elapsed time per iteration (ms): 250.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624311E+00 | sop loss: 5.182588E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.12 | backward-compute: 79.89 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 19.08
 iteration  2257000/10000000 | consumed samples:    288896000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629306E+00 | sop loss: 5.202145E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.43 | backward-compute: 79.83 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.53 | batch-generator: 14.29
 iteration  2258000/10000000 | consumed samples:    289024000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628348E+00 | sop loss: 5.218840E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.54 | backward-compute: 79.81 | backward-params-all-reduce: 14.66 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.35 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.83 | batch-generator: 17.46
 iteration  2259000/10000000 | consumed samples:    289152000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625775E+00 | sop loss: 5.012056E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.41 | backward-compute: 79.85 | backward-params-all-reduce: 14.54 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.30 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.77 | batch-generator: 13.81
 iteration  2260000/10000000 | consumed samples:    289280000 | elapsed time per iteration (ms): 247.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625488E+00 | sop loss: 5.251910E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.42 | backward-compute: 79.71 | backward-params-all-reduce: 14.27 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.76 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 18.78
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2260000 | lm loss value: 1.686892E+00 | lm loss PPL: 5.402665E+00 | sop loss value: 6.422757E-02 | sop loss PPL: 1.066335E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2261000/10000000 | consumed samples:    289408000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625657E+00 | sop loss: 5.150520E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.30 | backward-compute: 79.82 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 14.06
 iteration  2262000/10000000 | consumed samples:    289536000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626603E+00 | sop loss: 5.184734E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.81 | backward-compute: 79.82 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 18.48
 iteration  2263000/10000000 | consumed samples:    289664000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627865E+00 | sop loss: 5.029483E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.55 | backward-compute: 79.80 | backward-params-all-reduce: 14.44 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.59 | batch-generator: 16.94
 iteration  2264000/10000000 | consumed samples:    289792000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623580E+00 | sop loss: 5.122559E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.28 | backward-compute: 79.78 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 15.15
 iteration  2265000/10000000 | consumed samples:    289920000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627751E+00 | sop loss: 5.245785E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.70 | backward-compute: 79.82 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 16.00
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2265000 | lm loss value: 1.663006E+00 | lm loss PPL: 5.275146E+00 | sop loss value: 5.082807E-02 | sop loss PPL: 1.052142E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2266000/10000000 | consumed samples:    290048000 | elapsed time per iteration (ms): 252.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624430E+00 | sop loss: 5.208179E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.82 | backward-compute: 79.85 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 17.48
 iteration  2267000/10000000 | consumed samples:    290176000 | elapsed time per iteration (ms): 251.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627278E+00 | sop loss: 5.197959E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.09 | backward-compute: 79.82 | backward-params-all-reduce: 13.89 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 15.73
 iteration  2268000/10000000 | consumed samples:    290304000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625177E+00 | sop loss: 5.149630E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.03 | backward-compute: 79.96 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 16.40
 iteration  2269000/10000000 | consumed samples:    290432000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627724E+00 | sop loss: 5.123179E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.55 | backward-compute: 79.88 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 13.16
 iteration  2270000/10000000 | consumed samples:    290560000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626715E+00 | sop loss: 5.153519E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.43 | backward-compute: 79.82 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 20.21
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2270000 | lm loss value: 1.683229E+00 | lm loss PPL: 5.382911E+00 | sop loss value: 7.522028E-02 | sop loss PPL: 1.078122E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2271000/10000000 | consumed samples:    290688000 | elapsed time per iteration (ms): 249.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624982E+00 | sop loss: 5.202582E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.63 | backward-compute: 79.83 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 21.74
 iteration  2272000/10000000 | consumed samples:    290816000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626218E+00 | sop loss: 5.182366E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.03 | backward-compute: 79.80 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 13.36
 iteration  2273000/10000000 | consumed samples:    290944000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623105E+00 | sop loss: 5.299115E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.23 | backward-compute: 79.85 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 18.08
 iteration  2274000/10000000 | consumed samples:    291072000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624900E+00 | sop loss: 4.994296E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.77 | backward-compute: 79.82 | backward-params-all-reduce: 14.31 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 14.30
 iteration  2275000/10000000 | consumed samples:    291200000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626962E+00 | sop loss: 5.325945E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.15 | backward-compute: 79.85 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 19.74
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2275000 | lm loss value: 1.683288E+00 | lm loss PPL: 5.383229E+00 | sop loss value: 5.704368E-02 | sop loss PPL: 1.058702E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2276000/10000000 | consumed samples:    291328000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626568E+00 | sop loss: 5.100512E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.75 | backward-compute: 79.80 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 15.34
 iteration  2277000/10000000 | consumed samples:    291456000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626411E+00 | sop loss: 5.125626E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.16 | backward-compute: 79.81 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 19.47
 iteration  2278000/10000000 | consumed samples:    291584000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626010E+00 | sop loss: 5.221903E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.20 | backward-compute: 79.78 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 18.78
 iteration  2279000/10000000 | consumed samples:    291712000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628445E+00 | sop loss: 5.136782E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.64 | backward-compute: 79.85 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 15.38
 iteration  2280000/10000000 | consumed samples:    291840000 | elapsed time per iteration (ms): 250.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624605E+00 | sop loss: 5.063488E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.94 | backward-compute: 79.85 | backward-params-all-reduce: 13.86 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.49
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2280000 | lm loss value: 1.663032E+00 | lm loss PPL: 5.275283E+00 | sop loss value: 6.172252E-02 | sop loss PPL: 1.063667E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2281000/10000000 | consumed samples:    291968000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624355E+00 | sop loss: 5.151067E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.56 | backward-compute: 79.85 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.57 | batch-generator: 20.14
 iteration  2282000/10000000 | consumed samples:    292096000 | elapsed time per iteration (ms): 246.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626361E+00 | sop loss: 5.160535E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.91 | backward-compute: 79.85 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 12.16
 iteration  2283000/10000000 | consumed samples:    292224000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625106E+00 | sop loss: 5.165296E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.66 | backward-compute: 79.82 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 14.41
 iteration  2284000/10000000 | consumed samples:    292352000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628378E+00 | sop loss: 5.184081E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.15 | backward-compute: 79.80 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 16.03
 iteration  2285000/10000000 | consumed samples:    292480000 | elapsed time per iteration (ms): 246.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628130E+00 | sop loss: 5.270121E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.80 | backward-compute: 79.78 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.53
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2285000 | lm loss value: 1.657921E+00 | lm loss PPL: 5.248387E+00 | sop loss value: 7.820703E-02 | sop loss PPL: 1.081347E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2286000/10000000 | consumed samples:    292608000 | elapsed time per iteration (ms): 250.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625008E+00 | sop loss: 5.302882E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.68 | backward-compute: 79.86 | backward-params-all-reduce: 14.34 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.59 | batch-generator: 16.53
 iteration  2287000/10000000 | consumed samples:    292736000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623481E+00 | sop loss: 5.253777E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.71 | backward-compute: 79.86 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 18.20
 iteration  2288000/10000000 | consumed samples:    292864000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625088E+00 | sop loss: 5.039119E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.39 | backward-compute: 79.83 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 15.05
 iteration  2289000/10000000 | consumed samples:    292992000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628642E+00 | sop loss: 5.103808E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.33 | backward-compute: 79.80 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 16.43
 iteration  2290000/10000000 | consumed samples:    293120000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625676E+00 | sop loss: 5.173009E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.72 | backward-compute: 79.77 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 12.35
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2290000 | lm loss value: 1.657874E+00 | lm loss PPL: 5.248143E+00 | sop loss value: 7.620538E-02 | sop loss PPL: 1.079184E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2291000/10000000 | consumed samples:    293248000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628121E+00 | sop loss: 5.033427E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.73 | backward-compute: 79.83 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.51 | batch-generator: 15.54
 iteration  2292000/10000000 | consumed samples:    293376000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625558E+00 | sop loss: 5.209742E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.25 | backward-compute: 79.88 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 13.38
 iteration  2293000/10000000 | consumed samples:    293504000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624859E+00 | sop loss: 5.092151E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.63 | backward-compute: 79.84 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 15.92
 iteration  2294000/10000000 | consumed samples:    293632000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625704E+00 | sop loss: 5.108022E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.69 | backward-compute: 79.85 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 22.77
 iteration  2295000/10000000 | consumed samples:    293760000 | elapsed time per iteration (ms): 245.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625419E+00 | sop loss: 5.196160E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.66 | backward-compute: 79.84 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 15.50
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2295000 | lm loss value: 1.701350E+00 | lm loss PPL: 5.481345E+00 | sop loss value: 5.805653E-02 | sop loss PPL: 1.059775E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2296000/10000000 | consumed samples:    293888000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626131E+00 | sop loss: 5.218828E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.07 | backward-compute: 79.81 | backward-params-all-reduce: 14.46 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.23 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.65 | batch-generator: 15.17
 iteration  2297000/10000000 | consumed samples:    294016000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626721E+00 | sop loss: 5.119731E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.97 | backward-compute: 79.79 | backward-params-all-reduce: 14.48 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.23 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.68 | batch-generator: 13.71
 iteration  2298000/10000000 | consumed samples:    294144000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626617E+00 | sop loss: 5.231399E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.20 | backward-compute: 79.80 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.35 | batch-generator: 14.97
 iteration  2299000/10000000 | consumed samples:    294272000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624644E+00 | sop loss: 5.282323E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.27 | backward-compute: 79.86 | backward-params-all-reduce: 14.46 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.24 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.71 | batch-generator: 15.82
 iteration  2300000/10000000 | consumed samples:    294400000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623030E+00 | sop loss: 5.061761E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.68 | backward-compute: 79.86 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 19.41
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2300000 | lm loss value: 1.664690E+00 | lm loss PPL: 5.284034E+00 | sop loss value: 6.405371E-02 | sop loss PPL: 1.066150E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 2300000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 2300000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2267.28
 iteration  2301000/10000000 | consumed samples:    294528000 | elapsed time per iteration (ms): 252.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625665E+00 | sop loss: 5.189484E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.19 | backward-compute: 79.79 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 15.29
 iteration  2302000/10000000 | consumed samples:    294656000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.627681E+00 | sop loss: 5.222777E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.80 | backward-compute: 79.78 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 17.65
 iteration  2303000/10000000 | consumed samples:    294784000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624163E+00 | sop loss: 5.148883E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.74 | backward-compute: 79.84 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 17.56
 iteration  2304000/10000000 | consumed samples:    294912000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625151E+00 | sop loss: 5.162999E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.02 | backward-compute: 79.82 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 15.86
 iteration  2305000/10000000 | consumed samples:    295040000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625377E+00 | sop loss: 5.122669E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.67 | backward-compute: 79.95 | backward-params-all-reduce: 13.83 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 17.76
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2305000 | lm loss value: 1.673277E+00 | lm loss PPL: 5.329605E+00 | sop loss value: 6.040490E-02 | sop loss PPL: 1.062267E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2306000/10000000 | consumed samples:    295168000 | elapsed time per iteration (ms): 250.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623823E+00 | sop loss: 5.120609E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.98 | backward-compute: 79.85 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.49 | batch-generator: 20.71
 iteration  2307000/10000000 | consumed samples:    295296000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626455E+00 | sop loss: 5.123568E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.43 | backward-compute: 79.79 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 13.89
 iteration  2308000/10000000 | consumed samples:    295424000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625576E+00 | sop loss: 5.135949E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.28 | backward-compute: 79.84 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 16.99
 iteration  2309000/10000000 | consumed samples:    295552000 | elapsed time per iteration (ms): 246.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625277E+00 | sop loss: 5.135783E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.26 | backward-compute: 79.82 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 16.84
 iteration  2310000/10000000 | consumed samples:    295680000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623336E+00 | sop loss: 5.293005E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.87 | backward-compute: 79.80 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 16.38
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2310000 | lm loss value: 1.643914E+00 | lm loss PPL: 5.175384E+00 | sop loss value: 5.618846E-02 | sop loss PPL: 1.057797E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2311000/10000000 | consumed samples:    295808000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.628251E+00 | sop loss: 5.085983E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.09 | backward-compute: 79.89 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 19.02
 iteration  2312000/10000000 | consumed samples:    295936000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623696E+00 | sop loss: 5.100684E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.74 | backward-compute: 79.77 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 26.09
 iteration  2313000/10000000 | consumed samples:    296064000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626132E+00 | sop loss: 5.251932E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.15 | backward-compute: 79.97 | backward-params-all-reduce: 13.86 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 14.95
 iteration  2314000/10000000 | consumed samples:    296192000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625322E+00 | sop loss: 5.278499E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.49 | backward-compute: 79.93 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.36 | batch-generator: 12.27
 iteration  2315000/10000000 | consumed samples:    296320000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625671E+00 | sop loss: 5.121012E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.70 | backward-compute: 79.81 | backward-params-all-reduce: 14.34 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.52 | batch-generator: 15.95
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2315000 | lm loss value: 1.681639E+00 | lm loss PPL: 5.374358E+00 | sop loss value: 5.271439E-02 | sop loss PPL: 1.054129E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2316000/10000000 | consumed samples:    296448000 | elapsed time per iteration (ms): 251.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624380E+00 | sop loss: 5.166871E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.73 | backward-compute: 79.84 | backward-params-all-reduce: 14.39 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.58 | batch-generator: 16.94
 iteration  2317000/10000000 | consumed samples:    296576000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622606E+00 | sop loss: 5.233085E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.33 | backward-compute: 79.94 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 14.29
 iteration  2318000/10000000 | consumed samples:    296704000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622726E+00 | sop loss: 5.201325E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.72 | backward-compute: 79.93 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 24.90
 iteration  2319000/10000000 | consumed samples:    296832000 | elapsed time per iteration (ms): 246.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626089E+00 | sop loss: 5.300053E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.87 | backward-compute: 79.89 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 15.42
 iteration  2320000/10000000 | consumed samples:    296960000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624603E+00 | sop loss: 5.051811E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.97 | backward-compute: 79.82 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 17.14
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2320000 | lm loss value: 1.674495E+00 | lm loss PPL: 5.336100E+00 | sop loss value: 5.872371E-02 | sop loss PPL: 1.060482E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2321000/10000000 | consumed samples:    297088000 | elapsed time per iteration (ms): 250.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622795E+00 | sop loss: 5.113911E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.60 | backward-compute: 79.83 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 18.78
 iteration  2322000/10000000 | consumed samples:    297216000 | elapsed time per iteration (ms): 246.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624411E+00 | sop loss: 5.146676E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.84 | backward-compute: 79.79 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 17.66
 iteration  2323000/10000000 | consumed samples:    297344000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626020E+00 | sop loss: 5.253474E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.77 | backward-compute: 79.81 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 21.05
 iteration  2324000/10000000 | consumed samples:    297472000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621939E+00 | sop loss: 5.279116E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.93 | backward-compute: 79.83 | backward-params-all-reduce: 14.34 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.57 | batch-generator: 13.43
 iteration  2325000/10000000 | consumed samples:    297600000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624727E+00 | sop loss: 5.079659E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.20 | backward-compute: 79.82 | backward-params-all-reduce: 14.82 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.88 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.32 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.82 | batch-generator: 14.35
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2325000 | lm loss value: 1.688102E+00 | lm loss PPL: 5.409205E+00 | sop loss value: 7.005664E-02 | sop loss PPL: 1.072569E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2326000/10000000 | consumed samples:    297728000 | elapsed time per iteration (ms): 251.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.629285E+00 | sop loss: 5.242675E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.00 | backward-compute: 79.78 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 15.78
 iteration  2327000/10000000 | consumed samples:    297856000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622398E+00 | sop loss: 5.099902E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.89 | backward-compute: 79.85 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.21
 iteration  2328000/10000000 | consumed samples:    297984000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624836E+00 | sop loss: 5.228194E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.56 | backward-compute: 79.76 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 13.69
 iteration  2329000/10000000 | consumed samples:    298112000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624593E+00 | sop loss: 5.028725E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.70 | backward-compute: 79.77 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.32 | batch-generator: 10.58
 iteration  2330000/10000000 | consumed samples:    298240000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624406E+00 | sop loss: 5.190527E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.32 | backward-compute: 79.82 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 16.04
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2330000 | lm loss value: 1.687890E+00 | lm loss PPL: 5.408056E+00 | sop loss value: 7.230669E-02 | sop loss PPL: 1.074985E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2331000/10000000 | consumed samples:    298368000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624637E+00 | sop loss: 5.213670E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.89 | backward-compute: 79.83 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 14.94
 iteration  2332000/10000000 | consumed samples:    298496000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623009E+00 | sop loss: 5.218399E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.39 | backward-compute: 79.85 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 14.57
 iteration  2333000/10000000 | consumed samples:    298624000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624716E+00 | sop loss: 5.317248E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.30 | backward-compute: 79.81 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.63
 iteration  2334000/10000000 | consumed samples:    298752000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622164E+00 | sop loss: 5.368098E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.81 | backward-compute: 79.81 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 15.90
 iteration  2335000/10000000 | consumed samples:    298880000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621820E+00 | sop loss: 5.284278E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.63 | backward-compute: 79.77 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 14.91
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2335000 | lm loss value: 1.679414E+00 | lm loss PPL: 5.362413E+00 | sop loss value: 8.098202E-02 | sop loss PPL: 1.084351E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2336000/10000000 | consumed samples:    299008000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625994E+00 | sop loss: 5.291632E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.92 | backward-compute: 79.78 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.17
 iteration  2337000/10000000 | consumed samples:    299136000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621958E+00 | sop loss: 4.963590E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.35 | backward-compute: 79.75 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 15.99
 iteration  2338000/10000000 | consumed samples:    299264000 | elapsed time per iteration (ms): 245.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620901E+00 | sop loss: 5.007644E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.91 | backward-compute: 79.76 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 14.19
 iteration  2339000/10000000 | consumed samples:    299392000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623198E+00 | sop loss: 5.130189E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.74 | backward-compute: 79.74 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 18.06
 iteration  2340000/10000000 | consumed samples:    299520000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621834E+00 | sop loss: 5.093463E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.83 | backward-compute: 79.75 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 13.12
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2340000 | lm loss value: 1.683344E+00 | lm loss PPL: 5.383530E+00 | sop loss value: 7.593109E-02 | sop loss PPL: 1.078888E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2341000/10000000 | consumed samples:    299648000 | elapsed time per iteration (ms): 250.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623666E+00 | sop loss: 5.226831E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.25 | backward-compute: 79.80 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.44
 iteration  2342000/10000000 | consumed samples:    299776000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624392E+00 | sop loss: 5.138896E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.37 | backward-compute: 79.79 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.48 | batch-generator: 13.30
 iteration  2343000/10000000 | consumed samples:    299904000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623293E+00 | sop loss: 5.149183E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.92 | backward-compute: 79.80 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.25
 iteration  2344000/10000000 | consumed samples:    300032000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623129E+00 | sop loss: 5.193416E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.18 | backward-compute: 79.81 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 16.17
 iteration  2345000/10000000 | consumed samples:    300160000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623796E+00 | sop loss: 5.111436E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.62 | backward-compute: 79.79 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.76 | optimizer-unscale-and-check-inf: 2.24 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 12.49
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2345000 | lm loss value: 1.678773E+00 | lm loss PPL: 5.358978E+00 | sop loss value: 6.843235E-02 | sop loss PPL: 1.070828E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2346000/10000000 | consumed samples:    300288000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624793E+00 | sop loss: 5.168030E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.93 | backward-compute: 79.77 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 12.62
 iteration  2347000/10000000 | consumed samples:    300416000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626007E+00 | sop loss: 5.187330E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.54 | backward-compute: 79.76 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 14.54
 iteration  2348000/10000000 | consumed samples:    300544000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625613E+00 | sop loss: 5.083249E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.14 | backward-compute: 79.75 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 14.29
 iteration  2349000/10000000 | consumed samples:    300672000 | elapsed time per iteration (ms): 246.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624378E+00 | sop loss: 5.204745E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.55 | backward-compute: 79.78 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.52
 iteration  2350000/10000000 | consumed samples:    300800000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618027E+00 | sop loss: 5.182664E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.09 | backward-compute: 79.80 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 18.97
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2350000 | lm loss value: 1.668409E+00 | lm loss PPL: 5.303722E+00 | sop loss value: 4.851944E-02 | sop loss PPL: 1.049716E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 2350000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 2350000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2287.13
 iteration  2351000/10000000 | consumed samples:    300928000 | elapsed time per iteration (ms): 251.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626207E+00 | sop loss: 5.165975E-02 | loss scale: 8192.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.46 | backward-compute: 79.80 | backward-params-all-reduce: 14.37 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.19 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.63 | batch-generator: 14.79
 iteration  2352000/10000000 | consumed samples:    301056000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626374E+00 | sop loss: 5.029923E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.24 | backward-compute: 79.95 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.54
 iteration  2353000/10000000 | consumed samples:    301184000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624702E+00 | sop loss: 5.226406E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.58 | backward-compute: 79.86 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 15.01
 iteration  2354000/10000000 | consumed samples:    301312000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624900E+00 | sop loss: 5.223439E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.10 | backward-compute: 79.89 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.66
 iteration  2355000/10000000 | consumed samples:    301440000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624554E+00 | sop loss: 5.214875E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.75 | backward-compute: 79.83 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 12.81
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2355000 | lm loss value: 1.711244E+00 | lm loss PPL: 5.535846E+00 | sop loss value: 7.560478E-02 | sop loss PPL: 1.078536E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2356000/10000000 | consumed samples:    301568000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620660E+00 | sop loss: 5.020797E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.77 | backward-compute: 79.87 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 18.02
 iteration  2357000/10000000 | consumed samples:    301696000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626785E+00 | sop loss: 5.192319E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.67 | backward-compute: 79.81 | backward-params-all-reduce: 13.92 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.41
 iteration  2358000/10000000 | consumed samples:    301824000 | elapsed time per iteration (ms): 249.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623372E+00 | sop loss: 5.007483E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.95 | backward-compute: 79.82 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.44 | batch-generator: 26.79
 iteration  2359000/10000000 | consumed samples:    301952000 | elapsed time per iteration (ms): 246.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621271E+00 | sop loss: 5.212647E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.14 | backward-compute: 79.79 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.50 | batch-generator: 18.07
 iteration  2360000/10000000 | consumed samples:    302080000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623776E+00 | sop loss: 5.287503E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.85 | backward-compute: 79.78 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 14.51
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2360000 | lm loss value: 1.640046E+00 | lm loss PPL: 5.155405E+00 | sop loss value: 5.995936E-02 | sop loss PPL: 1.061793E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2361000/10000000 | consumed samples:    302208000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623708E+00 | sop loss: 5.157776E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.66 | backward-compute: 79.83 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 18.44
 iteration  2362000/10000000 | consumed samples:    302336000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624060E+00 | sop loss: 5.212602E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.43 | backward-compute: 79.80 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 17.13
 iteration  2363000/10000000 | consumed samples:    302464000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623160E+00 | sop loss: 5.175570E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.44 | backward-compute: 79.73 | backward-params-all-reduce: 14.48 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.22 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.71 | batch-generator: 15.44
 iteration  2364000/10000000 | consumed samples:    302592000 | elapsed time per iteration (ms): 250.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621112E+00 | sop loss: 5.151604E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.13 | backward-compute: 79.82 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 12.73
 iteration  2365000/10000000 | consumed samples:    302720000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624473E+00 | sop loss: 5.222537E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.16 | backward-compute: 79.81 | backward-params-all-reduce: 14.36 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 17.49
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2365000 | lm loss value: 1.683521E+00 | lm loss PPL: 5.384483E+00 | sop loss value: 5.539871E-02 | sop loss PPL: 1.056962E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2366000/10000000 | consumed samples:    302848000 | elapsed time per iteration (ms): 251.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617502E+00 | sop loss: 5.186087E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.71 | backward-compute: 79.84 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 16.54
 iteration  2367000/10000000 | consumed samples:    302976000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624137E+00 | sop loss: 5.276754E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.14 | backward-compute: 79.87 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 23.27
 iteration  2368000/10000000 | consumed samples:    303104000 | elapsed time per iteration (ms): 252.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622504E+00 | sop loss: 5.108519E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.47 | backward-compute: 79.85 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.89 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.67 | batch-generator: 23.12
 iteration  2369000/10000000 | consumed samples:    303232000 | elapsed time per iteration (ms): 252.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622490E+00 | sop loss: 5.141769E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.65 | backward-compute: 79.85 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.91 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.70 | batch-generator: 15.53
 iteration  2370000/10000000 | consumed samples:    303360000 | elapsed time per iteration (ms): 250.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625475E+00 | sop loss: 5.169366E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.89 | backward-compute: 79.86 | backward-params-all-reduce: 14.37 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.93 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.76 | batch-generator: 15.99
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2370000 | lm loss value: 1.686114E+00 | lm loss PPL: 5.398463E+00 | sop loss value: 6.972764E-02 | sop loss PPL: 1.072216E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2371000/10000000 | consumed samples:    303488000 | elapsed time per iteration (ms): 252.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624054E+00 | sop loss: 5.203518E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.21 | backward-compute: 79.83 | backward-params-all-reduce: 14.39 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.91 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.73 | batch-generator: 18.97
 iteration  2372000/10000000 | consumed samples:    303616000 | elapsed time per iteration (ms): 251.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624780E+00 | sop loss: 5.243526E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.98 | backward-compute: 79.88 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.90 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.69 | batch-generator: 21.32
 iteration  2373000/10000000 | consumed samples:    303744000 | elapsed time per iteration (ms): 253.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621272E+00 | sop loss: 5.204622E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.54 | backward-compute: 79.91 | backward-params-all-reduce: 14.29 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.93 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.76 | batch-generator: 14.30
 iteration  2374000/10000000 | consumed samples:    303872000 | elapsed time per iteration (ms): 252.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624800E+00 | sop loss: 5.290308E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.75 | backward-compute: 79.86 | backward-params-all-reduce: 14.46 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.91 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.72 | batch-generator: 17.26
 iteration  2375000/10000000 | consumed samples:    304000000 | elapsed time per iteration (ms): 252.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624020E+00 | sop loss: 5.000346E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.58 | backward-compute: 79.86 | backward-params-all-reduce: 14.41 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.90 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.71 | batch-generator: 17.77
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2375000 | lm loss value: 1.697032E+00 | lm loss PPL: 5.457725E+00 | sop loss value: 7.926783E-02 | sop loss PPL: 1.082494E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2376000/10000000 | consumed samples:    304128000 | elapsed time per iteration (ms): 253.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624404E+00 | sop loss: 5.110433E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.93 | backward-compute: 79.88 | backward-params-all-reduce: 14.46 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.92 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.72 | batch-generator: 17.84
 iteration  2377000/10000000 | consumed samples:    304256000 | elapsed time per iteration (ms): 252.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622009E+00 | sop loss: 5.083614E-02 | loss scale: 8192.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.89 | backward-compute: 79.89 | backward-params-all-reduce: 14.28 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.91 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.69 | batch-generator: 16.20
 iteration  2378000/10000000 | consumed samples:    304384000 | elapsed time per iteration (ms): 251.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621401E+00 | sop loss: 5.113818E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.69 | backward-compute: 79.82 | backward-params-all-reduce: 14.35 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.91 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.73 | batch-generator: 15.89
 iteration  2379000/10000000 | consumed samples:    304512000 | elapsed time per iteration (ms): 252.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623451E+00 | sop loss: 5.214871E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.52 | backward-compute: 79.88 | backward-params-all-reduce: 14.31 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.91 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.73 | batch-generator: 21.20
 iteration  2380000/10000000 | consumed samples:    304640000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621627E+00 | sop loss: 5.205800E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.74 | backward-compute: 79.81 | backward-params-all-reduce: 14.46 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.92 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.19 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.75 | batch-generator: 15.66
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2380000 | lm loss value: 1.671925E+00 | lm loss PPL: 5.322403E+00 | sop loss value: 7.750227E-02 | sop loss PPL: 1.080585E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2381000/10000000 | consumed samples:    304768000 | elapsed time per iteration (ms): 251.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620347E+00 | sop loss: 5.032028E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.53 | backward-compute: 79.91 | backward-params-all-reduce: 14.27 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.92 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.71 | batch-generator: 17.39
 iteration  2382000/10000000 | consumed samples:    304896000 | elapsed time per iteration (ms): 251.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624394E+00 | sop loss: 5.155715E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.28 | backward-compute: 79.88 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.90 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.67 | batch-generator: 19.35
 iteration  2383000/10000000 | consumed samples:    305024000 | elapsed time per iteration (ms): 252.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623836E+00 | sop loss: 5.168989E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.47 | backward-compute: 79.84 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.89 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.67 | batch-generator: 16.27
 iteration  2384000/10000000 | consumed samples:    305152000 | elapsed time per iteration (ms): 250.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624047E+00 | sop loss: 5.194029E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.21 | backward-compute: 79.87 | backward-params-all-reduce: 14.37 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.92 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.73 | batch-generator: 15.90
 iteration  2385000/10000000 | consumed samples:    305280000 | elapsed time per iteration (ms): 252.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623676E+00 | sop loss: 5.178491E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.53 | backward-compute: 79.88 | backward-params-all-reduce: 14.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.90 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.68 | batch-generator: 17.53
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2385000 | lm loss value: 1.686092E+00 | lm loss PPL: 5.398342E+00 | sop loss value: 5.957728E-02 | sop loss PPL: 1.061388E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2386000/10000000 | consumed samples:    305408000 | elapsed time per iteration (ms): 253.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623972E+00 | sop loss: 5.034845E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.15 | backward-compute: 79.87 | backward-params-all-reduce: 14.45 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.90 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.70 | batch-generator: 19.29
 iteration  2387000/10000000 | consumed samples:    305536000 | elapsed time per iteration (ms): 252.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623077E+00 | sop loss: 5.192565E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.62 | backward-compute: 79.88 | backward-params-all-reduce: 14.53 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.94 | optimizer-unscale-and-check-inf: 2.31 | optimizer-clip-main-grad: 4.19 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.82 | batch-generator: 20.13
 iteration  2388000/10000000 | consumed samples:    305664000 | elapsed time per iteration (ms): 251.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625435E+00 | sop loss: 5.122694E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.37 | backward-compute: 79.92 | backward-params-all-reduce: 14.58 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.98 | optimizer-unscale-and-check-inf: 2.32 | optimizer-clip-main-grad: 4.23 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.92 | batch-generator: 19.29
 iteration  2389000/10000000 | consumed samples:    305792000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621438E+00 | sop loss: 5.163847E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.81 | backward-compute: 79.86 | backward-params-all-reduce: 14.41 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.92 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.71 | batch-generator: 16.26
 iteration  2390000/10000000 | consumed samples:    305920000 | elapsed time per iteration (ms): 251.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621927E+00 | sop loss: 5.109982E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.72 | backward-compute: 79.85 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.93 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.76 | batch-generator: 22.38
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2390000 | lm loss value: 1.633876E+00 | lm loss PPL: 5.123698E+00 | sop loss value: 6.391890E-02 | sop loss PPL: 1.066006E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2391000/10000000 | consumed samples:    306048000 | elapsed time per iteration (ms): 253.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622165E+00 | sop loss: 5.128686E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.63 | backward-compute: 79.88 | backward-params-all-reduce: 14.39 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.92 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.20 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.78 | batch-generator: 19.57
 iteration  2392000/10000000 | consumed samples:    306176000 | elapsed time per iteration (ms): 253.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625473E+00 | sop loss: 5.133339E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.25 | backward-compute: 79.89 | backward-params-all-reduce: 14.46 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.94 | optimizer-unscale-and-check-inf: 2.31 | optimizer-clip-main-grad: 4.20 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.81 | batch-generator: 17.77
 iteration  2393000/10000000 | consumed samples:    306304000 | elapsed time per iteration (ms): 251.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625857E+00 | sop loss: 5.220124E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.87 | backward-compute: 79.88 | backward-params-all-reduce: 14.76 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.95 | optimizer-unscale-and-check-inf: 2.32 | optimizer-clip-main-grad: 4.31 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.94 | batch-generator: 17.18
 iteration  2394000/10000000 | consumed samples:    306432000 | elapsed time per iteration (ms): 252.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621171E+00 | sop loss: 5.136443E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.17 | backward-compute: 79.85 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.92 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.73 | batch-generator: 19.71
 iteration  2395000/10000000 | consumed samples:    306560000 | elapsed time per iteration (ms): 252.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624658E+00 | sop loss: 5.273322E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.75 | backward-compute: 79.85 | backward-params-all-reduce: 14.48 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.94 | optimizer-unscale-and-check-inf: 2.31 | optimizer-clip-main-grad: 4.23 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.85 | batch-generator: 23.18
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2395000 | lm loss value: 1.677429E+00 | lm loss PPL: 5.351778E+00 | sop loss value: 7.960405E-02 | sop loss PPL: 1.082858E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2396000/10000000 | consumed samples:    306688000 | elapsed time per iteration (ms): 251.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622992E+00 | sop loss: 5.039730E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.68 | backward-compute: 79.87 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 15.78
 iteration  2397000/10000000 | consumed samples:    306816000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623440E+00 | sop loss: 5.244588E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.10 | backward-compute: 79.78 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 14.10
 iteration  2398000/10000000 | consumed samples:    306944000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624487E+00 | sop loss: 5.132998E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.75 | backward-compute: 79.77 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.81
 iteration  2399000/10000000 | consumed samples:    307072000 | elapsed time per iteration (ms): 246.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624316E+00 | sop loss: 5.179912E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.10 | backward-compute: 79.82 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 13.55
 iteration  2400000/10000000 | consumed samples:    307200000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624001E+00 | sop loss: 5.272814E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.51 | backward-compute: 79.79 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 14.24
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2400000 | lm loss value: 1.691996E+00 | lm loss PPL: 5.430308E+00 | sop loss value: 5.249277E-02 | sop loss PPL: 1.053895E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 2400000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 2400000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2360.99
 iteration  2401000/10000000 | consumed samples:    307328000 | elapsed time per iteration (ms): 251.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623872E+00 | sop loss: 5.142737E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.33 | backward-compute: 79.72 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 13.59
 iteration  2402000/10000000 | consumed samples:    307456000 | elapsed time per iteration (ms): 250.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624216E+00 | sop loss: 5.256395E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.46 | backward-compute: 79.75 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 17.18
 iteration  2403000/10000000 | consumed samples:    307584000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620877E+00 | sop loss: 5.147694E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.18 | backward-compute: 79.75 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.05
 iteration  2404000/10000000 | consumed samples:    307712000 | elapsed time per iteration (ms): 250.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621593E+00 | sop loss: 5.170073E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.13 | backward-compute: 79.75 | backward-params-all-reduce: 13.86 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.24 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 17.14
 iteration  2405000/10000000 | consumed samples:    307840000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622273E+00 | sop loss: 5.138779E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.76 | backward-compute: 79.85 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.50 | batch-generator: 13.92
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2405000 | lm loss value: 1.662355E+00 | lm loss PPL: 5.271713E+00 | sop loss value: 4.995499E-02 | sop loss PPL: 1.051224E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2406000/10000000 | consumed samples:    307968000 | elapsed time per iteration (ms): 251.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620672E+00 | sop loss: 5.277477E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.62 | backward-compute: 79.79 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.87
 iteration  2407000/10000000 | consumed samples:    308096000 | elapsed time per iteration (ms): 247.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624274E+00 | sop loss: 5.057453E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.30 | backward-compute: 79.84 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 14.93
 iteration  2408000/10000000 | consumed samples:    308224000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624405E+00 | sop loss: 5.177714E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.46 | backward-compute: 79.87 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 15.89
 iteration  2409000/10000000 | consumed samples:    308352000 | elapsed time per iteration (ms): 246.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621174E+00 | sop loss: 5.230904E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.39 | backward-compute: 79.79 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.53 | batch-generator: 13.56
 iteration  2410000/10000000 | consumed samples:    308480000 | elapsed time per iteration (ms): 250.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617764E+00 | sop loss: 5.124501E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.67 | backward-compute: 79.79 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 16.67
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2410000 | lm loss value: 1.706267E+00 | lm loss PPL: 5.508358E+00 | sop loss value: 6.922143E-02 | sop loss PPL: 1.071673E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2411000/10000000 | consumed samples:    308608000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623675E+00 | sop loss: 5.083890E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.58 | backward-compute: 79.82 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.47 | batch-generator: 18.14
 iteration  2412000/10000000 | consumed samples:    308736000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621374E+00 | sop loss: 5.154270E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.09 | backward-compute: 79.81 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 26.76
 iteration  2413000/10000000 | consumed samples:    308864000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623007E+00 | sop loss: 5.115639E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.88 | backward-compute: 79.81 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 13.48
 iteration  2414000/10000000 | consumed samples:    308992000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624861E+00 | sop loss: 5.176141E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.33 | backward-compute: 79.86 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 14.91
 iteration  2415000/10000000 | consumed samples:    309120000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624076E+00 | sop loss: 5.141883E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.18 | backward-compute: 79.80 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 23.16
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2415000 | lm loss value: 1.665195E+00 | lm loss PPL: 5.286707E+00 | sop loss value: 6.736921E-02 | sop loss PPL: 1.069690E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2416000/10000000 | consumed samples:    309248000 | elapsed time per iteration (ms): 251.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624356E+00 | sop loss: 4.992071E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.17 | backward-compute: 79.82 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 14.15
 iteration  2417000/10000000 | consumed samples:    309376000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624263E+00 | sop loss: 5.033427E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.57 | backward-compute: 79.86 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 13.70
 iteration  2418000/10000000 | consumed samples:    309504000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623279E+00 | sop loss: 5.162574E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.84 | backward-compute: 79.88 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 16.26
 iteration  2419000/10000000 | consumed samples:    309632000 | elapsed time per iteration (ms): 245.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621976E+00 | sop loss: 5.278469E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.88 | backward-compute: 79.80 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 15.03
 iteration  2420000/10000000 | consumed samples:    309760000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624477E+00 | sop loss: 5.063738E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.44 | backward-compute: 79.74 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 13.51
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2420000 | lm loss value: 1.684469E+00 | lm loss PPL: 5.389591E+00 | sop loss value: 5.690981E-02 | sop loss PPL: 1.058560E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2421000/10000000 | consumed samples:    309888000 | elapsed time per iteration (ms): 251.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621421E+00 | sop loss: 5.160480E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.90 | backward-compute: 79.75 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 14.91
 iteration  2422000/10000000 | consumed samples:    310016000 | elapsed time per iteration (ms): 251.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621916E+00 | sop loss: 5.147003E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.93 | backward-compute: 79.69 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 12.92
 iteration  2423000/10000000 | consumed samples:    310144000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621405E+00 | sop loss: 5.029319E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.70 | backward-compute: 79.80 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 18.13
 iteration  2424000/10000000 | consumed samples:    310272000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618960E+00 | sop loss: 5.083986E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.53 | backward-compute: 79.82 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.17
 iteration  2425000/10000000 | consumed samples:    310400000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621185E+00 | sop loss: 5.186009E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.58 | backward-compute: 79.84 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 17.09
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2425000 | lm loss value: 1.662421E+00 | lm loss PPL: 5.272056E+00 | sop loss value: 7.414218E-02 | sop loss PPL: 1.076960E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2426000/10000000 | consumed samples:    310528000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620927E+00 | sop loss: 5.133779E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.37 | backward-compute: 79.82 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.03
 iteration  2427000/10000000 | consumed samples:    310656000 | elapsed time per iteration (ms): 246.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623904E+00 | sop loss: 5.162455E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.83 | backward-compute: 79.79 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 14.38
 iteration  2428000/10000000 | consumed samples:    310784000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622618E+00 | sop loss: 5.164229E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.03 | backward-compute: 79.80 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 19.51
 iteration  2429000/10000000 | consumed samples:    310912000 | elapsed time per iteration (ms): 246.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624658E+00 | sop loss: 5.219922E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.13 | backward-compute: 79.88 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 15.95
 iteration  2430000/10000000 | consumed samples:    311040000 | elapsed time per iteration (ms): 245.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619459E+00 | sop loss: 5.124597E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.01 | backward-compute: 79.84 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 14.48
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2430000 | lm loss value: 1.706914E+00 | lm loss PPL: 5.511923E+00 | sop loss value: 5.124357E-02 | sop loss PPL: 1.052579E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2431000/10000000 | consumed samples:    311168000 | elapsed time per iteration (ms): 250.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622023E+00 | sop loss: 5.249014E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.85 | backward-compute: 79.79 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.48 | batch-generator: 14.10
 iteration  2432000/10000000 | consumed samples:    311296000 | elapsed time per iteration (ms): 246.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622035E+00 | sop loss: 5.064626E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.03 | backward-compute: 79.87 | backward-params-all-reduce: 14.56 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.26 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.71 | batch-generator: 13.53
 iteration  2433000/10000000 | consumed samples:    311424000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622482E+00 | sop loss: 5.223304E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.45 | backward-compute: 79.82 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 16.58
 iteration  2434000/10000000 | consumed samples:    311552000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619503E+00 | sop loss: 5.164680E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.14 | backward-compute: 79.83 | backward-params-all-reduce: 14.49 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.23 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.68 | batch-generator: 19.31
 iteration  2435000/10000000 | consumed samples:    311680000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624405E+00 | sop loss: 5.197336E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.99 | backward-compute: 79.81 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.22 | optimizer: 16.33 | batch-generator: 15.92
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2435000 | lm loss value: 1.675011E+00 | lm loss PPL: 5.338853E+00 | sop loss value: 5.339419E-02 | sop loss PPL: 1.054845E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2436000/10000000 | consumed samples:    311808000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621906E+00 | sop loss: 5.181828E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.93 | backward-compute: 79.78 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.05
 iteration  2437000/10000000 | consumed samples:    311936000 | elapsed time per iteration (ms): 250.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624087E+00 | sop loss: 5.247155E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.24 | backward-compute: 79.77 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 15.91
 iteration  2438000/10000000 | consumed samples:    312064000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624857E+00 | sop loss: 5.117894E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.48 | backward-compute: 79.81 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 16.79
 iteration  2439000/10000000 | consumed samples:    312192000 | elapsed time per iteration (ms): 246.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621959E+00 | sop loss: 5.051088E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.99 | backward-compute: 79.93 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 14.86
 iteration  2440000/10000000 | consumed samples:    312320000 | elapsed time per iteration (ms): 246.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620251E+00 | sop loss: 4.982319E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.41 | backward-compute: 79.86 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 14.97
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2440000 | lm loss value: 1.672428E+00 | lm loss PPL: 5.325084E+00 | sop loss value: 5.811905E-02 | sop loss PPL: 1.059841E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2441000/10000000 | consumed samples:    312448000 | elapsed time per iteration (ms): 251.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620400E+00 | sop loss: 5.256385E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.65 | backward-compute: 79.85 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 19.51
 iteration  2442000/10000000 | consumed samples:    312576000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621426E+00 | sop loss: 5.222445E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.37 | backward-compute: 79.82 | backward-params-all-reduce: 14.33 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 16.42
 iteration  2443000/10000000 | consumed samples:    312704000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619829E+00 | sop loss: 5.249257E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.61 | backward-compute: 79.79 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.89
 iteration  2444000/10000000 | consumed samples:    312832000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622735E+00 | sop loss: 5.186186E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.17 | backward-compute: 79.77 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 17.22
 iteration  2445000/10000000 | consumed samples:    312960000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620467E+00 | sop loss: 5.070420E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.74 | backward-compute: 79.80 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 18.04
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2445000 | lm loss value: 1.671291E+00 | lm loss PPL: 5.319029E+00 | sop loss value: 7.298604E-02 | sop loss PPL: 1.075716E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2446000/10000000 | consumed samples:    313088000 | elapsed time per iteration (ms): 253.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622417E+00 | sop loss: 5.122117E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.13 | backward-compute: 79.81 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 15.75
 iteration  2447000/10000000 | consumed samples:    313216000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620731E+00 | sop loss: 5.108083E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.95 | backward-compute: 79.78 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.65
 iteration  2448000/10000000 | consumed samples:    313344000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622295E+00 | sop loss: 5.235777E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.06 | backward-compute: 79.81 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.33
 iteration  2449000/10000000 | consumed samples:    313472000 | elapsed time per iteration (ms): 249.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623828E+00 | sop loss: 4.988462E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.27 | backward-compute: 79.78 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 13.86
 iteration  2450000/10000000 | consumed samples:    313600000 | elapsed time per iteration (ms): 249.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621343E+00 | sop loss: 5.162049E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.05 | backward-compute: 79.84 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 15.73
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2450000 | lm loss value: 1.644122E+00 | lm loss PPL: 5.176461E+00 | sop loss value: 5.320868E-02 | sop loss PPL: 1.054650E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 2450000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 2450000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2347.34
 iteration  2451000/10000000 | consumed samples:    313728000 | elapsed time per iteration (ms): 253.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.625215E+00 | sop loss: 5.272251E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.03 | backward-compute: 79.80 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.53 | batch-generator: 16.15
 iteration  2452000/10000000 | consumed samples:    313856000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620593E+00 | sop loss: 5.127001E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.57 | backward-compute: 79.78 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 15.46
 iteration  2453000/10000000 | consumed samples:    313984000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619196E+00 | sop loss: 5.080935E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.69 | backward-compute: 79.72 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.44 | batch-generator: 15.48
 iteration  2454000/10000000 | consumed samples:    314112000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624007E+00 | sop loss: 5.125028E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.09 | backward-compute: 79.75 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 16.25
 iteration  2455000/10000000 | consumed samples:    314240000 | elapsed time per iteration (ms): 246.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621722E+00 | sop loss: 5.144890E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.90 | backward-compute: 79.94 | backward-params-all-reduce: 13.92 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 16.95
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2455000 | lm loss value: 1.651213E+00 | lm loss PPL: 5.213298E+00 | sop loss value: 4.418196E-02 | sop loss PPL: 1.045173E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2456000/10000000 | consumed samples:    314368000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621324E+00 | sop loss: 5.190623E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.73 | backward-compute: 79.97 | backward-params-all-reduce: 14.52 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.30 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.76 | batch-generator: 15.65
 iteration  2457000/10000000 | consumed samples:    314496000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620132E+00 | sop loss: 5.124736E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.91 | backward-compute: 79.77 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.42
 iteration  2458000/10000000 | consumed samples:    314624000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622572E+00 | sop loss: 5.218811E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.54 | backward-compute: 79.85 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 24.85
 iteration  2459000/10000000 | consumed samples:    314752000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620546E+00 | sop loss: 5.152234E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.66 | backward-compute: 79.84 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 14.65
 iteration  2460000/10000000 | consumed samples:    314880000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622649E+00 | sop loss: 5.116933E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.94 | backward-compute: 79.80 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 14.08
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2460000 | lm loss value: 1.671708E+00 | lm loss PPL: 5.321251E+00 | sop loss value: 7.925957E-02 | sop loss PPL: 1.082485E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2461000/10000000 | consumed samples:    315008000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620614E+00 | sop loss: 5.172451E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.40 | backward-compute: 79.86 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 16.05
 iteration  2462000/10000000 | consumed samples:    315136000 | elapsed time per iteration (ms): 246.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623203E+00 | sop loss: 5.098695E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.85 | backward-compute: 79.78 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 13.88
 iteration  2463000/10000000 | consumed samples:    315264000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622344E+00 | sop loss: 4.944933E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.70 | backward-compute: 79.74 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.24 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 13.57
 iteration  2464000/10000000 | consumed samples:    315392000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623279E+00 | sop loss: 5.193869E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.74 | backward-compute: 79.83 | backward-params-all-reduce: 13.92 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 22.02
 iteration  2465000/10000000 | consumed samples:    315520000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619021E+00 | sop loss: 5.185715E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.93 | backward-compute: 79.82 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 12.81
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2465000 | lm loss value: 1.638667E+00 | lm loss PPL: 5.148300E+00 | sop loss value: 5.313194E-02 | sop loss PPL: 1.054569E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2466000/10000000 | consumed samples:    315648000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624529E+00 | sop loss: 5.172805E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.73 | backward-compute: 79.85 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 16.96
 iteration  2467000/10000000 | consumed samples:    315776000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620389E+00 | sop loss: 5.088577E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.63 | backward-compute: 79.83 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 14.71
 iteration  2468000/10000000 | consumed samples:    315904000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620408E+00 | sop loss: 5.204073E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.44 | backward-compute: 79.81 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 13.49
 iteration  2469000/10000000 | consumed samples:    316032000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619028E+00 | sop loss: 5.194639E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.74 | backward-compute: 79.86 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 18.12
 iteration  2470000/10000000 | consumed samples:    316160000 | elapsed time per iteration (ms): 249.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622746E+00 | sop loss: 5.182660E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.86 | backward-compute: 79.84 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 15.60
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2470000 | lm loss value: 1.657551E+00 | lm loss PPL: 5.246446E+00 | sop loss value: 5.647323E-02 | sop loss PPL: 1.058098E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2471000/10000000 | consumed samples:    316288000 | elapsed time per iteration (ms): 250.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621363E+00 | sop loss: 5.228290E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.74 | backward-compute: 79.85 | backward-params-all-reduce: 13.89 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 24.15
 iteration  2472000/10000000 | consumed samples:    316416000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620864E+00 | sop loss: 5.205279E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.26 | backward-compute: 79.83 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 15.00
 iteration  2473000/10000000 | consumed samples:    316544000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616753E+00 | sop loss: 5.062401E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.00 | backward-compute: 79.84 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.20
 iteration  2474000/10000000 | consumed samples:    316672000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623018E+00 | sop loss: 5.237746E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.11 | backward-compute: 79.84 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 13.66
 iteration  2475000/10000000 | consumed samples:    316800000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622216E+00 | sop loss: 5.189266E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.35 | backward-compute: 79.79 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.42 | batch-generator: 14.45
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2475000 | lm loss value: 1.664610E+00 | lm loss PPL: 5.283610E+00 | sop loss value: 6.521175E-02 | sop loss PPL: 1.067385E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2476000/10000000 | consumed samples:    316928000 | elapsed time per iteration (ms): 253.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621870E+00 | sop loss: 5.228096E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.02 | backward-compute: 79.79 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.46
 iteration  2477000/10000000 | consumed samples:    317056000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619399E+00 | sop loss: 5.241082E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.92 | backward-compute: 79.87 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 14.92
 iteration  2478000/10000000 | consumed samples:    317184000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621034E+00 | sop loss: 5.100741E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.42 | backward-compute: 79.73 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 15.77
 iteration  2479000/10000000 | consumed samples:    317312000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619641E+00 | sop loss: 5.123161E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.64 | backward-compute: 79.79 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 13.24
 iteration  2480000/10000000 | consumed samples:    317440000 | elapsed time per iteration (ms): 246.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620794E+00 | sop loss: 5.228552E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.03 | backward-compute: 79.86 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 15.34
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2480000 | lm loss value: 1.689080E+00 | lm loss PPL: 5.414495E+00 | sop loss value: 6.753995E-02 | sop loss PPL: 1.069873E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2481000/10000000 | consumed samples:    317568000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621582E+00 | sop loss: 5.198563E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.48 | backward-compute: 79.75 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.72
 iteration  2482000/10000000 | consumed samples:    317696000 | elapsed time per iteration (ms): 250.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620026E+00 | sop loss: 5.147901E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.64 | backward-compute: 79.77 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.50 | batch-generator: 16.54
 iteration  2483000/10000000 | consumed samples:    317824000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619597E+00 | sop loss: 5.025857E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.66 | backward-compute: 79.81 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.53 | batch-generator: 23.66
 iteration  2484000/10000000 | consumed samples:    317952000 | elapsed time per iteration (ms): 245.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620080E+00 | sop loss: 5.056996E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.14 | backward-compute: 79.86 | backward-params-all-reduce: 14.61 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.24 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.70 | batch-generator: 16.24
 iteration  2485000/10000000 | consumed samples:    318080000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620955E+00 | sop loss: 5.229234E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.37 | backward-compute: 79.83 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 12.28
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2485000 | lm loss value: 1.667306E+00 | lm loss PPL: 5.297875E+00 | sop loss value: 7.572834E-02 | sop loss PPL: 1.078670E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2486000/10000000 | consumed samples:    318208000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619939E+00 | sop loss: 5.421097E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.41 | backward-compute: 79.83 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.89
 iteration  2487000/10000000 | consumed samples:    318336000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623600E+00 | sop loss: 5.190285E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.72 | backward-compute: 79.77 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 14.34
 iteration  2488000/10000000 | consumed samples:    318464000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622915E+00 | sop loss: 5.187054E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.48 | backward-compute: 79.76 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.32
 iteration  2489000/10000000 | consumed samples:    318592000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619025E+00 | sop loss: 5.220514E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.57 | backward-compute: 79.91 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 19.04
 iteration  2490000/10000000 | consumed samples:    318720000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619500E+00 | sop loss: 5.174481E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.19 | backward-compute: 79.77 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 14.62
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2490000 | lm loss value: 1.662423E+00 | lm loss PPL: 5.272070E+00 | sop loss value: 5.031569E-02 | sop loss PPL: 1.051603E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2491000/10000000 | consumed samples:    318848000 | elapsed time per iteration (ms): 250.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621182E+00 | sop loss: 5.042701E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.12 | backward-compute: 79.97 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 17.18
 iteration  2492000/10000000 | consumed samples:    318976000 | elapsed time per iteration (ms): 246.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622509E+00 | sop loss: 5.145283E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.18 | backward-compute: 79.83 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 18.78
 iteration  2493000/10000000 | consumed samples:    319104000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623493E+00 | sop loss: 5.107569E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.68 | backward-compute: 79.86 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.23
 iteration  2494000/10000000 | consumed samples:    319232000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617960E+00 | sop loss: 5.209322E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.06 | backward-compute: 79.84 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 16.81
 iteration  2495000/10000000 | consumed samples:    319360000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621560E+00 | sop loss: 5.090545E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.89 | backward-compute: 79.90 | backward-params-all-reduce: 13.92 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 13.60
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2495000 | lm loss value: 1.667342E+00 | lm loss PPL: 5.298068E+00 | sop loss value: 8.136215E-02 | sop loss PPL: 1.084764E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2496000/10000000 | consumed samples:    319488000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621255E+00 | sop loss: 5.261731E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.56 | backward-compute: 79.74 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 15.86
 iteration  2497000/10000000 | consumed samples:    319616000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619639E+00 | sop loss: 5.115022E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.35 | backward-compute: 79.81 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 17.29
 iteration  2498000/10000000 | consumed samples:    319744000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619554E+00 | sop loss: 5.181006E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.82 | backward-compute: 79.79 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 14.68
 iteration  2499000/10000000 | consumed samples:    319872000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622560E+00 | sop loss: 5.186199E-02 | loss scale: 8192.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.31 | backward-compute: 79.87 | backward-params-all-reduce: 13.89 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 19.79
 iteration  2500000/10000000 | consumed samples:    320000000 | elapsed time per iteration (ms): 251.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620939E+00 | sop loss: 5.089057E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.50 | backward-compute: 79.75 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 15.76
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2500000 | lm loss value: 1.658387E+00 | lm loss PPL: 5.250837E+00 | sop loss value: 5.735129E-02 | sop loss PPL: 1.059028E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 2500000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 2500000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2333.55
 iteration  2501000/10000000 | consumed samples:    320128000 | elapsed time per iteration (ms): 254.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619113E+00 | sop loss: 5.187195E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.13 | backward-compute: 79.82 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.19 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.63 | batch-generator: 23.94
 iteration  2502000/10000000 | consumed samples:    320256000 | elapsed time per iteration (ms): 246.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618400E+00 | sop loss: 5.092586E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.16 | backward-compute: 79.82 | backward-params-all-reduce: 14.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.89 | optimizer-unscale-and-check-inf: 2.31 | optimizer-clip-main-grad: 4.47 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 17.00 | batch-generator: 16.22
 iteration  2503000/10000000 | consumed samples:    320384000 | elapsed time per iteration (ms): 246.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.626175E+00 | sop loss: 5.191823E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.45 | backward-compute: 79.80 | backward-params-all-reduce: 14.36 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.57 | batch-generator: 13.66
 iteration  2504000/10000000 | consumed samples:    320512000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620846E+00 | sop loss: 5.206042E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.46 | backward-compute: 79.85 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 17.89
 iteration  2505000/10000000 | consumed samples:    320640000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623488E+00 | sop loss: 5.091412E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.83 | backward-compute: 79.79 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 17.74
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2505000 | lm loss value: 1.666115E+00 | lm loss PPL: 5.291570E+00 | sop loss value: 6.471702E-02 | sop loss PPL: 1.066857E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2506000/10000000 | consumed samples:    320768000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622313E+00 | sop loss: 5.134710E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.42 | backward-compute: 79.82 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 14.18
 iteration  2507000/10000000 | consumed samples:    320896000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617520E+00 | sop loss: 5.206693E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.18 | backward-compute: 79.83 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 17.40
 iteration  2508000/10000000 | consumed samples:    321024000 | elapsed time per iteration (ms): 252.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618307E+00 | sop loss: 5.143088E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 140.22 | backward-compute: 79.75 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 16.10
 iteration  2509000/10000000 | consumed samples:    321152000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623155E+00 | sop loss: 5.155147E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.32 | backward-compute: 79.81 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 12.72
 iteration  2510000/10000000 | consumed samples:    321280000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619297E+00 | sop loss: 5.206967E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.53 | backward-compute: 79.82 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 14.13
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2510000 | lm loss value: 1.657592E+00 | lm loss PPL: 5.246662E+00 | sop loss value: 6.739105E-02 | sop loss PPL: 1.069714E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2511000/10000000 | consumed samples:    321408000 | elapsed time per iteration (ms): 252.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621758E+00 | sop loss: 5.063565E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.43 | backward-compute: 79.79 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.76 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.31 | batch-generator: 14.40
 iteration  2512000/10000000 | consumed samples:    321536000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620839E+00 | sop loss: 5.100547E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.33 | backward-compute: 79.82 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 13.27
 iteration  2513000/10000000 | consumed samples:    321664000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619341E+00 | sop loss: 5.115183E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.24 | backward-compute: 79.90 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 17.15
 iteration  2514000/10000000 | consumed samples:    321792000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619424E+00 | sop loss: 5.133851E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.60 | backward-compute: 79.77 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 19.79
 iteration  2515000/10000000 | consumed samples:    321920000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615163E+00 | sop loss: 5.217348E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.27 | backward-compute: 79.77 | backward-params-all-reduce: 14.27 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.52 | batch-generator: 16.85
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2515000 | lm loss value: 1.688505E+00 | lm loss PPL: 5.411384E+00 | sop loss value: 6.280750E-02 | sop loss PPL: 1.064822E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2516000/10000000 | consumed samples:    322048000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620360E+00 | sop loss: 5.102125E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.10 | backward-compute: 79.85 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 15.20
 iteration  2517000/10000000 | consumed samples:    322176000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618978E+00 | sop loss: 5.116943E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.19 | backward-compute: 79.75 | backward-params-all-reduce: 14.37 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.61 | batch-generator: 21.70
 iteration  2518000/10000000 | consumed samples:    322304000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619325E+00 | sop loss: 5.081464E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.65 | backward-compute: 79.75 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 14.05
 iteration  2519000/10000000 | consumed samples:    322432000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619902E+00 | sop loss: 5.152557E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.13 | backward-compute: 79.73 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 18.04
 iteration  2520000/10000000 | consumed samples:    322560000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621110E+00 | sop loss: 5.171081E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.73 | backward-compute: 79.75 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 16.39
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2520000 | lm loss value: 1.640711E+00 | lm loss PPL: 5.158838E+00 | sop loss value: 4.728751E-02 | sop loss PPL: 1.048423E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2521000/10000000 | consumed samples:    322688000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619522E+00 | sop loss: 5.212345E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.71 | backward-compute: 79.81 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.76 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.02 | optimizer-copy-main-to-model-params: 1.22 | optimizer: 16.29 | batch-generator: 13.08
 iteration  2522000/10000000 | consumed samples:    322816000 | elapsed time per iteration (ms): 245.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619054E+00 | sop loss: 5.048932E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.43 | backward-compute: 79.81 | backward-params-all-reduce: 14.37 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.58 | batch-generator: 17.62
 iteration  2523000/10000000 | consumed samples:    322944000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618566E+00 | sop loss: 5.257681E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.58 | backward-compute: 79.79 | backward-params-all-reduce: 14.50 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.19 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.62 | batch-generator: 15.98
 iteration  2524000/10000000 | consumed samples:    323072000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619657E+00 | sop loss: 5.113641E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.21 | backward-compute: 79.79 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 24.34
 iteration  2525000/10000000 | consumed samples:    323200000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620303E+00 | sop loss: 5.070433E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.15 | backward-compute: 79.78 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 18.50
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2525000 | lm loss value: 1.607047E+00 | lm loss PPL: 4.988058E+00 | sop loss value: 6.950089E-02 | sop loss PPL: 1.071973E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2526000/10000000 | consumed samples:    323328000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617035E+00 | sop loss: 5.223960E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.79 | backward-compute: 79.86 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 20.66
 iteration  2527000/10000000 | consumed samples:    323456000 | elapsed time per iteration (ms): 245.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619138E+00 | sop loss: 5.109526E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.86 | backward-compute: 79.79 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.09
 iteration  2528000/10000000 | consumed samples:    323584000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621079E+00 | sop loss: 5.063979E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.34 | backward-compute: 79.77 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 13.42
 iteration  2529000/10000000 | consumed samples:    323712000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622277E+00 | sop loss: 5.168429E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.12 | backward-compute: 79.77 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 16.03
 iteration  2530000/10000000 | consumed samples:    323840000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621514E+00 | sop loss: 5.222406E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.40 | backward-compute: 79.79 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 17.06
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2530000 | lm loss value: 1.643430E+00 | lm loss PPL: 5.172882E+00 | sop loss value: 5.770602E-02 | sop loss PPL: 1.059404E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2531000/10000000 | consumed samples:    323968000 | elapsed time per iteration (ms): 250.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617603E+00 | sop loss: 5.114678E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.83 | backward-compute: 79.86 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 17.87
 iteration  2532000/10000000 | consumed samples:    324096000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616688E+00 | sop loss: 5.131486E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.03 | backward-compute: 79.81 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 24.71
 iteration  2533000/10000000 | consumed samples:    324224000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621674E+00 | sop loss: 5.148759E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.25 | backward-compute: 79.83 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.24
 iteration  2534000/10000000 | consumed samples:    324352000 | elapsed time per iteration (ms): 251.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622049E+00 | sop loss: 5.038047E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.39 | backward-compute: 79.84 | backward-params-all-reduce: 14.45 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.24 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.69 | batch-generator: 22.93
 iteration  2535000/10000000 | consumed samples:    324480000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619014E+00 | sop loss: 5.222280E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.43 | backward-compute: 79.84 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.65
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2535000 | lm loss value: 1.676970E+00 | lm loss PPL: 5.349320E+00 | sop loss value: 4.423410E-02 | sop loss PPL: 1.045227E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2536000/10000000 | consumed samples:    324608000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622246E+00 | sop loss: 5.099708E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.17 | backward-compute: 79.83 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.84
 iteration  2537000/10000000 | consumed samples:    324736000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.623533E+00 | sop loss: 5.094321E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.86 | backward-compute: 79.83 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.33 | batch-generator: 14.17
 iteration  2538000/10000000 | consumed samples:    324864000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620826E+00 | sop loss: 5.011899E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.40 | backward-compute: 79.83 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 18.11
 iteration  2539000/10000000 | consumed samples:    324992000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618473E+00 | sop loss: 5.067786E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.65 | backward-compute: 79.79 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 16.09
 iteration  2540000/10000000 | consumed samples:    325120000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620142E+00 | sop loss: 5.207945E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.12 | backward-compute: 79.79 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.56 | batch-generator: 17.50
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2540000 | lm loss value: 1.642252E+00 | lm loss PPL: 5.166793E+00 | sop loss value: 6.941969E-02 | sop loss PPL: 1.071886E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2541000/10000000 | consumed samples:    325248000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618869E+00 | sop loss: 5.092287E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.70 | backward-compute: 79.83 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.54 | batch-generator: 16.29
 iteration  2542000/10000000 | consumed samples:    325376000 | elapsed time per iteration (ms): 251.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619096E+00 | sop loss: 5.191340E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.05 | backward-compute: 79.86 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 18.75
 iteration  2543000/10000000 | consumed samples:    325504000 | elapsed time per iteration (ms): 246.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620377E+00 | sop loss: 4.964556E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.27 | backward-compute: 79.91 | backward-params-all-reduce: 14.39 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.20 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.64 | batch-generator: 18.42
 iteration  2544000/10000000 | consumed samples:    325632000 | elapsed time per iteration (ms): 250.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617062E+00 | sop loss: 5.080396E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.90 | backward-compute: 79.81 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.50 | batch-generator: 18.05
 iteration  2545000/10000000 | consumed samples:    325760000 | elapsed time per iteration (ms): 245.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615823E+00 | sop loss: 5.127321E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.84 | backward-compute: 79.83 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.85
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2545000 | lm loss value: 1.698602E+00 | lm loss PPL: 5.466300E+00 | sop loss value: 5.949102E-02 | sop loss PPL: 1.061296E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2546000/10000000 | consumed samples:    325888000 | elapsed time per iteration (ms): 250.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619607E+00 | sop loss: 5.229386E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.17 | backward-compute: 79.82 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 15.83
 iteration  2547000/10000000 | consumed samples:    326016000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620458E+00 | sop loss: 5.091534E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.56 | backward-compute: 79.77 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 16.60
 iteration  2548000/10000000 | consumed samples:    326144000 | elapsed time per iteration (ms): 250.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620165E+00 | sop loss: 5.166789E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.98 | backward-compute: 79.80 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 18.15
 iteration  2549000/10000000 | consumed samples:    326272000 | elapsed time per iteration (ms): 251.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620735E+00 | sop loss: 4.984060E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.16 | backward-compute: 79.76 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 22.18
 iteration  2550000/10000000 | consumed samples:    326400000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618449E+00 | sop loss: 5.157582E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.46 | backward-compute: 79.84 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 15.20
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2550000 | lm loss value: 1.625277E+00 | lm loss PPL: 5.079826E+00 | sop loss value: 7.369968E-02 | sop loss PPL: 1.076483E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 2550000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 2550000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2376.33
 iteration  2551000/10000000 | consumed samples:    326528000 | elapsed time per iteration (ms): 251.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620274E+00 | sop loss: 5.055434E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.91 | backward-compute: 79.84 | backward-params-all-reduce: 14.38 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.56 | batch-generator: 15.35
 iteration  2552000/10000000 | consumed samples:    326656000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616788E+00 | sop loss: 5.076960E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.44 | backward-compute: 79.81 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.14
 iteration  2553000/10000000 | consumed samples:    326784000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620265E+00 | sop loss: 5.169274E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.36 | backward-compute: 79.76 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.01
 iteration  2554000/10000000 | consumed samples:    326912000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618005E+00 | sop loss: 5.049926E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.84 | backward-compute: 79.77 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 18.52
 iteration  2555000/10000000 | consumed samples:    327040000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618817E+00 | sop loss: 5.119815E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.66 | backward-compute: 79.81 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 16.13
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2555000 | lm loss value: 1.677006E+00 | lm loss PPL: 5.349516E+00 | sop loss value: 6.029072E-02 | sop loss PPL: 1.062145E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2556000/10000000 | consumed samples:    327168000 | elapsed time per iteration (ms): 252.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620909E+00 | sop loss: 4.975788E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.24 | backward-compute: 79.78 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 10.73
 iteration  2557000/10000000 | consumed samples:    327296000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619635E+00 | sop loss: 5.040476E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.92 | backward-compute: 79.78 | backward-params-all-reduce: 14.37 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.56 | batch-generator: 14.99
 iteration  2558000/10000000 | consumed samples:    327424000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617244E+00 | sop loss: 5.134256E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.30 | backward-compute: 79.80 | backward-params-all-reduce: 14.58 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.23 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.66 | batch-generator: 16.17
 iteration  2559000/10000000 | consumed samples:    327552000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620679E+00 | sop loss: 5.253036E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.61 | backward-compute: 79.82 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 16.73
 iteration  2560000/10000000 | consumed samples:    327680000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621226E+00 | sop loss: 5.199825E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.36 | backward-compute: 79.93 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.48
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2560000 | lm loss value: 1.665414E+00 | lm loss PPL: 5.287861E+00 | sop loss value: 5.637404E-02 | sop loss PPL: 1.057993E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2561000/10000000 | consumed samples:    327808000 | elapsed time per iteration (ms): 250.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618996E+00 | sop loss: 5.089154E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.19 | backward-compute: 79.86 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 17.93
 iteration  2562000/10000000 | consumed samples:    327936000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619004E+00 | sop loss: 5.131522E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.66 | backward-compute: 79.84 | backward-params-all-reduce: 14.40 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.21 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.64 | batch-generator: 13.58
 iteration  2563000/10000000 | consumed samples:    328064000 | elapsed time per iteration (ms): 246.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.624124E+00 | sop loss: 5.094143E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.38 | backward-compute: 79.77 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.65
 iteration  2564000/10000000 | consumed samples:    328192000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619715E+00 | sop loss: 5.161516E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.36 | backward-compute: 79.81 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.88
 iteration  2565000/10000000 | consumed samples:    328320000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617709E+00 | sop loss: 5.163921E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.86 | backward-compute: 79.86 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.41 | batch-generator: 15.07
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2565000 | lm loss value: 1.666824E+00 | lm loss PPL: 5.295324E+00 | sop loss value: 5.763144E-02 | sop loss PPL: 1.059325E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2566000/10000000 | consumed samples:    328448000 | elapsed time per iteration (ms): 250.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619905E+00 | sop loss: 5.161629E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.24 | backward-compute: 79.89 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 16.97
 iteration  2567000/10000000 | consumed samples:    328576000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621221E+00 | sop loss: 5.036863E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.35 | backward-compute: 79.95 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 14.04
 iteration  2568000/10000000 | consumed samples:    328704000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621463E+00 | sop loss: 5.136707E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.56 | backward-compute: 79.84 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 17.28
 iteration  2569000/10000000 | consumed samples:    328832000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618211E+00 | sop loss: 5.115928E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.78 | backward-compute: 79.84 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 18.60
 iteration  2570000/10000000 | consumed samples:    328960000 | elapsed time per iteration (ms): 246.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616693E+00 | sop loss: 5.197908E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.71 | backward-compute: 79.80 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 15.99
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2570000 | lm loss value: 1.672017E+00 | lm loss PPL: 5.322893E+00 | sop loss value: 6.427210E-02 | sop loss PPL: 1.066383E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2571000/10000000 | consumed samples:    329088000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619420E+00 | sop loss: 5.117479E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.76 | backward-compute: 79.75 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 13.33
 iteration  2572000/10000000 | consumed samples:    329216000 | elapsed time per iteration (ms): 245.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620580E+00 | sop loss: 5.090052E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.04 | backward-compute: 79.84 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 16.44
 iteration  2573000/10000000 | consumed samples:    329344000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621369E+00 | sop loss: 5.226084E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.22 | backward-compute: 79.81 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 20.34
 iteration  2574000/10000000 | consumed samples:    329472000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619917E+00 | sop loss: 5.088339E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.21 | backward-compute: 79.81 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 21.52
 iteration  2575000/10000000 | consumed samples:    329600000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618173E+00 | sop loss: 5.290869E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.28 | backward-compute: 79.88 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.85
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2575000 | lm loss value: 1.648663E+00 | lm loss PPL: 5.200024E+00 | sop loss value: 7.253603E-02 | sop loss PPL: 1.075232E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2576000/10000000 | consumed samples:    329728000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617394E+00 | sop loss: 5.127585E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.07 | backward-compute: 79.85 | backward-params-all-reduce: 14.31 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.85 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.19 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.63 | batch-generator: 22.56
 iteration  2577000/10000000 | consumed samples:    329856000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621831E+00 | sop loss: 5.191716E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.69 | backward-compute: 79.82 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 15.77
 iteration  2578000/10000000 | consumed samples:    329984000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616502E+00 | sop loss: 5.183651E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.44 | backward-compute: 79.79 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 14.71
 iteration  2579000/10000000 | consumed samples:    330112000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622250E+00 | sop loss: 5.206103E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.10 | backward-compute: 79.75 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 13.04
 iteration  2580000/10000000 | consumed samples:    330240000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619026E+00 | sop loss: 5.180766E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.01 | backward-compute: 79.79 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 15.81
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2580000 | lm loss value: 1.627892E+00 | lm loss PPL: 5.093125E+00 | sop loss value: 6.200731E-02 | sop loss PPL: 1.063970E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2581000/10000000 | consumed samples:    330368000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620779E+00 | sop loss: 5.187284E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.95 | backward-compute: 79.79 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 21.20
 iteration  2582000/10000000 | consumed samples:    330496000 | elapsed time per iteration (ms): 246.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616335E+00 | sop loss: 5.021636E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.61 | backward-compute: 79.80 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 15.30
 iteration  2583000/10000000 | consumed samples:    330624000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618465E+00 | sop loss: 5.020665E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.70 | backward-compute: 79.85 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 17.97
 iteration  2584000/10000000 | consumed samples:    330752000 | elapsed time per iteration (ms): 246.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619190E+00 | sop loss: 5.110858E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.28 | backward-compute: 79.83 | backward-params-all-reduce: 14.22 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 18.36
 iteration  2585000/10000000 | consumed samples:    330880000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618572E+00 | sop loss: 5.140855E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.17 | backward-compute: 79.81 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.47 | batch-generator: 18.11
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2585000 | lm loss value: 1.702121E+00 | lm loss PPL: 5.485568E+00 | sop loss value: 7.161285E-02 | sop loss PPL: 1.074239E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2586000/10000000 | consumed samples:    331008000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619057E+00 | sop loss: 5.148512E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.25 | backward-compute: 79.76 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 17.08
 iteration  2587000/10000000 | consumed samples:    331136000 | elapsed time per iteration (ms): 246.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619808E+00 | sop loss: 5.071417E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.60 | backward-compute: 79.94 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 16.95
 iteration  2588000/10000000 | consumed samples:    331264000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620112E+00 | sop loss: 5.153059E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.48 | backward-compute: 79.83 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 26.56
 iteration  2589000/10000000 | consumed samples:    331392000 | elapsed time per iteration (ms): 249.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619805E+00 | sop loss: 5.175562E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.91 | backward-compute: 79.86 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 23.97
 iteration  2590000/10000000 | consumed samples:    331520000 | elapsed time per iteration (ms): 250.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618355E+00 | sop loss: 5.148920E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.95 | backward-compute: 79.79 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.53
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2590000 | lm loss value: 1.657333E+00 | lm loss PPL: 5.245305E+00 | sop loss value: 5.131524E-02 | sop loss PPL: 1.052655E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2591000/10000000 | consumed samples:    331648000 | elapsed time per iteration (ms): 251.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620059E+00 | sop loss: 5.222726E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.89 | backward-compute: 79.77 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.86
 iteration  2592000/10000000 | consumed samples:    331776000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.622707E+00 | sop loss: 5.062391E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.36 | backward-compute: 79.83 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 16.27
 iteration  2593000/10000000 | consumed samples:    331904000 | elapsed time per iteration (ms): 246.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616302E+00 | sop loss: 5.135691E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.69 | backward-compute: 79.75 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 16.06
 iteration  2594000/10000000 | consumed samples:    332032000 | elapsed time per iteration (ms): 250.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618936E+00 | sop loss: 5.045080E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.87 | backward-compute: 79.78 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 12.64
 iteration  2595000/10000000 | consumed samples:    332160000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618774E+00 | sop loss: 5.094668E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.22 | backward-compute: 79.84 | backward-params-all-reduce: 14.31 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.53 | batch-generator: 17.35
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2595000 | lm loss value: 1.636518E+00 | lm loss PPL: 5.137252E+00 | sop loss value: 5.206751E-02 | sop loss PPL: 1.053447E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2596000/10000000 | consumed samples:    332288000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620625E+00 | sop loss: 5.122452E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.43 | backward-compute: 79.73 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 17.07
 iteration  2597000/10000000 | consumed samples:    332416000 | elapsed time per iteration (ms): 246.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620043E+00 | sop loss: 5.245129E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.45 | backward-compute: 79.79 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 16.10
 iteration  2598000/10000000 | consumed samples:    332544000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.613492E+00 | sop loss: 5.166132E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.47 | backward-compute: 79.86 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 19.44
 iteration  2599000/10000000 | consumed samples:    332672000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616896E+00 | sop loss: 4.966638E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.59 | backward-compute: 79.76 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.41 | batch-generator: 19.12
 iteration  2600000/10000000 | consumed samples:    332800000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619709E+00 | sop loss: 5.156552E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.05 | backward-compute: 79.77 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.76
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2600000 | lm loss value: 1.625200E+00 | lm loss PPL: 5.079434E+00 | sop loss value: 5.054269E-02 | sop loss PPL: 1.051842E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 2600000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 2600000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2358.44
 iteration  2601000/10000000 | consumed samples:    332928000 | elapsed time per iteration (ms): 252.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618689E+00 | sop loss: 5.051552E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.25 | backward-compute: 79.77 | backward-params-all-reduce: 14.20 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.50 | batch-generator: 13.52
 iteration  2602000/10000000 | consumed samples:    333056000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618554E+00 | sop loss: 5.148962E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.38 | backward-compute: 79.69 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.24 | optimizer-clip-main-grad: 4.03 | optimizer-copy-main-to-model-params: 1.22 | optimizer: 16.31 | batch-generator: 14.36
 iteration  2603000/10000000 | consumed samples:    333184000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618936E+00 | sop loss: 5.018891E-02 | loss scale: 8192.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.44 | backward-compute: 79.74 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 16.35
 iteration  2604000/10000000 | consumed samples:    333312000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619674E+00 | sop loss: 5.178061E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.30 | backward-compute: 79.78 | backward-params-all-reduce: 14.30 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 21.29
 iteration  2605000/10000000 | consumed samples:    333440000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617821E+00 | sop loss: 5.026015E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.15 | backward-compute: 79.80 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 16.83
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2605000 | lm loss value: 1.697591E+00 | lm loss PPL: 5.460778E+00 | sop loss value: 7.114702E-02 | sop loss PPL: 1.073739E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2606000/10000000 | consumed samples:    333568000 | elapsed time per iteration (ms): 251.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619088E+00 | sop loss: 5.059126E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.37 | backward-compute: 79.70 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 16.65
 iteration  2607000/10000000 | consumed samples:    333696000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618388E+00 | sop loss: 5.112305E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.54 | backward-compute: 79.81 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 19.07
 iteration  2608000/10000000 | consumed samples:    333824000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616324E+00 | sop loss: 5.131918E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.76 | backward-compute: 79.82 | backward-params-all-reduce: 14.28 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 18.55
 iteration  2609000/10000000 | consumed samples:    333952000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618103E+00 | sop loss: 5.186890E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.63 | backward-compute: 79.83 | backward-params-all-reduce: 14.62 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.87 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.27 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.75 | batch-generator: 17.26
 iteration  2610000/10000000 | consumed samples:    334080000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618193E+00 | sop loss: 5.115920E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.63 | backward-compute: 79.92 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 17.81
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2610000 | lm loss value: 1.655573E+00 | lm loss PPL: 5.236081E+00 | sop loss value: 5.528167E-02 | sop loss PPL: 1.056838E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2611000/10000000 | consumed samples:    334208000 | elapsed time per iteration (ms): 250.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617975E+00 | sop loss: 5.170466E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.45 | backward-compute: 79.83 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 13.31
 iteration  2612000/10000000 | consumed samples:    334336000 | elapsed time per iteration (ms): 249.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618891E+00 | sop loss: 5.102801E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.07 | backward-compute: 79.84 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 15.89
 iteration  2613000/10000000 | consumed samples:    334464000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616694E+00 | sop loss: 5.139648E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.33 | backward-compute: 79.83 | backward-params-all-reduce: 14.43 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.20 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.62 | batch-generator: 12.71
 iteration  2614000/10000000 | consumed samples:    334592000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618283E+00 | sop loss: 5.166441E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.25 | backward-compute: 79.78 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.97
 iteration  2615000/10000000 | consumed samples:    334720000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616834E+00 | sop loss: 5.084447E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.46 | backward-compute: 79.80 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 17.45
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2615000 | lm loss value: 1.681246E+00 | lm loss PPL: 5.372248E+00 | sop loss value: 6.649607E-02 | sop loss PPL: 1.068757E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2616000/10000000 | consumed samples:    334848000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616230E+00 | sop loss: 5.095896E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.35 | backward-compute: 79.79 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 14.89
 iteration  2617000/10000000 | consumed samples:    334976000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618438E+00 | sop loss: 5.233500E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.60 | backward-compute: 79.83 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 17.23
 iteration  2618000/10000000 | consumed samples:    335104000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618511E+00 | sop loss: 5.107027E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.81 | backward-compute: 79.83 | backward-params-all-reduce: 14.27 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 17.19
 iteration  2619000/10000000 | consumed samples:    335232000 | elapsed time per iteration (ms): 247.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621417E+00 | sop loss: 5.166187E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.25 | backward-compute: 79.87 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 21.73
 iteration  2620000/10000000 | consumed samples:    335360000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617632E+00 | sop loss: 5.159174E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.37 | backward-compute: 79.85 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 20.38
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2620000 | lm loss value: 1.690515E+00 | lm loss PPL: 5.422275E+00 | sop loss value: 5.866674E-02 | sop loss PPL: 1.060422E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2621000/10000000 | consumed samples:    335488000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619884E+00 | sop loss: 5.139266E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.50 | backward-compute: 79.73 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 15.95
 iteration  2622000/10000000 | consumed samples:    335616000 | elapsed time per iteration (ms): 251.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616703E+00 | sop loss: 5.262189E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.42 | backward-compute: 79.73 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.38
 iteration  2623000/10000000 | consumed samples:    335744000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619631E+00 | sop loss: 5.183400E-02 | loss scale: 8192.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.83 | backward-compute: 79.83 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 23.92
 iteration  2624000/10000000 | consumed samples:    335872000 | elapsed time per iteration (ms): 250.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617717E+00 | sop loss: 5.177427E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.14 | backward-compute: 79.77 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 14.69
 iteration  2625000/10000000 | consumed samples:    336000000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619258E+00 | sop loss: 5.180476E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.97 | backward-compute: 79.84 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 15.25
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2625000 | lm loss value: 1.673569E+00 | lm loss PPL: 5.331161E+00 | sop loss value: 8.178329E-02 | sop loss PPL: 1.085221E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2626000/10000000 | consumed samples:    336128000 | elapsed time per iteration (ms): 251.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619046E+00 | sop loss: 5.130572E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.64 | backward-compute: 79.78 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 17.30
 iteration  2627000/10000000 | consumed samples:    336256000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620037E+00 | sop loss: 5.013199E-02 | loss scale: 8192.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.52 | backward-compute: 79.91 | backward-params-all-reduce: 13.92 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.35 | batch-generator: 16.07
 iteration  2628000/10000000 | consumed samples:    336384000 | elapsed time per iteration (ms): 249.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620291E+00 | sop loss: 5.188231E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.45 | backward-compute: 79.71 | backward-params-all-reduce: 14.39 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.19 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.60 | batch-generator: 14.33
 iteration  2629000/10000000 | consumed samples:    336512000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618317E+00 | sop loss: 5.201213E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.89 | backward-compute: 79.79 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 12.46
 iteration  2630000/10000000 | consumed samples:    336640000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615821E+00 | sop loss: 5.203837E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.82 | backward-compute: 79.81 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 13.39
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2630000 | lm loss value: 1.660780E+00 | lm loss PPL: 5.263414E+00 | sop loss value: 5.430776E-02 | sop loss PPL: 1.055809E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2631000/10000000 | consumed samples:    336768000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620128E+00 | sop loss: 5.162729E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.96 | backward-compute: 79.79 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 17.18
 iteration  2632000/10000000 | consumed samples:    336896000 | elapsed time per iteration (ms): 246.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620511E+00 | sop loss: 5.065737E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.46 | backward-compute: 79.85 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 16.02
 iteration  2633000/10000000 | consumed samples:    337024000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619131E+00 | sop loss: 5.121684E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.83 | backward-compute: 79.80 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 17.24
 iteration  2634000/10000000 | consumed samples:    337152000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621279E+00 | sop loss: 5.168864E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.61 | backward-compute: 79.78 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 13.42
 iteration  2635000/10000000 | consumed samples:    337280000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618967E+00 | sop loss: 5.095210E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.00 | backward-compute: 79.82 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 14.26
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2635000 | lm loss value: 1.652242E+00 | lm loss PPL: 5.218667E+00 | sop loss value: 8.594069E-02 | sop loss PPL: 1.089742E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2636000/10000000 | consumed samples:    337408000 | elapsed time per iteration (ms): 251.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621590E+00 | sop loss: 5.101011E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.96 | backward-compute: 79.80 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.18
 iteration  2637000/10000000 | consumed samples:    337536000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617923E+00 | sop loss: 4.978593E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.52 | backward-compute: 79.81 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 16.24
 iteration  2638000/10000000 | consumed samples:    337664000 | elapsed time per iteration (ms): 245.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616999E+00 | sop loss: 5.127356E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.64 | backward-compute: 79.78 | backward-params-all-reduce: 14.39 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.83
 iteration  2639000/10000000 | consumed samples:    337792000 | elapsed time per iteration (ms): 250.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618995E+00 | sop loss: 5.135382E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.53 | backward-compute: 79.79 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.59 | batch-generator: 22.15
 iteration  2640000/10000000 | consumed samples:    337920000 | elapsed time per iteration (ms): 249.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619838E+00 | sop loss: 5.192796E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.17 | backward-compute: 79.82 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 25.19
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2640000 | lm loss value: 1.643035E+00 | lm loss PPL: 5.170839E+00 | sop loss value: 6.673378E-02 | sop loss PPL: 1.069011E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2641000/10000000 | consumed samples:    338048000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615721E+00 | sop loss: 5.113250E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.61 | backward-compute: 79.83 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 19.02
 iteration  2642000/10000000 | consumed samples:    338176000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.613184E+00 | sop loss: 5.227312E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.94 | backward-compute: 79.78 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 18.55
 iteration  2643000/10000000 | consumed samples:    338304000 | elapsed time per iteration (ms): 246.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619979E+00 | sop loss: 5.112282E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.75 | backward-compute: 79.77 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.36
 iteration  2644000/10000000 | consumed samples:    338432000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618453E+00 | sop loss: 5.161032E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.66 | backward-compute: 79.83 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 17.81
 iteration  2645000/10000000 | consumed samples:    338560000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616454E+00 | sop loss: 5.184055E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.02 | backward-compute: 79.82 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 17.18
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2645000 | lm loss value: 1.675673E+00 | lm loss PPL: 5.342391E+00 | sop loss value: 7.370619E-02 | sop loss PPL: 1.076490E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2646000/10000000 | consumed samples:    338688000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617564E+00 | sop loss: 5.203070E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.39 | backward-compute: 79.84 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 16.74
 iteration  2647000/10000000 | consumed samples:    338816000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.613486E+00 | sop loss: 5.077720E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.85 | backward-compute: 79.82 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 17.12
 iteration  2648000/10000000 | consumed samples:    338944000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615961E+00 | sop loss: 5.155445E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.46 | backward-compute: 79.82 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 15.71
 iteration  2649000/10000000 | consumed samples:    339072000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616522E+00 | sop loss: 5.233413E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.60 | backward-compute: 79.82 | backward-params-all-reduce: 14.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 15.92
 iteration  2650000/10000000 | consumed samples:    339200000 | elapsed time per iteration (ms): 249.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619155E+00 | sop loss: 5.049971E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.94 | backward-compute: 79.79 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 12.91
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2650000 | lm loss value: 1.644367E+00 | lm loss PPL: 5.177732E+00 | sop loss value: 6.602062E-02 | sop loss PPL: 1.068249E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 2650000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 2650000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2399.25
 iteration  2651000/10000000 | consumed samples:    339328000 | elapsed time per iteration (ms): 252.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617673E+00 | sop loss: 5.177273E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.07 | backward-compute: 79.81 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 16.92
 iteration  2652000/10000000 | consumed samples:    339456000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618254E+00 | sop loss: 5.074317E-02 | loss scale: 8192.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.30 | backward-compute: 79.81 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 16.01
 iteration  2653000/10000000 | consumed samples:    339584000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617919E+00 | sop loss: 5.135930E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.90 | backward-compute: 79.84 | backward-params-all-reduce: 14.52 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.22 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.66 | batch-generator: 15.99
 iteration  2654000/10000000 | consumed samples:    339712000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618461E+00 | sop loss: 5.125422E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.30 | backward-compute: 79.82 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 18.20
 iteration  2655000/10000000 | consumed samples:    339840000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618328E+00 | sop loss: 5.114836E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.22 | backward-compute: 79.77 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 12.76
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2655000 | lm loss value: 1.674994E+00 | lm loss PPL: 5.338762E+00 | sop loss value: 6.452176E-02 | sop loss PPL: 1.066649E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2656000/10000000 | consumed samples:    339968000 | elapsed time per iteration (ms): 252.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618205E+00 | sop loss: 5.111092E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.70 | backward-compute: 79.83 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 14.06
 iteration  2657000/10000000 | consumed samples:    340096000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619100E+00 | sop loss: 5.108867E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.02 | backward-compute: 79.85 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.44
 iteration  2658000/10000000 | consumed samples:    340224000 | elapsed time per iteration (ms): 249.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620740E+00 | sop loss: 5.237903E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.35 | backward-compute: 79.80 | backward-params-all-reduce: 14.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.60 | batch-generator: 13.89
 iteration  2659000/10000000 | consumed samples:    340352000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615801E+00 | sop loss: 5.064070E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.56 | backward-compute: 79.77 | backward-params-all-reduce: 14.36 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.56 | batch-generator: 14.39
 iteration  2660000/10000000 | consumed samples:    340480000 | elapsed time per iteration (ms): 250.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.613348E+00 | sop loss: 5.012801E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.83 | backward-compute: 79.75 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 15.45
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2660000 | lm loss value: 1.683438E+00 | lm loss PPL: 5.384036E+00 | sop loss value: 4.990318E-02 | sop loss PPL: 1.051169E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2661000/10000000 | consumed samples:    340608000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615351E+00 | sop loss: 5.096773E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.12 | backward-compute: 79.78 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 20.14
 iteration  2662000/10000000 | consumed samples:    340736000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618287E+00 | sop loss: 5.113528E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.28 | backward-compute: 79.79 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.50 | batch-generator: 22.53
 iteration  2663000/10000000 | consumed samples:    340864000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616799E+00 | sop loss: 5.201245E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.31 | backward-compute: 79.71 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 17.55
 iteration  2664000/10000000 | consumed samples:    340992000 | elapsed time per iteration (ms): 245.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617888E+00 | sop loss: 5.232092E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.31 | backward-compute: 79.79 | backward-params-all-reduce: 14.35 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.59 | batch-generator: 16.28
 iteration  2665000/10000000 | consumed samples:    341120000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617275E+00 | sop loss: 5.215764E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.58 | backward-compute: 79.77 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.31
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2665000 | lm loss value: 1.673808E+00 | lm loss PPL: 5.332436E+00 | sop loss value: 6.107432E-02 | sop loss PPL: 1.062978E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2666000/10000000 | consumed samples:    341248000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618282E+00 | sop loss: 5.164653E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.16 | backward-compute: 79.79 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.55 | batch-generator: 16.04
 iteration  2667000/10000000 | consumed samples:    341376000 | elapsed time per iteration (ms): 249.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621995E+00 | sop loss: 5.102388E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.44 | backward-compute: 79.84 | backward-params-all-reduce: 14.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.53 | batch-generator: 18.17
 iteration  2668000/10000000 | consumed samples:    341504000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618840E+00 | sop loss: 5.264825E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.18 | backward-compute: 79.82 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 16.77
 iteration  2669000/10000000 | consumed samples:    341632000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618598E+00 | sop loss: 5.082529E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.58 | backward-compute: 79.81 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 20.03
 iteration  2670000/10000000 | consumed samples:    341760000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618168E+00 | sop loss: 5.168118E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.41 | backward-compute: 79.83 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 19.20
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2670000 | lm loss value: 1.651845E+00 | lm loss PPL: 5.216594E+00 | sop loss value: 6.957366E-02 | sop loss PPL: 1.072051E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2671000/10000000 | consumed samples:    341888000 | elapsed time per iteration (ms): 251.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614448E+00 | sop loss: 5.086148E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.66 | backward-compute: 79.79 | backward-params-all-reduce: 14.35 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.46 | batch-generator: 13.83
 iteration  2672000/10000000 | consumed samples:    342016000 | elapsed time per iteration (ms): 246.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619325E+00 | sop loss: 5.124558E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.72 | backward-compute: 79.75 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 13.99
 iteration  2673000/10000000 | consumed samples:    342144000 | elapsed time per iteration (ms): 247.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616074E+00 | sop loss: 5.091644E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.17 | backward-compute: 79.79 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 18.05
 iteration  2674000/10000000 | consumed samples:    342272000 | elapsed time per iteration (ms): 246.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.621260E+00 | sop loss: 5.027285E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.19 | backward-compute: 79.81 | backward-params-all-reduce: 14.79 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.89 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.34 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.86 | batch-generator: 16.15
 iteration  2675000/10000000 | consumed samples:    342400000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618958E+00 | sop loss: 5.180512E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.60 | backward-compute: 79.81 | backward-params-all-reduce: 14.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 16.50
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2675000 | lm loss value: 1.634696E+00 | lm loss PPL: 5.127900E+00 | sop loss value: 5.556289E-02 | sop loss PPL: 1.057135E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2676000/10000000 | consumed samples:    342528000 | elapsed time per iteration (ms): 252.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617133E+00 | sop loss: 5.169102E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.38 | backward-compute: 79.82 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 15.69
 iteration  2677000/10000000 | consumed samples:    342656000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616521E+00 | sop loss: 5.242704E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.16 | backward-compute: 79.84 | backward-params-all-reduce: 14.39 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.19 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.62 | batch-generator: 14.13
 iteration  2678000/10000000 | consumed samples:    342784000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615163E+00 | sop loss: 5.147817E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.23 | backward-compute: 79.86 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 23.33
 iteration  2679000/10000000 | consumed samples:    342912000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.613758E+00 | sop loss: 5.101140E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.63 | backward-compute: 79.82 | backward-params-all-reduce: 14.34 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.53 | batch-generator: 13.45
 iteration  2680000/10000000 | consumed samples:    343040000 | elapsed time per iteration (ms): 250.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616298E+00 | sop loss: 5.062094E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.13 | backward-compute: 79.84 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 14.10
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2680000 | lm loss value: 1.676823E+00 | lm loss PPL: 5.348536E+00 | sop loss value: 6.342159E-02 | sop loss PPL: 1.065476E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2681000/10000000 | consumed samples:    343168000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616470E+00 | sop loss: 5.152986E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.90 | backward-compute: 79.76 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 16.16
 iteration  2682000/10000000 | consumed samples:    343296000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616955E+00 | sop loss: 4.961811E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.03 | backward-compute: 79.78 | backward-params-all-reduce: 14.33 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 19.79
 iteration  2683000/10000000 | consumed samples:    343424000 | elapsed time per iteration (ms): 250.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616531E+00 | sop loss: 5.095637E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.36 | backward-compute: 79.81 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 18.93
 iteration  2684000/10000000 | consumed samples:    343552000 | elapsed time per iteration (ms): 246.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619114E+00 | sop loss: 5.104963E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.87 | backward-compute: 79.85 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 14.28
 iteration  2685000/10000000 | consumed samples:    343680000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614417E+00 | sop loss: 5.057365E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.64 | backward-compute: 79.85 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 12.56
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2685000 | lm loss value: 1.708449E+00 | lm loss PPL: 5.520393E+00 | sop loss value: 5.736610E-02 | sop loss PPL: 1.059043E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2686000/10000000 | consumed samples:    343808000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617969E+00 | sop loss: 5.147345E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.91 | backward-compute: 79.81 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 14.03
 iteration  2687000/10000000 | consumed samples:    343936000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619156E+00 | sop loss: 5.232641E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.47 | backward-compute: 79.83 | backward-params-all-reduce: 14.31 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 17.70
 iteration  2688000/10000000 | consumed samples:    344064000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614865E+00 | sop loss: 5.101662E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.34 | backward-compute: 79.86 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.55
 iteration  2689000/10000000 | consumed samples:    344192000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615266E+00 | sop loss: 5.061077E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.73 | backward-compute: 79.77 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 16.78
 iteration  2690000/10000000 | consumed samples:    344320000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617080E+00 | sop loss: 4.984922E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.23 | backward-compute: 79.77 | backward-params-all-reduce: 14.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 19.08
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2690000 | lm loss value: 1.639928E+00 | lm loss PPL: 5.154798E+00 | sop loss value: 6.892725E-02 | sop loss PPL: 1.071358E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2691000/10000000 | consumed samples:    344448000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617718E+00 | sop loss: 5.154870E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.83 | backward-compute: 79.91 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 17.11
 iteration  2692000/10000000 | consumed samples:    344576000 | elapsed time per iteration (ms): 251.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620003E+00 | sop loss: 5.206902E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.80 | backward-compute: 79.86 | backward-params-all-reduce: 14.40 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.57 | batch-generator: 16.52
 iteration  2693000/10000000 | consumed samples:    344704000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.620063E+00 | sop loss: 5.110341E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.29 | backward-compute: 79.88 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 17.57
 iteration  2694000/10000000 | consumed samples:    344832000 | elapsed time per iteration (ms): 252.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617100E+00 | sop loss: 5.191376E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 139.42 | backward-compute: 79.81 | backward-params-all-reduce: 13.90 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 12.36
 iteration  2695000/10000000 | consumed samples:    344960000 | elapsed time per iteration (ms): 250.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616868E+00 | sop loss: 5.077046E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.98 | backward-compute: 79.80 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 16.70
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2695000 | lm loss value: 1.631377E+00 | lm loss PPL: 5.110906E+00 | sop loss value: 7.234159E-02 | sop loss PPL: 1.075022E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2696000/10000000 | consumed samples:    345088000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617582E+00 | sop loss: 5.231938E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.07 | backward-compute: 79.80 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 16.84
 iteration  2697000/10000000 | consumed samples:    345216000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617973E+00 | sop loss: 5.173678E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.63 | backward-compute: 79.82 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.57
 iteration  2698000/10000000 | consumed samples:    345344000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619473E+00 | sop loss: 5.183477E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.93 | backward-compute: 79.88 | backward-params-all-reduce: 14.23 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.14 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.54 | batch-generator: 17.04
 iteration  2699000/10000000 | consumed samples:    345472000 | elapsed time per iteration (ms): 250.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614063E+00 | sop loss: 5.119568E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.74 | backward-compute: 79.83 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 16.76
 iteration  2700000/10000000 | consumed samples:    345600000 | elapsed time per iteration (ms): 247.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615747E+00 | sop loss: 4.991021E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.37 | backward-compute: 79.79 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 15.41
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2700000 | lm loss value: 1.652554E+00 | lm loss PPL: 5.220298E+00 | sop loss value: 5.390717E-02 | sop loss PPL: 1.055387E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 2700000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 2700000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2283.91
 iteration  2701000/10000000 | consumed samples:    345728000 | elapsed time per iteration (ms): 250.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616438E+00 | sop loss: 5.110187E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.43 | backward-compute: 79.80 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 14.82
 iteration  2702000/10000000 | consumed samples:    345856000 | elapsed time per iteration (ms): 251.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614736E+00 | sop loss: 5.057774E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.74 | backward-compute: 79.79 | backward-params-all-reduce: 13.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 29.48
 iteration  2703000/10000000 | consumed samples:    345984000 | elapsed time per iteration (ms): 250.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615937E+00 | sop loss: 5.324351E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.81 | backward-compute: 79.74 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.34
 iteration  2704000/10000000 | consumed samples:    346112000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618560E+00 | sop loss: 4.997843E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.71 | backward-compute: 79.86 | backward-params-all-reduce: 14.56 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.28 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.75 | batch-generator: 14.93
 iteration  2705000/10000000 | consumed samples:    346240000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614355E+00 | sop loss: 5.118354E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.72 | backward-compute: 79.84 | backward-params-all-reduce: 13.98 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 16.17
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2705000 | lm loss value: 1.651675E+00 | lm loss PPL: 5.215710E+00 | sop loss value: 4.870028E-02 | sop loss PPL: 1.049906E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2706000/10000000 | consumed samples:    346368000 | elapsed time per iteration (ms): 251.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614030E+00 | sop loss: 5.160275E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.60 | backward-compute: 79.83 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.45 | batch-generator: 16.25
 iteration  2707000/10000000 | consumed samples:    346496000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614565E+00 | sop loss: 5.165395E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.41 | backward-compute: 79.82 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.46 | batch-generator: 14.81
 iteration  2708000/10000000 | consumed samples:    346624000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616816E+00 | sop loss: 5.123072E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.10 | backward-compute: 79.83 | backward-params-all-reduce: 14.44 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.25 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.70 | batch-generator: 12.67
 iteration  2709000/10000000 | consumed samples:    346752000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615925E+00 | sop loss: 5.137129E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.88 | backward-compute: 79.81 | backward-params-all-reduce: 14.33 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.59 | batch-generator: 16.01
 iteration  2710000/10000000 | consumed samples:    346880000 | elapsed time per iteration (ms): 246.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614926E+00 | sop loss: 5.314843E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.12 | backward-compute: 79.81 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 18.65
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2710000 | lm loss value: 1.659250E+00 | lm loss PPL: 5.255365E+00 | sop loss value: 5.411624E-02 | sop loss PPL: 1.055607E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2711000/10000000 | consumed samples:    347008000 | elapsed time per iteration (ms): 250.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615989E+00 | sop loss: 5.007964E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.78 | backward-compute: 79.92 | backward-params-all-reduce: 13.91 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 24.18
 iteration  2712000/10000000 | consumed samples:    347136000 | elapsed time per iteration (ms): 250.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614220E+00 | sop loss: 5.173305E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 138.08 | backward-compute: 79.88 | backward-params-all-reduce: 13.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 14.92
 iteration  2713000/10000000 | consumed samples:    347264000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618350E+00 | sop loss: 5.171827E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.03 | backward-compute: 79.89 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 14.98
 iteration  2714000/10000000 | consumed samples:    347392000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614527E+00 | sop loss: 5.182644E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.39 | backward-compute: 79.83 | backward-params-all-reduce: 14.31 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.58 | batch-generator: 17.96
 iteration  2715000/10000000 | consumed samples:    347520000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.612462E+00 | sop loss: 5.051992E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.20 | backward-compute: 79.82 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 17.13
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2715000 | lm loss value: 1.639576E+00 | lm loss PPL: 5.152983E+00 | sop loss value: 6.510454E-02 | sop loss PPL: 1.067271E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2716000/10000000 | consumed samples:    347648000 | elapsed time per iteration (ms): 251.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.613833E+00 | sop loss: 5.101622E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.16 | backward-compute: 79.76 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 14.34
 iteration  2717000/10000000 | consumed samples:    347776000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615574E+00 | sop loss: 5.036218E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.29 | backward-compute: 79.76 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 15.03
 iteration  2718000/10000000 | consumed samples:    347904000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617893E+00 | sop loss: 5.127681E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.94 | backward-compute: 79.87 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.42 | batch-generator: 18.42
 iteration  2719000/10000000 | consumed samples:    348032000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615550E+00 | sop loss: 5.106726E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.59 | backward-compute: 79.78 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.38 | batch-generator: 14.68
 iteration  2720000/10000000 | consumed samples:    348160000 | elapsed time per iteration (ms): 246.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618767E+00 | sop loss: 5.161620E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.96 | backward-compute: 79.84 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.47 | batch-generator: 15.06
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2720000 | lm loss value: 1.666712E+00 | lm loss PPL: 5.294730E+00 | sop loss value: 8.129503E-02 | sop loss PPL: 1.084691E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2721000/10000000 | consumed samples:    348288000 | elapsed time per iteration (ms): 250.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615730E+00 | sop loss: 5.134387E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.06 | backward-compute: 79.80 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 19.47
 iteration  2722000/10000000 | consumed samples:    348416000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617726E+00 | sop loss: 5.063774E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.67 | backward-compute: 79.76 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.44 | batch-generator: 17.18
 iteration  2723000/10000000 | consumed samples:    348544000 | elapsed time per iteration (ms): 245.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.613561E+00 | sop loss: 5.011997E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 132.55 | backward-compute: 79.78 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.54 | batch-generator: 14.03
 iteration  2724000/10000000 | consumed samples:    348672000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615623E+00 | sop loss: 5.118889E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.30 | backward-compute: 79.81 | backward-params-all-reduce: 14.86 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.89 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.43 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.95 | batch-generator: 18.94
 iteration  2725000/10000000 | consumed samples:    348800000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615066E+00 | sop loss: 5.097638E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.77 | backward-compute: 79.75 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 15.24
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2725000 | lm loss value: 1.657402E+00 | lm loss PPL: 5.245667E+00 | sop loss value: 5.993774E-02 | sop loss PPL: 1.061770E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2726000/10000000 | consumed samples:    348928000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619601E+00 | sop loss: 5.223247E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.83 | backward-compute: 79.77 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.77 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 13.70
 iteration  2727000/10000000 | consumed samples:    349056000 | elapsed time per iteration (ms): 246.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616420E+00 | sop loss: 5.206727E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.65 | backward-compute: 79.78 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 15.81
 iteration  2728000/10000000 | consumed samples:    349184000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615763E+00 | sop loss: 5.077268E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.71 | backward-compute: 79.79 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 13.68
 iteration  2729000/10000000 | consumed samples:    349312000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615443E+00 | sop loss: 5.074814E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.28 | backward-compute: 79.73 | backward-params-all-reduce: 14.28 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.52 | batch-generator: 15.65
 iteration  2730000/10000000 | consumed samples:    349440000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614527E+00 | sop loss: 5.062526E-02 | loss scale: 16384.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.94 | backward-compute: 79.80 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 14.51
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2730000 | lm loss value: 1.655370E+00 | lm loss PPL: 5.235018E+00 | sop loss value: 6.374659E-02 | sop loss PPL: 1.065822E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2731000/10000000 | consumed samples:    349568000 | elapsed time per iteration (ms): 249.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618732E+00 | sop loss: 5.110776E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.24 | backward-compute: 79.79 | backward-params-all-reduce: 14.53 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.22 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.65 | batch-generator: 14.91
 iteration  2732000/10000000 | consumed samples:    349696000 | elapsed time per iteration (ms): 249.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615120E+00 | sop loss: 5.128783E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.55 | backward-compute: 79.78 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 15.54
 iteration  2733000/10000000 | consumed samples:    349824000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.619515E+00 | sop loss: 5.101553E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.43 | backward-compute: 79.78 | backward-params-all-reduce: 13.96 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 18.74
 iteration  2734000/10000000 | consumed samples:    349952000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615627E+00 | sop loss: 5.128834E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.20 | backward-compute: 79.82 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.47 | batch-generator: 25.68
 iteration  2735000/10000000 | consumed samples:    350080000 | elapsed time per iteration (ms): 248.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616653E+00 | sop loss: 5.033517E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.93 | backward-compute: 79.76 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.25
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2735000 | lm loss value: 1.698967E+00 | lm loss PPL: 5.468297E+00 | sop loss value: 7.865665E-02 | sop loss PPL: 1.081833E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2736000/10000000 | consumed samples:    350208000 | elapsed time per iteration (ms): 251.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615592E+00 | sop loss: 5.011283E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.77 | backward-compute: 79.79 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.42 | batch-generator: 15.73
 iteration  2737000/10000000 | consumed samples:    350336000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.613485E+00 | sop loss: 5.158124E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.47 | backward-compute: 79.91 | backward-params-all-reduce: 14.29 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.53 | batch-generator: 17.06
 iteration  2738000/10000000 | consumed samples:    350464000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614950E+00 | sop loss: 5.072285E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.55 | backward-compute: 79.79 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 17.49
 iteration  2739000/10000000 | consumed samples:    350592000 | elapsed time per iteration (ms): 250.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615096E+00 | sop loss: 4.923312E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.87 | backward-compute: 79.88 | backward-params-all-reduce: 13.97 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.46 | batch-generator: 29.21
 iteration  2740000/10000000 | consumed samples:    350720000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616099E+00 | sop loss: 5.096009E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.94 | backward-compute: 79.82 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.36 | batch-generator: 18.69
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2740000 | lm loss value: 1.660984E+00 | lm loss PPL: 5.264490E+00 | sop loss value: 5.073365E-02 | sop loss PPL: 1.052043E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2741000/10000000 | consumed samples:    350848000 | elapsed time per iteration (ms): 250.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616166E+00 | sop loss: 5.054006E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.54 | backward-compute: 79.83 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 13.79
 iteration  2742000/10000000 | consumed samples:    350976000 | elapsed time per iteration (ms): 246.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614680E+00 | sop loss: 5.197660E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.43 | backward-compute: 79.88 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 17.42
 iteration  2743000/10000000 | consumed samples:    351104000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615193E+00 | sop loss: 5.229090E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.68 | backward-compute: 79.84 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.55 | batch-generator: 18.25
 iteration  2744000/10000000 | consumed samples:    351232000 | elapsed time per iteration (ms): 249.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615166E+00 | sop loss: 5.071037E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.20 | backward-compute: 79.79 | backward-params-all-reduce: 13.99 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 16.10
 iteration  2745000/10000000 | consumed samples:    351360000 | elapsed time per iteration (ms): 246.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615302E+00 | sop loss: 5.151744E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.50 | backward-compute: 79.79 | backward-params-all-reduce: 14.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.48 | batch-generator: 12.35
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2745000 | lm loss value: 1.642662E+00 | lm loss PPL: 5.168909E+00 | sop loss value: 6.387557E-02 | sop loss PPL: 1.065960E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2746000/10000000 | consumed samples:    351488000 | elapsed time per iteration (ms): 248.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616840E+00 | sop loss: 4.941960E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.42 | backward-compute: 79.79 | backward-params-all-reduce: 14.28 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.58 | batch-generator: 16.96
 iteration  2747000/10000000 | consumed samples:    351616000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617860E+00 | sop loss: 5.155465E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.57 | backward-compute: 79.78 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 17.08
 iteration  2748000/10000000 | consumed samples:    351744000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616627E+00 | sop loss: 5.177547E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.50 | backward-compute: 79.82 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 16.94
 iteration  2749000/10000000 | consumed samples:    351872000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616731E+00 | sop loss: 5.079610E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.03 | backward-compute: 79.78 | backward-params-all-reduce: 14.45 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.17 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.55 | batch-generator: 12.27
 iteration  2750000/10000000 | consumed samples:    352000000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615642E+00 | sop loss: 5.149781E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.67 | backward-compute: 79.81 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 14.34
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2750000 | lm loss value: 1.648391E+00 | lm loss PPL: 5.198610E+00 | sop loss value: 7.515746E-02 | sop loss PPL: 1.078054E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 2750000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 2750000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2288.36
 iteration  2751000/10000000 | consumed samples:    352128000 | elapsed time per iteration (ms): 252.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614401E+00 | sop loss: 5.152909E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.40 | backward-compute: 79.84 | backward-params-all-reduce: 14.13 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 16.14
 iteration  2752000/10000000 | consumed samples:    352256000 | elapsed time per iteration (ms): 245.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.613574E+00 | sop loss: 5.065386E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 131.77 | backward-compute: 79.83 | backward-params-all-reduce: 14.70 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.89 | optimizer-unscale-and-check-inf: 2.30 | optimizer-clip-main-grad: 4.32 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.84 | batch-generator: 17.76
 iteration  2753000/10000000 | consumed samples:    352384000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615136E+00 | sop loss: 5.078604E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.17 | backward-compute: 79.86 | backward-params-all-reduce: 14.56 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.25 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.69 | batch-generator: 14.68
 iteration  2754000/10000000 | consumed samples:    352512000 | elapsed time per iteration (ms): 247.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.613970E+00 | sop loss: 5.039695E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.67 | backward-compute: 79.80 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.10 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 16.16
 iteration  2755000/10000000 | consumed samples:    352640000 | elapsed time per iteration (ms): 250.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618115E+00 | sop loss: 5.139042E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.61 | backward-compute: 79.84 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 18.16
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2755000 | lm loss value: 1.672784E+00 | lm loss PPL: 5.326978E+00 | sop loss value: 4.997077E-02 | sop loss PPL: 1.051240E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2756000/10000000 | consumed samples:    352768000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.613676E+00 | sop loss: 5.230391E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.63 | backward-compute: 79.77 | backward-params-all-reduce: 14.26 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 14.80
 iteration  2757000/10000000 | consumed samples:    352896000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614813E+00 | sop loss: 5.116157E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.41 | backward-compute: 79.87 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.11 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 17.35
 iteration  2758000/10000000 | consumed samples:    353024000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616808E+00 | sop loss: 5.197445E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.37 | backward-compute: 79.83 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 15.51
 iteration  2759000/10000000 | consumed samples:    353152000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.613304E+00 | sop loss: 4.999457E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.55 | backward-compute: 79.83 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.41 | batch-generator: 18.34
 iteration  2760000/10000000 | consumed samples:    353280000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614006E+00 | sop loss: 5.056978E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.50 | backward-compute: 79.85 | backward-params-all-reduce: 14.60 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.27 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.74 | batch-generator: 15.39
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2760000 | lm loss value: 1.643905E+00 | lm loss PPL: 5.175341E+00 | sop loss value: 5.587213E-02 | sop loss PPL: 1.057462E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2761000/10000000 | consumed samples:    353408000 | elapsed time per iteration (ms): 251.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614917E+00 | sop loss: 5.192244E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.23 | backward-compute: 79.84 | backward-params-all-reduce: 14.04 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.37
 iteration  2762000/10000000 | consumed samples:    353536000 | elapsed time per iteration (ms): 247.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614641E+00 | sop loss: 5.000686E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.53 | backward-compute: 79.84 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.38 | batch-generator: 14.65
 iteration  2763000/10000000 | consumed samples:    353664000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614331E+00 | sop loss: 5.088911E-02 | loss scale: 8192.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.60 | backward-compute: 79.74 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.59
 iteration  2764000/10000000 | consumed samples:    353792000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616989E+00 | sop loss: 5.035899E-02 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.43 | backward-compute: 79.76 | backward-params-all-reduce: 14.08 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 16.69
 iteration  2765000/10000000 | consumed samples:    353920000 | elapsed time per iteration (ms): 248.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615919E+00 | sop loss: 5.102865E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.89 | backward-compute: 79.77 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 18.30
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2765000 | lm loss value: 1.664346E+00 | lm loss PPL: 5.282219E+00 | sop loss value: 5.943330E-02 | sop loss PPL: 1.061235E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2766000/10000000 | consumed samples:    354048000 | elapsed time per iteration (ms): 249.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.613771E+00 | sop loss: 4.984615E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.80 | backward-compute: 79.81 | backward-params-all-reduce: 14.51 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.24 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.67 | batch-generator: 19.65
 iteration  2767000/10000000 | consumed samples:    354176000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618382E+00 | sop loss: 5.170852E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.24 | backward-compute: 79.82 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 16.46
 iteration  2768000/10000000 | consumed samples:    354304000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.613959E+00 | sop loss: 5.057828E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.99 | backward-compute: 79.91 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 19.53
 iteration  2769000/10000000 | consumed samples:    354432000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614078E+00 | sop loss: 5.125507E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.28 | backward-compute: 79.81 | backward-params-all-reduce: 14.17 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.44 | batch-generator: 16.04
 iteration  2770000/10000000 | consumed samples:    354560000 | elapsed time per iteration (ms): 248.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616281E+00 | sop loss: 5.169621E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.70 | backward-compute: 79.82 | backward-params-all-reduce: 14.05 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.43 | batch-generator: 16.67
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2770000 | lm loss value: 1.656441E+00 | lm loss PPL: 5.240627E+00 | sop loss value: 4.712968E-02 | sop loss PPL: 1.048258E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2771000/10000000 | consumed samples:    354688000 | elapsed time per iteration (ms): 250.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.618075E+00 | sop loss: 5.219117E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.35 | backward-compute: 79.80 | backward-params-all-reduce: 13.91 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 16.70
 iteration  2772000/10000000 | consumed samples:    354816000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617633E+00 | sop loss: 5.192035E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.97 | backward-compute: 79.77 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 14.34
 iteration  2773000/10000000 | consumed samples:    354944000 | elapsed time per iteration (ms): 247.5 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614380E+00 | sop loss: 5.033932E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.28 | backward-compute: 79.81 | backward-params-all-reduce: 14.40 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.18 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.59 | batch-generator: 13.93
 iteration  2774000/10000000 | consumed samples:    355072000 | elapsed time per iteration (ms): 246.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617236E+00 | sop loss: 5.089700E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.97 | backward-compute: 79.86 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.39 | batch-generator: 16.14
 iteration  2775000/10000000 | consumed samples:    355200000 | elapsed time per iteration (ms): 248.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616817E+00 | sop loss: 5.121276E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.53 | backward-compute: 79.84 | backward-params-all-reduce: 14.31 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.52 | batch-generator: 12.95
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2775000 | lm loss value: 1.657558E+00 | lm loss PPL: 5.246485E+00 | sop loss value: 6.705196E-02 | sop loss PPL: 1.069351E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2776000/10000000 | consumed samples:    355328000 | elapsed time per iteration (ms): 249.6 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.611457E+00 | sop loss: 5.161652E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.23 | backward-compute: 79.85 | backward-params-all-reduce: 14.60 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.25 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.69 | batch-generator: 16.90
 iteration  2777000/10000000 | consumed samples:    355456000 | elapsed time per iteration (ms): 249.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614268E+00 | sop loss: 5.096108E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.24 | backward-compute: 79.82 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.49 | batch-generator: 16.55
 iteration  2778000/10000000 | consumed samples:    355584000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615490E+00 | sop loss: 4.995127E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.03 | backward-compute: 79.78 | backward-params-all-reduce: 14.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.50 | batch-generator: 16.37
 iteration  2779000/10000000 | consumed samples:    355712000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615214E+00 | sop loss: 5.005549E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.80 | backward-compute: 79.83 | backward-params-all-reduce: 13.85 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.40 | batch-generator: 20.03
 iteration  2780000/10000000 | consumed samples:    355840000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614195E+00 | sop loss: 5.121576E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.02 | backward-compute: 79.78 | backward-params-all-reduce: 14.14 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 13.27
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2780000 | lm loss value: 1.632802E+00 | lm loss PPL: 5.118195E+00 | sop loss value: 6.182111E-02 | sop loss PPL: 1.063772E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2781000/10000000 | consumed samples:    355968000 | elapsed time per iteration (ms): 250.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617771E+00 | sop loss: 5.037482E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.72 | backward-compute: 79.78 | backward-params-all-reduce: 14.28 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.57 | batch-generator: 18.14
 iteration  2782000/10000000 | consumed samples:    356096000 | elapsed time per iteration (ms): 248.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615176E+00 | sop loss: 5.196383E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.26 | backward-compute: 79.82 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 14.08
 iteration  2783000/10000000 | consumed samples:    356224000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.612598E+00 | sop loss: 4.935617E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.55 | backward-compute: 79.81 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 19.42
 iteration  2784000/10000000 | consumed samples:    356352000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.613097E+00 | sop loss: 5.203220E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.08 | backward-compute: 79.88 | backward-params-all-reduce: 14.07 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.37 | batch-generator: 14.33
 iteration  2785000/10000000 | consumed samples:    356480000 | elapsed time per iteration (ms): 247.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.613199E+00 | sop loss: 5.096060E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.38 | backward-compute: 79.92 | backward-params-all-reduce: 14.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 14.06
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2785000 | lm loss value: 1.658937E+00 | lm loss PPL: 5.253722E+00 | sop loss value: 6.546475E-02 | sop loss PPL: 1.067655E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2786000/10000000 | consumed samples:    356608000 | elapsed time per iteration (ms): 250.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616397E+00 | sop loss: 4.934813E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.48 | backward-compute: 79.87 | backward-params-all-reduce: 14.45 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.19 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.63 | batch-generator: 16.12
 iteration  2787000/10000000 | consumed samples:    356736000 | elapsed time per iteration (ms): 248.2 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.616631E+00 | sop loss: 5.207233E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.44 | backward-compute: 79.83 | backward-params-all-reduce: 14.02 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.07 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 15.26
 iteration  2788000/10000000 | consumed samples:    356864000 | elapsed time per iteration (ms): 248.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617332E+00 | sop loss: 5.114833E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.32 | backward-compute: 79.82 | backward-params-all-reduce: 14.10 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 15.93
 iteration  2789000/10000000 | consumed samples:    356992000 | elapsed time per iteration (ms): 250.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.611904E+00 | sop loss: 5.075903E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.46 | backward-compute: 79.80 | backward-params-all-reduce: 14.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.05 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.40 | batch-generator: 14.85
 iteration  2790000/10000000 | consumed samples:    357120000 | elapsed time per iteration (ms): 248.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.612851E+00 | sop loss: 5.081997E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 136.16 | backward-compute: 79.84 | backward-params-all-reduce: 13.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.37 | batch-generator: 15.36
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2790000 | lm loss value: 1.640479E+00 | lm loss PPL: 5.157640E+00 | sop loss value: 4.777049E-02 | sop loss PPL: 1.048930E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2791000/10000000 | consumed samples:    357248000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.613720E+00 | sop loss: 5.058496E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.52 | backward-compute: 79.78 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.79 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.39 | batch-generator: 14.77
 iteration  2792000/10000000 | consumed samples:    357376000 | elapsed time per iteration (ms): 248.3 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.617469E+00 | sop loss: 5.103018E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.17 | backward-compute: 79.82 | backward-params-all-reduce: 14.29 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.13 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.51 | batch-generator: 15.65
 iteration  2793000/10000000 | consumed samples:    357504000 | elapsed time per iteration (ms): 249.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615388E+00 | sop loss: 5.007575E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.00 | backward-compute: 79.76 | backward-params-all-reduce: 14.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.78 | optimizer-unscale-and-check-inf: 2.25 | optimizer-clip-main-grad: 4.04 | optimizer-copy-main-to-model-params: 1.23 | optimizer: 16.34 | batch-generator: 14.03
 iteration  2794000/10000000 | consumed samples:    357632000 | elapsed time per iteration (ms): 247.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.611361E+00 | sop loss: 5.011886E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.07 | backward-compute: 79.84 | backward-params-all-reduce: 14.01 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.06 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.42 | batch-generator: 19.06
 iteration  2795000/10000000 | consumed samples:    357760000 | elapsed time per iteration (ms): 247.7 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615160E+00 | sop loss: 5.139194E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.88 | backward-compute: 79.86 | backward-params-all-reduce: 14.12 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.45 | batch-generator: 16.27
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2795000 | lm loss value: 1.720627E+00 | lm loss PPL: 5.588033E+00 | sop loss value: 6.225017E-02 | sop loss PPL: 1.064229E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 iteration  2796000/10000000 | consumed samples:    357888000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614109E+00 | sop loss: 5.041316E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.65 | backward-compute: 79.81 | backward-params-all-reduce: 14.16 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.08 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.44 | batch-generator: 17.98
 iteration  2797000/10000000 | consumed samples:    358016000 | elapsed time per iteration (ms): 249.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615173E+00 | sop loss: 5.141865E-02 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 137.09 | backward-compute: 79.81 | backward-params-all-reduce: 14.09 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.81 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.48 | batch-generator: 21.75
 iteration  2798000/10000000 | consumed samples:    358144000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.612862E+00 | sop loss: 5.041398E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.47 | backward-compute: 79.79 | backward-params-all-reduce: 14.49 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.83 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.20 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.62 | batch-generator: 12.14
 iteration  2799000/10000000 | consumed samples:    358272000 | elapsed time per iteration (ms): 247.4 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614002E+00 | sop loss: 5.051454E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.55 | backward-compute: 79.78 | backward-params-all-reduce: 14.19 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.09 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.46 | batch-generator: 14.43
 iteration  2800000/10000000 | consumed samples:    358400000 | elapsed time per iteration (ms): 249.0 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615922E+00 | sop loss: 5.128761E-02 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.83 | backward-compute: 79.81 | backward-params-all-reduce: 14.35 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.82 | optimizer-unscale-and-check-inf: 2.27 | optimizer-clip-main-grad: 4.15 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.56 | batch-generator: 16.33
---------------------------------------------------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 2800000 | lm loss value: 1.638408E+00 | lm loss PPL: 5.146967E+00 | sop loss value: 6.671397E-02 | sop loss PPL: 1.068990E+00 | 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
saving checkpoint at iteration 2800000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
  successfully saved checkpoint at iteration 2800000 to /workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe
time (ms) | save checkpoint: 2347.11
 iteration  2801000/10000000 | consumed samples:    358528000 | elapsed time per iteration (ms): 250.8 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.613850E+00 | sop loss: 5.083703E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 133.79 | backward-compute: 79.87 | backward-params-all-reduce: 14.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.84 | optimizer-unscale-and-check-inf: 2.28 | optimizer-clip-main-grad: 4.16 | optimizer-copy-main-to-model-params: 1.25 | optimizer: 16.58 | batch-generator: 13.94
 iteration  2802000/10000000 | consumed samples:    358656000 | elapsed time per iteration (ms): 247.9 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.615794E+00 | sop loss: 5.175890E-02 | loss scale: 16384.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
time (ms) | forward-compute: 134.81 | backward-compute: 79.85 | backward-params-all-reduce: 14.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.80 | optimizer-unscale-and-check-inf: 2.26 | optimizer-clip-main-grad: 4.12 | optimizer-copy-main-to-model-params: 1.24 | optimizer: 16.48 | batch-generator: 14.18
 iteration  2803000/10000000 | consumed samples:    358784000 | elapsed time per iteration (ms): 249.1 | learning rate: 1.000E-05 | global batch size:   128 | lm loss: 1.614388E+00 | sop loss: 5.049431E-02 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 135.05 | backward-compute: 79.86 | backward-params-all-reduce: 14.71 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 3.86 | optimizer-unscale-and-check-inf: 2.29 | optimizer-clip-main-grad: 4.29 | optimizer-copy-main-to-model-params: 1.26 | optimizer: 16.77 | batch-generator: 17.21
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/opt/conda/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/opt/conda/lib/python3.8/site-packages/torch/distributed/launch.py", line 303, in <module>
    main()
  File "/opt/conda/lib/python3.8/site-packages/torch/distributed/launch.py", line 294, in main
    raise subprocess.CalledProcessError(returncode=process.returncode,
subprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', 'pretrain_bert.py', '--local_rank=7', '--num-layers', '12', '--hidden-size', '768', '--num-attention-heads', '12', '--micro-batch-size', '16', '--global-batch-size', '128', '--seq-length', '512', '--max-position-embeddings', '512', '--train-iters', '10000000', '--save', '/workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe', '--load', '/workspace/megatron/ngc_models/release_bert_base_cased_nttreso_jp_32k_mecab_bpe', '--data-path', '/workspace/megatron/megatron2/nttreso-ja-bert-vocab-32k-mecab-bpe-case_text_sentence', '--vocab-file', '/workspace/megatron/datasets/nttreso_qa/export/export_readable_20210727_simp_2read_v3.mecab.txt.vocab.32000.v3.bpe', '--tokenizer-type', 'BertWordPieceCaseJp', '--data-impl', 'mmap', '--split', '949,50,1', '--distributed-backend', 'nccl', '--lr', '0.0001', '--lr-decay-style', 'linear', '--min-lr', '1.0e-5', '--lr-decay-iters', '990000', '--weight-decay', '1e-2', '--clip-grad', '1.0', '--lr-warmup-fraction', '.01', '--log-interval', '1000', '--save-interval', '50000', '--eval-interval', '5000', '--eval-iters', '10', '--fp16']' died with <Signals.SIGTERM: 15>.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
